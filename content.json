{"meta":{"title":"Avery Ma 的个人网站","subtitle":"这是什么？","description":"个人网站、博客","author":"skinyi","url":"https://skinyi.github.io","root":"/"},"pages":[{"title":"关于","date":"2022-02-22T12:55:00.000Z","updated":"2022-02-24T13:30:42.633Z","comments":true,"path":"about/index.html","permalink":"https://skinyi.github.io/about/index.html","excerpt":"","text":"关于我 联系我 邮箱：averyma@foxmail.com"},{"title":"categories","date":"2022-02-23T06:19:06.228Z","updated":"2022-02-23T06:19:06.228Z","comments":false,"path":"categories/index.html","permalink":"https://skinyi.github.io/categories/index.html","excerpt":"","text":""},{"title":"repositories","date":"2022-02-23T06:19:12.138Z","updated":"2022-02-23T06:19:12.138Z","comments":false,"path":"repository/index.html","permalink":"https://skinyi.github.io/repository/index.html","excerpt":"","text":""},{"title":"tags","date":"2022-02-23T06:19:18.235Z","updated":"2022-02-23T06:19:18.235Z","comments":false,"path":"tags/index.html","permalink":"https://skinyi.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"初识 Ansible 自动化工具","slug":"Linux | 初识 Ansible 自动化工具","date":"2022-08-15T07:15:16.560Z","updated":"2022-08-15T07:20:50.687Z","comments":true,"path":"2022-08-15-Linux | 初识 Ansible 自动化工具.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E5%88%9D%E8%AF%86%20Ansible%20%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B7%A5%E5%85%B7.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 自动化与 Linux 系统管理 为何需要自动化管理 ​多年来，大多数系统管理和基础架构管理都依赖于通过图形或命令行用户界面执行的手动任务。系统管理员通常使用检查清单、其他文档或记忆的例程来执行标准任务。 ​这样的做法容易出错。系统管理员很容易跳过某个步骤或错误地执行某个步骤。对步骤执行是否正确或产生预期的结果的验证通常有限。 ​另外，如果以手动方式单独管理每一服务器，对于应该要在配置上完全一致的许多服务器而言，它们很容易会出现微小（或重大）的差异。这可能会加大维护的难度，并给 IT 环境带来错误或不稳定性。 ​自动化可以帮助您避免手动管理系统和基础架构造成的问题。作为系统管理员，您可以使用它来确保快速、正确地部署和配置所有系统。这样，您可以自动执行日常计划中的重复性任务，从而空出时间并专注于更重要的事情。对组织而言，这意味着您可以更快地推出下一版本的应用或服务更新。 基础架构即代码 ​良好的自动化系统允许您实施基础架构即代码方法。基础架构即代码意味着您可以使用机器可读的自动化语言来定义和描述您希望IT基础架构所处的状态。理想情况下，这种自动化语言也应该非常便于人类阅读，因为这样您就可以轻松了解所处的状态并对其进行更改。然后，此代码可应用于您的基础架构，确保它真正处于该状态。 ​如果自动化语言表示为简单文本文件，则可以在软件代码等版本控制系统中轻松管理。这样做的好处是每个更改都可以签入到版本控制系统中，因此您可以获得随时间所做更改的历史记录。如果您要恢复到更早的已知良好配置，只需签出这一版本的代码并将其应用到您的基础架构。 ​这样就奠定了一个基础，帮助您遵循 DevOps 中的最佳实践。开发人员可以在自动化语言中定义所需的配置。操作员可以更轻松地查看这些更改以提供反馈，并使用该自动化可重复地确保系统处于开发人员期望的状态。 减少人为错误 ​通过使用任务自动化和基础架构即代码方法来减少在服务器上手动执行的任务，您的服务器将更频繁地处于一致的配置中。这意味着您需要习惯于通过更新自动化代码进行更改，而不是手动将其应用到服务器。否则，在下次通过自动化应用更改时您将面临丢失之前手动应用的更改的风险。 ​自动化允许您使用代码审查、多个主题专家的同行评审，以及自动化本身的程序文档，以降低您的操作风险。 ​最终，您可以强制必须通过自动化对 IT 基础架构进行更改，以减少人为错误。 什么是 Ansible ​Ansible 是一款开源自动化平台。它是一种简单的自动化语言，能够在 Ansible Playbook 中完美地描述 IT 应用基础架构。它也是一个自动化引擎，可运行 Ansible Playbook。 ​Ansible 可以管理强大的自动化任务，而且能够适应许多不同的工作流和环境。同时，Ansible 新用户可以非常快速地利用它来提高工作效率。 Ansible 简单明了 ​Ansible Playbook 提供人类可读的自动化。这表示，Playbook 不仅是自动化工具，而且易于阅读、理解和更改。不需要掌握特别的编码技能就能编写它们。Playbook 按顺序执行任务。Playbook 设计的简易性使其可供每个团队使用，让 Ansible 入门者也能够快速获得成效。 Ansible 功能强大 ​可以利用 Ansible 部署应用，也可将它用于配置管理、工作流自动化和网络自动化。Ansible可用于编排整个应用生命周期。 Ansible 无需代理 ​Ansible 围绕无代理架构构建。通常而言，Ansible 通过 OpenSSH 或 WinRM 连接它所管理的主机并且运行任务，方法通常是（但不总是）将称为 Ansible 模块的小程序推送至这些主机。这些程序用于将系统置于需要的特定状态。在 Ansible 运行完其任务后，推送的所有模块都会被删除。您几乎可以立即开始使用 Ansible，因为不需要批准使用任何特殊代理，然后再部署到受管主机上。由于没有代理，也不需要额外的自定义安全基础架构，Ansible 要比其他备选方案更加高效和安全。 ​同时 Ansible 也具有以下多个重要的优点： 跨平台支持：Ansible 提供 Linux、Windows、UNIX 和网络设备的无代理支持，适用于物理、虚拟、云和容器环境。 人类可读的自动化：Ansible Playbook 采用 YAML 文本文件编写，易于阅读，有助于确保所有人都能理解它们的用途。 完美描述应用：可以通过 Ansible Playbook 进行每一种更改，并描述和记录应用环境的每一个方面。 轻松管理版本控制：Ansible Playbook 和项目是纯文本。它们可以视作源代码，放在您的现有版本控制系统中。 支持动态清单：可以从外部来源动态更新 Ansible 管理的计算机的列表，随时获取所有受管服务器的当前正确列表，不受基础架构或位置的影响。 编排可与其他系统轻松集成：能够利用环境中现有的 HPSA、Puppet、Jenkins、红帽卫星和其他系统，并且集成到 Ansible 工作流中。 Ansible 的概念和架构 ​Ansible架构中有两种计算机类型，即控制节点和受管主机。Ansible 在控制节点上安装和运行，该计算机上也含有 Ansible 项目文件的副本。控制节点可以是管理员的笔记本电脑、多个管理员共享的系统，或者运行红帽 Ansible Tower 的服务器。 ​受管主机列在清单中，清单还可以将这些系统组织到组中，以便于集中管理。清单可以在静态文本文件中定义，或者通过从外部来源获取信息的脚本来动态确定。 ​Ansible 用户无需编写复杂的脚本，而只要创建高级别 play 即可确保主机或主机组处于特定状态。Play 按该 play 指定的顺序对主机执行一系列任务。这些 play 通过采用 YAML 格式的文本文件来表达。包含一个或多个 play 的文件称为 playbook。 ​每个任务运行一个模块，即（使用 Python、PowerShell 或某种其他语言编写的）一小段代码。各个模块基本上是您的工具包中的一个工具。Ansible 随附了数百个实用模块，它们能够执行许多不同的自动化任务。它们可以作用于系统文件，安装软件或者进行 API 调用。 ​在任务中使用时，模块通常确保计算机的某一特定方面处于特定的状态。例如，使用某一模块的任务可以确保某一文件存在且具有特定的权限和内容，而使用另一不同模块的任务可确保已挂载特定的文件系统。如果系统不处于指定的状态，任务应将它置于该状态。如果系统已处于该状态，则不执行任何操作。如果任务失败，Ansible 的默认行为是对发生了错误的主机中止 playbook 的其余部分任务。 ​play 和 playbook 设计为具有幂等性。这意味着，您可以在相同主机上多次安全地运行一个 playbook。当您的系统处于正确状态时，playbook 在运行时不会进行任何更改。这意味着，您应该能够在相同主机上多次安全地运行一个 playbook。当您的系统处于正确状态时，playbook 在运行时不应进行任何更改。您可以使用多个模块来运行任意命令。但是，您必须小心使用这些模块，以确保它们以幂等方式运行。 ​Ansible 也使用插件。插件是您可以添加到 Ansible 中的代码，以对它进行扩展并使它适合新的用途和平台。 ​Ansible 架构是无代理的。通常，当管理员运行 Ansible Playbook 或临时命令时，控制节点使用 SSH（默认）或 WinRM 连接受管主机。这意味着客户端无需在受管主机上安装特定于 Ansible 的代理，也不需要允许将特殊的网络流量传输到某一非标准端口。 ​红帽 AnsibleTower 是一种企业框架，可帮助您规模化控制、保护和管理 Ansible 自动化。您可以用它控制谁有权在哪些主机上运行 playbook，共享使用 SSH 凭据而不必允许用户传输或查看其内容，记录您的所有 Ansible 作业，以及管理清单，等等。它提供基于Web的用户界面（Web UI）和 RESTful API。它不是 Ansible 的核心部分，而是单独的产品，能够帮助您更加有效地以团队或更大规模使用 Ansible。 Ansible 架构的优势 不会因为复杂性而破坏效率 ​越简单越好。Ansilble的设计宗旨是工具易用，自动化易写易读。您应利用这一特点在创建自动化时追求简单化。 专为易读性优化 ​Ansible自动化语言围绕简单易读的声明性文本文件来构建。正确编写的AnsiblePlaybook可以清楚地记录您的工作流自动化。 声明式思维 ​Ansible 是一种要求状态引擎。它通过表达您希望系统处于何种状态来解决如何自动化 IT 部署的问题。Ansible 的目标是通过仅执行必要的更改，使您的系统处于所需的状态。试图将 Ansible 视为脚本语言并非正确的做法。 Ansible 用例 ​与某些其他工具不同，Ansible 在一个易用的平台中，将编排与配置管理、调配和应用部署相结合。 ​Ansible的一些用例包括： 配置管理 ​集中化配置文件管理和部署是 Ansible 的常见用例，很多超级用户也是通过这种方式了解 Ansible 自动化平台。 应用部署 ​通过Ansible定义应用，以及使用红帽 Ansible Tower 管理部署时，各团队可以更加有效地管理从开发到生产的整个应用生命周期。 调配 ​应用必须要部署或安装到系统上。Ansible 和红帽 Ansible Tower 有助于简化调配系统的流程，不论您是要 PXE 引导和kickstart 安装裸机恢复服务器或虚拟机，还是从模板创建虚拟机或云实例。应用必须要部署或安装到系统上。 持续交付 ​创建 CI/CD 管道需要多个团队的协调和参与。如果没有组织内人人可用的简单自动化平台，就无法实现这个目标。Ansible Playbook 让您的应用可以在整个生命周期内得到正确部署（和管理）。 安全和合规性 ​当您在 Ansible Playbook 中定义安全策略时，也可以将扫描和修复整站安全策略集成到其他自动化流程中。确保安全应该是您所有部署中不可或缺的组成部分，而不是事后才去考虑的部分。 编排 ​仅配置本身不足以定义您的环境。您还需要定义多个配置间应如何交互，并且确保以整体的方式管理各类分散的资源。","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"管理网络安全","slug":"Linux | 管理网络安全","date":"2022-08-15T07:11:49.614Z","updated":"2022-08-15T07:14:18.990Z","comments":true,"path":"2022-08-15-Linux | 管理网络安全.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E7%AE%A1%E7%90%86%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 管理服务器防火墙 防火墙原理概述 Netfilter ​Linux 内核中包含 netfilter，它是网络流量操作（如数据包过滤、网络地址转换和端口转换）的框架。通过在内核中实现拦截函数调用和消息的处理程序，netfilter 允许其他内核模块直接与内核的网络堆栈进行接口连接。防火墙软件使用一些 Hook 方法来注册过滤规则和数据包修改功能，以便对经过网络堆栈的每个数据包进行处理。在到达用户空间组件或应用之前，任何传入、传出或转发的网络数据包都可以通过编程方式来检查、修改、丢弃或路由。netfilter 是红帽企业 Linux 8 防火墙的主要组件。 Nftables ​Linux 内核中还包含 nftables，这是一个新的过滤器和数据包分类子系统，其增强了 netfilter 的部分代码，但仍保留了 netfilter 的架构，如网络堆栈 Hook、连接跟踪系统及日志记录功能。nftables 更新的优势在于更快的数据包处理、更快的规则集更新，以及以相同的规则同时处理 IPV4 和 IPV6。nftables 与原始 netfilter 之间的另一个主要区别是它们的接口。Netfilter 通过多个实用程序框架进行配置，其中包括 iptables、ip6tables、arptables 和 ebtables，这些框架现在已被弃用。Nftables 使用单个 nft 用户空间实用程序，通过一个接口来管理所有协议，由此消除了以往不同前端和多个 netfilter 接口引起的争用问题。 Firewalld ​Firewalld 是一个动态防火墙管理器，它是 nftables 框架的前端（使用 nft 命令）。在推出 nftables 之前，作为一种改进 iptables 服务的替代方案，firewalld 曾使用 iptables 命令来直接配置 netfilter。在 RHEL8 中，firewalld 仍然是推荐的前端，它使用 nft 来管理防火墙规则集。Firewalld 仍可以读取和管理 iptables 配置文件和规则集，并使用 xtables-nft-multi 将 iptables 对象直接转换为 nftables 规则和对象。对于 nft 转换过程无法正确处理现 有 iptables 规则集的复杂用例，您可以对 firewalld 进行配置，使之恢复为 iptables 后端，虽然强烈建议不要这样做。 ​应用会使用 D-Bus 接口查询子系统。firewalld 子系统（可通过 firewalld RPM 软件包获得）未包含在最小安装中，但包含在基本安装中。借助 firewalld，可以将所有网络流量分为多个区域，从而简化防火墙管理。根据数据包源IP地址或传入网络接口等条件，流量将转入相应区域的防火墙规则。每个区域都有自己的端口和服务列表，它们处于打开或者关闭状态。 对于笔记本电脑或经常更改网络的其他计算机，可以使用 NetworkManager 自动设置连接的防火墙区域。这些区域使用适于特定连接的规则进行自定义。 当您经常在家庭、办公室和公共无线网络间切换时，此功能尤为实用。当连接到家庭网络和企业网络时，用户可能希望系统的sshd 服务可访问，但当用户连接到当地咖啡馆的公共无线网络时则不然。 ​Firewalld 会检查进入系统的每个数据包的源地址。如果该源地址被分配给特定区域，则应用该区域的规则。如果该源地址未分配给某个区域，firewalld 就会将数据包与传入网络接口的区域相关联，并应用该区域的规则。如果出于某种原因，网络接口未与某个区域关联，则 firewalld 会将数据包与默认区域相关联。 ​默认区域不是一个单独的区域，而是指代现有的区域。最初，firewalld 指定 public 区域为默认区域，并将 lo 回环接口映射至 trusted 区域。 ​大多数区域会允许与特定端口和协议（例如 631/udp）或预定义服务（例如 ssh ）的列表匹配的流量通过防火墙。如果流量不与允许的端口和协议或服务匹配，则通常会被拒绝。（trusted 区域默认情况下允许所有流量，它是此规则的一个例外。） 预定义区域 ​Firewalld 上有一些预定义区域，可分别进行自定义。默认情况下，如果传入流量属于系统启动的通信的一部分，则所有区域都允许这些传入流量和所有传出流量。下表详细介绍了这些初始区域配置。 区域名称 默认配置 trusted 允许所有传入流量。 home 除非与传出流量相关，或与 ssh、mdns、ipp-client、samba-client 或 dhcpv6-client 预定义服务匹配，否则拒绝传入流量。 internal 除非与传出流量相关，或与 ssh、mdns、ipp-client、samba-client 或 dhcpv6-client 预定义服务匹配，否则拒绝传入流量。（一开始与 home 区域相同） work 除非与传出流量相关，或与 ssh、ipp-client 或 dhcpv6-client 预定义服务匹配，否则拒绝传入流量。 public 除非与传出流量相关，或与 ssh 或 dhcpv6-client 预定义服务匹配，否则拒绝传入流量。新添加的网络接口的默认区域。 external 除非与传出流量相关，或与 ssh 预定义服务匹配，否则拒绝传入流量。通过此区域转发的 IPV4 传出流量将进行伪装，以使其看起来像是来自传出网络接口的 IPV4 地址。 dmz 除非与传出流量相关，或与 ssh 预定义服务匹配，否则拒绝传入流量。 block 除非与传出流量相关，否则拒绝所有传入流量。 drop 除非与传出流量相关，否则丢弃所有传入流量（甚至不产生包含 ICMP 错误的响应）。 预定义服务 ​Firewald 上有一些预定义服务。这些服务定义可帮助您识别要配置的特定网络服务。例如，可指定预构建的 samba-client 服务来配置正确的端口和协议，而无需研究 samba-client 服务的相关端口。下表列出了初始防火墙区域配置中使用的预定义服务。 服务名称 配置 SSH 本地 SSH 服务器。到 22/tcp 的流量。 dhcpv6-client 本地 DHCPv6 客户端。到 fe80::/64 IPV6 网络中 546/udp 的流量。 ipp-client 本地 IPP 打印。到 631/udp 的流量。 samba-client 本地 Windows 文件和打印共享客户端。到 137/udp 和 138/udp 的流量。 MDNS 多播 DNS（mDNS）本地链路名称解析。到 5353/udp 指向 224.0.0.251（IPV4）或 f02:fb（IPV6）多播地址的流量。 许多预定义服务都包含在 firewalld 软件包中。使用 firewall-cmd --get-services 可以列出这些预定义服务。预定义服务的配置文件位于 /usr/1ib/firewalld/services 中，其格式由 firewalld.zone（5）定义。 可以使用预定义服务，或者直接指定所需的端口和协议。可以使用Web控制台图形界面来查看预定义服务和定义更多服务。 配置防火墙 ​系统管理员可通过三种主要方式与firewalld交互： 直接编辑/etc/firewalld/中的配置文件（本章中不讨论）； Web控制台图形界面（略）； firewall-cmd命令行工具。 本章重点关注从命令行配置防火墙。 从命令行配置防火墙 ​firewall-cmd 命令将会与 firewalld 动态防火墙管理器进行交互。它是作为主 firewalld 软件包的一部分安装的，可用于倾向于使用命令行的管理员，在没有图形环境的系统上工作，或编写有关防火墙设置的脚本。 ​下表列出一些常用 firewall-cmd 命令及其说明。请注意，除非另有指定，否则几乎所有命令都作用于运行时配置，当指定*--permanent*选项时除外。如果指定了 --permanent 选项，还必须通过运行 firewall-cmd -reload 命令来激活设置，它将读取当前的永久配置并将其作为新的运行时配置来应用。列出的许多命令都采用 --zone=ZONE 选项来确定所影响的区域。如果需要子网拖码，请使用 CIDR 表示法，如 192.168.1/24。 firewall-cmd 命令 说明 --get-default-zone 查询当前默认区域。 --set-default-zone=ZONE 设置默认区域。此命令会同时更改运行时配置和永久配置。 --get-zones 列出所有可用区域。 --get-active-zones 列出当前正在使用的所有区域（具有关联的接口或源）及其接口和源信息。 --add-source=CIDR [--zone=ZONE] 将来自 IP 地址或网络/子网掩码的所有流量路由到指定区域。如果未提供 --zone= 选项，则使用默认区域。 --remove-source=CIDR [--zone=ZONE] 从区域中删除用于路由来自 IP 地址或网络/子网拖码的所有流量的规则。如果未提供 -zone= 选项，则使用默认区域。 --add-interface=INTERFACE [--zone=ZONE] 将来自 INTERFACE 的所有流量路由到指定区域。如果未提供 --zone= 选项，则使用默认区域。 --change-interface=INTERFACE [zone=ZONE] 将接口与 ZONE 而非其当前区域关联。如果未提供 --zone= 选项，则使用默认区域。 --list-all [--zone=ZONE] 列出 ZONE 的所有已配置接口、源、服务和端口。如果未提供 --zone= 选项，则使用默认区域。 --list-all-zones 检索所有区域的所有信息（接口、源、端口、服务）。 --add-service=SERVICE [--zone=ZONE] 允许到 SERVICE 的流量。如果未提供 --zone= 选项，则使用默认区域。 --add-port=PORT/PROTOCOL [--zone=ZONE] 允许到 PORT/PROTOCOL 端口的流量。如果未提供 --zone= 选项，则使用默认区域。 --remoce-service=SERVICE [--zone=ZONE] 从区域的允许列表中删除 SERVICE。如果未提供 --zone= 选项，则使用默认区域。 --remove-port=PORT/PROTOCOL [--zone=ZONE] 从区域的允许列表中删除 PORT/PROTOCOL 端口。如果未提供 --zone= 选项，则使用默认区域。 --reload 丢弃运行时配置并应用持久配置。 ​以下命令示例会将默认区域设置为 dmz，将来自 192.168.9.0/24 网络的所有流量都分配给 internal 区域，并在internal 区域上打开用于 mysql 服务的网络端口。 1234[root@localhost ~]\\# firewall-cmd --set-default-zone=dmz[root@localhost ~]\\# firewall-cmd --permanent --zone=internal --add-source=192.168.0.0/24[root@localhost ~]\\# firewall-cmd --permanent --add-service=mysql[root@localhost ~]\\# firewall-cmd --reload 对于 firewalld 的基本语法不够的情况，还可以添加富规则（一种更具表达力的语法）来编写复杂的规则。如果富规则语法也不够，您还可以使用直接配置规则，这是与 firewalld 规则混合使用的原始 nft 语法。 这些高级模式超出了本章的讨论范围。 控制 SELinux 端口标记 SELinux 端口标记概述 ​SELinux 不仅仅是进行文件和进程标记。SELinux 策略还严格实施网络流量。SELinux 用来控制网络流量的其中一种方法是标记网络端口；例如，在 targeted 策略中，端口 22/TCP 具有标签 ssh_port_t与其相关联。默认 HTTP 端口 80/TCP 和 443/TCP 具有标签 http_port_t 与其相关联。当某个进程希望侦听端口时，SELinux将检查是否允许与该进程（域）相关联的标签绑定该端口标签。这可以阻止恶意服务控制本应由其他（合法）网络服务使用的端口。 管理 SELinux 端口标记 ​如果决定在非标准端口上运行服务，SELinux 肯定会拦截此流量。在这种情况下，必须更新 SELinux 端口标签。在某些情况下，targeted 策略已经通过可以使用的类型标记了端口；例如，由于端口 8008/TCP 通常用于Web应用程序，此端口已使用http_port_t（Web 服务器的默认端口类型）进行标记。 列出端口标签 ​要获取所有当前端口标签分配的概述，请运行 semanage port -l 命令。-l 选项将以下列形式列出所有当前分配： 1port_label_t tcp|udp comma,separated,list,of,ports ​输出示例： 123456[root@localhost ~]\\# semanage port -l......http_cache_port_t tcp 8080, 8118, 8123, 10001-10010http_cache_port_t udp 8130http_port_t tcp 80, 81, 443, 488, 8008, 8009, 8443, 9000...... ​要优化搜索，可以使用 grep 命令： 12345[root@localhost ~]\\# semanage port -l | grep ftpftp_data_port_t tcp 20ftp_port_t tcp 21, 989, 990ftp_port_t udp 989, 990tftp_port_t udp 69 ​一个端口标签可能会在输出中出现两次，一次是针对 TCP ，一次是针对 UDP。 添加端口标签 ​使用 semanage 命令可以分配新端口标签、删除端口标签或修改现有端口标签。 Linux 发行版中的大多数标准服务都提供了一个 SELinux 策略模块，用于在端口上设置标签。其中无法使用 semanage 来更改这些端口上的标签；要更改这些标签则需要替换策略模块。编写和生成策略模块在此节不涉及。 ​要向现有端口标签（类型）中添加端口，请使用以下语法。-a 将添加新端口标签，-t 表示类型，-p 表示协议。 1[root@localhost ~]\\# semanage port -a -t port_label -p tcp|udp PORTNUMBER ​例如，要允许 gopher 服务侦听端口 71/TCP： 1[root@localhost ~]\\# semanage port -a -t gopher_port_t -p tcp 71 ​要查看对默认策略的本地更改，管理员可以在 semanage 命令中添加 -C 选项。 1234[root@localhost ~]\\# semanage port -l -CSELinux Port Type Proto Port Number......gopher_port_t tcp 71 targeted 策略随附了大量端口类型。在 selinux-policy-doc 软件包中可以找到特定于服务的 SELinux man page，其中包含了有关 SELinux 类型、布尔值和端口类型的文档。如果系统上尚未安装这些 man page，可以避循以下步骤进行安装： 12[root@localhost ~]\\# yum -y install selinux-policy-doc[root@localhost ~]\\# man -k _selinux 删除端口标签 ​删除自定义端口标签的语法与添加端口标签的语法相同，但不是使用 -a 选项（表示添加），而是使用 -d 选项（表示删除）。 ​例如，要删除端口 71/TCP 与 gopher_port_t 的绑定： 1[root@localhost ~]\\# semanage port -d -t gopher_port_t -p tcp 71 修改端口标签 ​要更改端口绑定（可能是因为需求发生改变），可以使用 -m（修改）选项。这种流程比删除旧绑定并添加新绑定更高效。 ​例如，要将端口 71/TCP 从 gopher_port_t 修改为 http_port_t，管理员可以使用以下命令： 1[root@localhost ~]\\# semanage port -m -t http port_t -p tcp 71 ​和以前一样，使用 semanage 命令可以查看修改内容。 12345678910[root@localhost ~]\\# semanage port -l -C SELinux Port Type Proto Port Number......http_port_t tcp 71[root@localhost ~]\\# semanage port -l | grep httphttp_cache_port_t tcp 8080，8118，8123，10001-10010http_cache_port_t udp 3130http_port_t tcp 71，80，81，443，488，8008，8009，8443，9000pegasus_http_port_t tcp 5988pegasus_https_port_t tcp 5989","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"控制启动过程以解决启动问题","slug":"Linux | 控制启动过程以解决启动问题","date":"2022-08-15T07:07:44.559Z","updated":"2022-08-15T07:10:49.640Z","comments":true,"path":"2022-08-15-Linux | 控制启动过程以解决启动问题.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E6%8E%A7%E5%88%B6%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B%E4%BB%A5%E8%A7%A3%E5%86%B3%E5%90%AF%E5%8A%A8%E9%97%AE%E9%A2%98.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 RHEL8 启动过程描述 ​现代计算机系统是硬件与软件的复杂组合。从未定义的断电状态开始，到拥有登录提示符的运行中系统，这需要大量的硬件和软件配合工作。以下列表从较高层面概述了启动红帽企业 Linux 8 的物理 X86_64 系统所涉及的任务。X86_64虚拟机列表大致相同，但某些特定于硬件的步骤是由虚拟机监控程序在软件中处理的。 计算机已接通电源。系统固件（现代 UEFI 或更旧的 BIOS）运行开机自检（POST，并开始初始化部分硬件。 使用系统 BIOS 或 UEFI 配置屏幕【通常在启动过程早期通过按特定的组合键（例如F2）即可进入】进行配置。 系统固件会搜索可启动设备，可能是在 UEFI 启动固件中配置的，也可能按照 BIOS 中配置的顺序搜索所有磁盘上的主启动记录（MBR）。 使用系统 BIOS 或 UEFI 配置屏幕【通常在启动过程早期通过按特定的组合键（例如 F2 ）即可进入】进行配置。 系统固件会从磁盘读取启动加载器，然后将系统控制权交给启动加载器。在红帽企业 Linux 8 系统中，启动加载器为 GRand Unified Boot loader version 2（GRUB2）。 使用 grub2-install 命令进行配置，它将安装 GRUB2 作为磁盘上的启动加载器。 GRUB2 将从 /boot/grub2/grub.cfg 文件加载配置并显示一个菜单，从中可以选择要启动的内核。 使用 /etc/grub.d/ 目录、/etc/default/grub 文件和 grub2-mkconfig 命令进行配置，以生成*/boot/grub2/grub.cfg* 文件。 选择内核或超时到期后，启动加载器会从磁盘中加载内核和 initramfs ，并将它们放入内存中。initramfs是一个存档，其中包含启动时所有必要硬件的内核模块、初始化脚本等等。在红帽企业 Linux8 中，*initramfs 包含自身可用的整个系统。 使用 /etc/dracut.conf.d/ 目录、dracut 命令和 lsinitrd 命令进行配置，以检查initramfs 文件。 启动加载器将控制权交给内核，从而传递启动加载器的内核命令行中指定的任何选项，以及 initramfs 在内存中的位置。 使用 /etc/grub.d/ 目录、/etc/default/grub 文件和 grub2-mkconfig 命令进行配置，以生成 /boot/grubz/grub.cfg 文件。 对于内核可在 initramfs 中找到驱动程序的所有硬件，内核会初始化这些硬件，然后作为 PID 1 从 initramfs 执行 /sbin/init。在红帽企业 Linux8 中，/sbin/init 是一个指向 systemd 的链接。 使用内核 init= 命令行参数进行配置。 initramfs 中的 systemd 实例会执行 initrd.target 目标的所有单元。这包括将磁盘上的 root 文件系统挂载于 /sysroot 目录。 使用 /etc/fstab 进行配置。 内核将 root 文件系统从 initramfs 切换（回转）为 /sysroot 中的 root 文件系统。随后，systemd 会使用磁盘中安装的 systemd 副本来自行重新执行。 systemd 会查找从内核命令行传递或系统中配置的默认目标，然后启动（或停止）单元，以符合该目标的配置，从而自动解决单元间的依赖关系。本质上，systemd 目标是一组系统应激活以达到所需状态的单元。这些目标通常启动一个基于文本的登录或图形登录屏幕。 使用 /etc/systemd/system/default.target 和 /etc/systemd/system/ 进行配置。 重新启动和关闭 ​要关闭或从命令行重新启动正在运行的系统，可以使用 systemctl 命令。 ​systemctl poweroff 会停止所有运行的服务，卸载所有文件系统（或者在文件系统无法卸载时以只读形式将其重新挂载），然后关闭系统。 ​systemctl reboot 会停止所有运行的服务，卸载所有文件系统，然后重新启动系统。您也可以使用这些命令的简短版本poweroff 和 reboot，它们是 systemctl 同等命令的符号链接。 systemctl halt 和 halt 也可以用于停止系统，但与 poweroff 不同，这些命令不会关闭系统，而是让系统进入能安全地手动关闭的状态。 SYSTEMD Target ​systemd target 是一组系统应启动以达到所需状态的 systemd 单元。下表列出了最重要的目标： Target 用途 graphical.target 系统支持多用户、图形和基于文本的登录。 multi-user.target 系统仅支持多用户、基于文本的登录。 rescue.target sulogin 提示，表示基本系统初始化已完成。 emergency.target sulogin 提示，表示 initramfs 回转完成，且系统 root 以只读形式挂载于 / 上。 ​某个目标可能属于另一目标。例如，graphical.target 包含 multi-user.target，后者反过来取决于 basic.target 和其他目标。可以使用以下命令来查看这些依赖项。 123456789101112[user@localhost ~]\\$ systemctl list-dependencies graphical.target | grep targetgraphical.target* ﹂multi-user.target* |-basic.target* | |-paths.target* | |-slices.target* | |-sockets.target* | |-sysinit.target* | | |-cryptsetup.target* | | |-local-fs.target* | | |-swap.target...... ​要列出可用目标，可以使用以下命令： 12345678910[user@localhost ~]\\$ systemctl list-units --type=target --all UNIT LOAD ACTIVE SUB DESCRIPTION ------------------------------------------------------------------------ basic.target loaded active active Basic System cryptsetup.target loaded active active Local Encrypted Volumes emergency.target loaded inactive dead Emergency Mode getty-pre.target loaded inactive dead Login Prompts (Pre) getty.target loaded active active Login Prompts graphical.target loaded inactive dead Graphical Interface ...... 运行时切换 Target 在运行的系统中，系统管理员可以使用 systemctl isolate 命令本来切换到其他目标。 1[root@localhost ~]\\# systemctl isolate multi-user.target ​隔离某个目标会停止该目标（及其依赖项）不需要的所有服务，并启动任何尚未启动的所需服务。但并非所有目标都能隔离，一般只能隔离单元文件中设置了 A11owIsolate=yes 的目标。例如，可以隔离图形目标，但不能隔离 cryptsetup 目标。 1234567891011[user@localhost ~]\\$ systemctl cat graphical.target# /usr/lib/systemd/system/graphical.target......[Unit]Description=Graphical InterfaceDocumentation=man:systemd.special (7）Requires=multi-user.targetWants=display-manager.serviceConflicts=rescue.service rescue.targetAfter=multi-user.target rescue.service rescue.target display-manager.serviceAllowIsolate=yes 123456[user@localhost ~]\\$ systemctl cat cryptsetup.target#/usr/lib/systemd/system/cryptsetup.target......[unit]Description=Local Encrypted VolumesDocumentation=man：systemd，special (7) 设置默认目标 系统启动时，systemd 会激活 default.target 目标。通常，/etc/systemd/system/ 中的默认目标是指向 graphical.target 或 multi-user.target 的符号链接。systemctl 命令提供了两个子命令（get-default 和 set-default）用于管理该符号链接，而不是手动编辑该链接。 1234567[root@localhost ~]\\# systemctl get-defaultmulti-user.target[root@localhost ~]\\# systemctl set-default graphical.targetRemoved /etc/systemd/system/default.target.Created symlink /etc/systemd/system/default.target -&gt; /usr/lib/systemd/system/graphical.target[root@localhost ~]\\# systemctl get-defaultgraphical.target 在启动时选择其他目标 ​要在启动时选择其他目标，请从启动加载器将 systemd.unit=target.target 选项附加到内核命令行。 ​例如，要将系统启动到救援 shell，以便能在几乎没有任何服务运行的情况下更改系统配置，可以在启动加载器将以下选项附加到内核命令行。 1systemd.unit=rescue.target ​该配置更改仅影响单个启动，这使其成为对启动过程进行故障排除的有用工具。 ​要使用这种选择其他目标的方法，可以执行以下步骤： 启动或重新启动系统； 按任意键（Enter 除外，它用于执行正常启动）中断启动加载器菜单倒计时； 将光标移至要启动的内核条目； 按 e 编辑当前条目； 将光标移至以 linux 开头的行 —— 此为内核命令行； 附加 systemd.unit=target.target，例如，systemd.unit=emergency.target； 按 Ctrl + x 使用这些更改进行启动； 重置 ROOT 密码 ​每个系统管理员都应该能完成的一项任务是重置丢失的 root 密码。如果管理员仍处于登录状态，不管是作为拥有完全 sudo 访问权限的非特权用户，还是作为 root 用户，这个任务都很简单。如果管理员未登录，则这个任务变得略微复杂。 ​有几种方法可用于设置新的root密码。例如，系统管理员可以使用 Live CD 启动系统，从此处挂载根文件系统，然后编辑 /etc/shadow。在本节中，我们将探讨一个无需使用外部介质的方法。 从启动加载器重置 ROOT 密码 ​在 RHEL8 中，可以使从 initramfs 运行的脚本在某些点暂停，提供 root shell，然后在该 shell 存在的情况下继续。这主要是为了进行调试，但也可以使用该方法来重置丢失的 root 密码。 ​要访问该 root shell，可以按照以下步骤进行操作： 重新启动系统。 按任意键（Enter除外）中断启动加载器倒计时。 将光标移至要启动的内核条目。 按 e 编辑选定的条目。 将光标移到内核命令行（以linux开头的行）。 附加 rd.break。利用该选项，就在系统从 initramfs 向实际系统移交控制权前，系统将会中断。 按 Ctrl + x 使用这些更改进行启动。 ​此时，系统会显示 root shell，且磁盘上的实际根文件系统会在 /sysroot 中以只读方式挂载。由于进行故障排除经常要求修改根文件系统，因此需要将根文件系统更改为读/写模式。以下步骤说明在对 mount 命令使用 remount,rw 选项的情况下，如何利用所设置的新选项（rw）重新挂载文件系统。 预建的映像可能会在内核中放置多个 console= 参数，以便支持各种各样的实施场景。这些 console= 参数指示了用于控制台输出的设备。对于 rd.break，有一点需要注意的是，尽管系统会将内核消息发送给所有控制台，但提示符最终将使用最后提供的控制台。如果未获得提示符，在从启动加载器编辑内核命令行时，可能需要临时对 console= 参数重新进行排序。 系统尚未启用 SELinux，因此您所创建的任何文件都没有 SELinux 上下文。有些工具（例如 passwd 命令）首先会创建一个临时文件，然后移动新文件以代替要编辑的文件，从而有效地创建不带 SELinux 上下文的新文件。因此，当对 passwd 命令使用 rd.break 时，/etc/shadow 文件并没有获得 SELinux 上下文。 ​要在此时重置 root 密码，可以执行以下步骤： 以 读/写 形式重新挂载 /sysroot； 1switch_root:/\\# mount -o remount,rw /sysroot 切换为 chroot 存放位置，其中 /sysroot 被视为文件系统树的根； 1switch_root:/\\# chroot /sysroot 设置新 root 密码； 1sh-4.4\\# passwd root 确保所有未标记的文件（包括此时的 /etc/shadow）在启动过程中都会重新获得标记； 1sh-4.4\\# touch /.autorelabel 键入 exit 命令并执行两次，分别退出 chroot 和 initramfs shell。 ​此时，系统将继续进行启动，执行完整的SELinux重新标记，然后再次重新启动。 检查日志来排除启动问题 ​查看以前启动失败时的日志会很有用。如果系统日志在重启后持久保留，则可以使用 journalctl 工具来检查这些日志。 ​需注意，默认情况下，系统日志保存在 /run/1og/journal 目录中，这意味着系统重启时这些日志会被清除。要将日志存储在 /var/log/journal 目录中（可在系统重启后持久保留），请在 /etc/systemd/journald.conf 中将 Storage 参数设置为 persistent。 123456[root@localhost ~]\\# vim /etc/systemd/journald.conf......[Journal]Storage=persistent......[root@localhost ~]\\# systemctl restart systemd-journal.service ​要检查上一次启动的日志，请对 journalctl 使用 -b 选项。如果不使用任何参数，-b 选项将仅显示从上一次启动以来的消息。如果参数为负数，则显示以前的启动的日志。 1[root@localhost ~]\\# journalctl -b -1 -p err ​该命令将显示上一次启动中被评为错误或更严重级别的所有消息。 修复 SYSTEMD 启动问题 ​为了在启动时对服务启动问题进行故障排除，红帽企业 Linux 8 提供了以下工具。 启用早期调试 Shell ​通过执行 systemctl enable debug-shell.service 来启用 debug-shell 服务，系统会于启动序列早期在 TTY9（使用ctrl + Alt + F9 切换）上生成一个 root shell。该 shell 会自动作为 root 登录，这样，管理员可以在操作系统仍在启动时对系统进行调试。 在完成调试后务必要禁用 debug-shell 服务。 使用紧急情况和救援目标 ​通过从启动加载器将 systemd.unit=rescue.target 或 systemd，unit=emergency.target 附加到内核命令行，系统将生成救援或紧急情况 shell，而不是正常启动。这两个 shell 都需要提供 root 密码。 ​紧急情况目标使 root 文件系统以只读方式挂载，而救援目标会等待 sysinit.target 完成，这样系统的更多部分会进行初始化，如日志记录服务或文件系统。此时 root 用户无法更改 /etc/fstab，直至驱动器以读写状态重新挂载（mount -o remount,rw /）。 ​管理员可以使用这些 shell 来修复坊碍系统正常启动的任何问题；例如，服务之间的依赖关系循环，或 /etc/fstab 中的错误条目。从这些 shell 退出后，系统会继续进行常规启动过程。 识别阻塞作业 ​在启动过程中，systemd 会生成大量作业。如果其中其些作业无法完成，则它们会纺碍其他作业运行。要检查当前作业列表，管理员可以使用 systemctl 1ist-jobs 命令。所有列为 running 的作业都必须先完成，然后列为 waiting 的作业才可以继续。 修复启动时出现的文件系统问题 ​*/etc/fstab* 中的错误和损坏的文件系统可能会阻止系统启动。在大多数情况下，systemd 会降 至需要提供 root 密码的紧急修复 shell。 ​下表列出了一些常见错误及其结果。 问题 结果 损坏文件系统 systemd 尝试修复文件系统。如果问题过于严重，无法进行自动修复，系统会将用户降至紧急 shell。 /etc/fstab 中引用的设备UUID 不存在 systemd 将等待一定的时间，等设备变得可用。如果设备未变得可用，则系统会在超时后将用户降至紧急 shell。 /etc/fstab 中的挂载点不存在 系统将用户降至紧急 shell。 /etc/fstab 中指定的挂载点错误 系统将用户降至紧急 shell。 ​在所有情况下，管理员还都可以使用 emergency.target 来诊断和修复问题，因为在显示紧急 shell 之前，不会挂载任何文件系统。 使用紧急 shell 解决文件系统问题时，别忘了在编辑 /etc/fstab 之后运行 systemctl daemon-reload。如果不重新加载，systemd 可能会继续使用旧版本。 ​在 /etc/fstab 文件中，条目内的 nofail 选项允许在该文件系统挂载不成功的情况下仍启动系统。正常情况下，请勿使用该选项。使用 nofail 时，应用可以从缺失的存储启动，这可能会带来严重后果。","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"访问网络附加存储","slug":"Linux | 访问网络附加存储","date":"2022-08-15T07:03:27.839Z","updated":"2022-08-15T07:06:15.091Z","comments":true,"path":"2022-08-15-Linux | 访问网络附加存储.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E8%AE%BF%E9%97%AE%E7%BD%91%E7%BB%9C%E9%99%84%E5%8A%A0%E5%AD%98%E5%82%A8.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 挂载和卸载 NFS 共享 ​NFS（网络文件系统）是由Linux、UNIX及类似操作系统使用的互联网标准协议，可作为它们的本地网络文件系统。它是一种仍在积极增强的开放标准，可支持本地Linux权限和文件系统功能。 ​红帽企业 Linux 8 中的默认 NFS 版本为 4.2 。支持NFSV4和NFSV3的主要版本。NFSV2 已不再受支持。NFSV4 仅使用TCP 协议与服务器进行通信；较早的 NFS 版本可使用 TCP 或 UDP。 ​NFS 服务器导出共享（目录）。NFS 客户端将导出的共享挂载到本地挂载点（目录），该挂载点必须存在。可以通过多种方式挂载 NFS 共享： 使用 mount 命令手动挂载； 使用 /etc/fstab 条目在启动时自动挂载； 按需挂载：使用 autofs 服务或 systemd.automount 功能。 挂载 NFS 共享 ​要挂载 NFS 共享，可以执行以下三个步骤： 识别：NFS 客户端系统的管理员可以通过各种方式识别可用的 NFS 共享 NFS 服务器的管理员可以提供导出详细信息，包括安全性要求。 或者，客户端管理员可以通过挂载 NFS 服务器的根目录并浏览已导出目录来识别 NFSV4 共享。以 root 用户身份执行该操作。对使用 Kerberos 安全性的共享的访问将被拒绝，但共享（目录）名称仍可见。可以浏览其他共享目录。 123[user@localhost ~]\\$ sudo mkdir mountpoint[user@localhost ~]\\$ sudo mount serverb:/ mountpoint[user@localhost ~]\\$ sudo ls mount point 挂载点：使用 mkdir 在合适的位置创建挂载点 1[user@localhost ~]\\$ mkdir -p mountpoint 挂载：与分区上的文件系统一样，NFS 共享必须先进性挂载才可用。要挂载 NFS 共享，可以从以下选项中进行选择。无论在哪种情况下，都必须作为 root 用户登陆，或使用 sudo 命令，以超级用户身份运行这些命令。 临时挂载：使用 mount 命令挂载 NFS 共享： 1[user@localhost ~]\\$ sudo mount -t nfs -o rw,sync serverb:/share mountpoint ​*-t nfs* 选项是 NFS 共享的文件系统类型（未严格要求，为完整性而显示）。-o sync 选项使 mount 立即与 NFS 服务器同步写操作（默认值为异步）。 ​此命令将立即但并不持久挂载共享；下一次系统启动时，此NFS共享将不可用。对于一次性访问数据的情况，该选项很有用。它也可用于在持久提供共享之前对挂载NFS共享进行测试。 持久挂载：为了确保在启动时挂载 NFS 共享，可以编辑 /etc/fstab 文件来添加挂载条目。 123[user@localhost ~]\\$ sudo vim /etc/fstab# 以下是 /etc/fstab 文件条目serverb:/share /mountpoint nfs rw,soft 0 0 ​接着，挂载 NFS 共享： 1[user@localhost ~]\\$ sudo mount /mountpoint ​由于 NFS 客户端服务会在 /etc/fstab 文件中查找 NFS 服务器和挂载选项，因此您无需在命令行中指定这些内容。 卸载 NFS 共享 ​以 root 用户身份（或使用 sudo），使用 umount 命令卸载 NFS 共享。 1[user@localhost ~]\\$ sudo umount mountpoint 卸载共享不会删除它的 /etc/fstab 条目。除非删除或注释掉该条目，否则在下一次系统启动或重启 NFS 客户端服务时将重新挂载 NFS 共享。 NFSCONF 工具 ​RHEL8 引入了 nfsconf 工具，用于管理 NFSv4 与 NFSv3 下的 NFS 客户端和服务器配置文件。使用 /etc/nfs.conf配置 nfsconf 工具（早期版本的操作系统中的 /etc/sysconfig/nfs文件现已被弃用）。使用 nfsconf 工具来获取、设置或取消设置NFS配置参数。 ​*/etc/nfs.conf* 配置文件由多个部分组成，它的开头是一个位于方括号中的关键字（[keyword]）以及这一部分的值分配。对于 NFS 服务器，请配置 [nfsd] 部分。值的分配（或键）由值的名称、等号和值的设置组成，例如 vers4.2=y。以 “#” 或 “;” 开头的行将被忽略，就像空白行一样。 1[user@localhost ~]\\$ sudo cat /etc/nfs.conf 12345678910111213141516[nfsd]# debug=0# threads=0# host=# port=0# grace-time=90# lease-time=90# tcp=y# vers2=n# vers3=y# vers4=y# vers4.0=y# vers4.1=y# vers4.2=y# rdma=n# ...... ​默认情况下，[nfsd] 部分的键值对会被注释掉。不过，注释中会显示在不做更改的情况下将会生效的默认选项。这为配置 NFS 提供了很好的起点。 ​使用 nfsconf --set section key value 来设置指定部分的键值。 1[user@localhost ~]\\$ sudo nfsconf --set nfsd vers4.2 y ​此命令将更新 /etc/nfs.conf 配置文件： 1[user@localhost ~]\\$ sudo cat /etc/nfs.conf 1234[nfsd]# ......vers4.2 = y# ...... ​使用 nfsconf --get section key 来检索指定部分的键值： 12[user@localhost ~]\\$ sudo nfsconf --get nfsd vers4.2y ​使用 nfsconf --unset section key 来取消设置指定部分的键值： 1[user@localhost ~]\\$ sudo nfsconf --unset nfsd vers4.2 配置一个仅限使用 NFSv4 的客户端 ​通过在 /etc/nfs.conf 配置文件中设置以下值，可以配置一个仅限使用 NFSv4 的客户端。 ​首先禁用 UDP 以及其他与 NFSv2 和 NFSv3 有关的键： 123[user@localhost ~]\\$ sudo nfsconf --set nfsd udp n[user@localhost ~]\\$ sudo nfsconf --set nfsd vers2 n[user@localhost ~]\\$ sudo nfsconf --set nfsd vers3 n ​启用 TCP 和 NFSv4 相关键： 12345[user@localhost ~]\\$ sudo nfsconf --set nfsd tcp y[user@localhost ~]\\$ sudo nfsconf --set nfsd vers4 y[user@localhost ~]\\$ sudo nfsconf --set nfsd vers4.0 y[user@localhost ~]\\$ sudo nfsconf --set nfsd vers4.1 y[user@localhost ~]\\$ sudo nfsconf --set nfsd vers4.2 y ​和以前一样，/etc/nfs.conf 配置文件中会显示所做的更改： 1[user@localhost ~]\\$ cat /etc/nfs.conf 12345678910[nfsd]udp = nvers2 = nvers3 = ntcp = yvers4 = yvers4.0 = yvers4.1 = yvers4.2 = y# ...... 自动挂载网络附加存储 使用自动挂载器挂载 NFS 共享 ​自动挂载器是一种服务（autofs），它可以 “根据需要” 自动挂载NFS共享，并将在不再使用 NFS 共享时自动卸载这些共享。 ​自动挂载服务的优势： 用户无需具有root特权就可以运行 mount 和 umount 命令。 自动挂载器中配置的 NFS 共享可供计算机上的所有用户使用，受访问权限约束。 NFS 共享不像 /etc/fstab 中的条目一样永久连接，从而可释放网络和系统资源。 自动挂载器在客户端配置，无需进行任何服务器端配置。 自动挂载器与 mount 命令使用相同的选项，包括安全性选项。 自动挂载器支持直接和间接挂载点映射，在挂载点位置方面提供了灵活性。 autofs 可创建和删除间接挂载点，从而避免了手动管理。 NFS 是默认的自动挂载器网络文件系统，但也可以自动挂载其他网络文件系统。 autofs 是一种服务，其管理方式类似于其他系统服务。 配置自动挂载 NFS 共享 ​配置自动挂载包含以下步骤： 安装 autofs 软件包； 1[user@localhost ~]\\$ sudo yum install autofs ​此软件包包含使用自动挂载器挂载NFS共享所需的所有内容。 向 /etc/auto.master.d 添加一个主映射文件。此文件确定用于挂载点的基础目录，并确定用于创建自动挂载的映射文件； 1[user@localhost ~]\\$ sudo vim /etc/auto.master.d/demo.autofs ​主映射文件的名称是任意的（尽管通常会有一定的含意），但为了让子系统能够识别，它必须以 .autofs 作为扩展名。可以在一个主映射文件中放置多个条目；或者可以创建多个主映射文件，且每个文件的条目都进行逻辑分组。 ​在此例中，为简介映射的挂载添加主映射条目： 1/shares /etc/auto.demo 创建映射文件。每个映射文件确定一组自动挂载的挂载点、挂载选项及挂载的源位置； 1[user@localhost ~]\\$ sudo vim /etc/auto.demo ​映射文件的命名规则是 /etc/auto.name, 其中 name 反映了映射内容。 1work -rw,sync serverb:/shares/work ​条目的格式为挂载点、挂载选项和源位置。此示例显示基本的间接映射条目。本节稍后部分将讨论直接映射和使用通配符的间接映射。 挂载点在 man page 被称为 “密钥”，它由 autofs 服务自动创建和删除。在此例中，完全限定挂载点是 /shares/work（请参阅主映射文件）。autofs 服务将根据需要创建和删除 /shares 目录和 /shares/work 目录。 在此例中，本地挂载点将镜像服务器的目录结构，但这不是必需的；本地挂载点可以随意命名。autofs 服务不会在客户端上强制执行特定的命名结构。 挂载选项以短划线字符 - 开头，并使用逗号分隔，不带空格。自动挂载时，可以使用相应的挂载选项来手动挂载文件系统。在此例中，自动挂载器将挂载具有读/写访问权限的共享内容（rw选项），并且在写入操作期间服务器会立即同步（sync 选项）。 有用的自动挂载器特定选项包括 -fstype= 和 -strict。使用 fstype 指定文件系统类型，如 nfs4 或 xfs；挂载文件系统时，使用 strict 可将错误视为严重。 NFS 共享的源位置遵循 host:/pathname 模式；在此示例中为 serverb:/shares/work。为了确保此次自动挂载成功，NFS 服务器 serverb 必须以读/写访问权限导出目录，而请求访问的用户必须对该目录具有标准 Linux 文件权限。如果 serverb 以只读访问权限导出目录，那么客户端也仅获得只读访问权限，即使它要求读/写访问权限。 启动并启用自动挂载器服务； 使用 systemctl 启动并启用 autofs 服务。 12[user@localhost ~]\\$ sudo systemctl enable --now autofsCreated symlink /etc/systemd/system/multi-user.target.wants/autofs.service -&gt; /usr/lib/systemd/system/autofs.service. 直接映射 ​直接映射用于将NFS共享映射到现有的绝对路径挂载点。 ​要使用直接映射的挂载点，主映射文件可能如下所示： 1/- /etc/auto.direct ​所有直接映射条目都使用 /- 作为基础目录。在此例中，包含挂载详细信息的映射文件是 /etc/auto,direct。 ​*/etc/auto.direct* 文件的内容可能如下所示： 1/mnt/docs -rw,sync serverb:/shares/docs ​挂载点（或密钥）始终为绝对路径。映射文件的其余部分使用相同的结构。 ​在此例中，存在 /mnt 目录，它由 autofs 管理。autofs 服务将自动创建和删除整个 /mnt/docs 目录。 间接通配符映射 ​当NFS服务器导出一个目录中的多个子目录时，可将自动挂载程序配置为使用单个映射条目访问这些子目录其中的任何一个。 ​继续前面的示例，如果 serverb:/shares 导出两个或多个子目录，并且能够使用相同的挂载选项访问这些子目录，则 /etc/auto.demo 文件的内容可能如下所示： 1* -rw,sync serverb:/shares/&amp; ​挂载点（或密钥）是星号字符 *，而源位置上的子目录是 &amp; 符号。条日中的所有其他内容都相同。 ​当用户尝试访问 /shares/work 时，密钥 *（此例中为 work ）将代替源位置中的 &amp; 符号，并挂载 serverb:/shares/work。对于间接示例，autofs 将自动创建和删除 work 目录。","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"使用 Stratis 管理分层存储","slug":"Linux | 使用 Stratis 管理分层存储","date":"2022-08-15T06:50:24.466Z","updated":"2022-08-15T07:01:55.282Z","comments":true,"path":"2022-08-15-Linux | 使用 Stratis 管理分层存储.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E4%BD%BF%E7%94%A8%20Stratis%20%E7%AE%A1%E7%90%86%E5%88%86%E5%B1%82%E5%AD%98%E5%82%A8.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 STRATIS 架构概述 ​RHEL 当前的本地存储解决方案中包含许多成熟、稳定的技术，其中包括设备映射器（dm）、逻辑卷管理器（LVM）及 XFS 文件系统。这些组件提供的功能包括可大规模扩展的文件系统、快照、冗余（RAID）逻辑设备、多路径、精简配置、缓存、重复数据删除，以及对虚拟机和容器的支持。每个存储堆栈层（dm、LVM 和 XFS）均使用专门面向层的命令和实用程序进行管理，这就要求系统管理员将物理设备、固定大小的卷和文件系统作为独立的存储组件进行管理。 ​在 RHEL 8 中，红帽推出了 Stratis 存储管理解决方案。Straits 以管理物理存储设备池的服务形式运行，并透明地为所创建的文件系统创建和管理卷。由于 Stratis 使用现有的存储驱动程序和工具，因此 Stratis 也支持当前在 LVM、XFS 和设备映射器中使用的所有高级存储功能。 ​在卷管理文件系统中，文件系统借助一个名为精简配置的概念内置于磁盘设备的共享池中。Straits 文件系统没有固定大小，也不再预分配未使用的快空间。尽管文件系统仍构建在隐藏的 LVM 卷上，但 Stratis 会管理基础卷，并可在需要时对其进行扩展。文件系统的 “使用中” 大小可视作所含文件占用的实际块数量。文件系统的可用空间就是它所驻留的池设备中仍未使用的空间量。多个文件系统可以驻留在同一磁盘设备池中，共享可用空间，但文件系统也可以保留池空间，以便在需要时保证可用性。 ​Straitis 使用存储的元数据来识别所管理的池、卷和文件系统。因此，绝不应该对 Stratis 创建的文件系统进行手动重新格式化或重新配置；只应使用 Straitis 工具和命令对它们进行管理。手动配置 Stratis 文件系统可能会导致该元数据丢失，并阻止 Stratis 识别它已创建的文件系统。 ​可以使用不同组的块设备来创建多个池。在每个池中，可以创建一个或多个文件系统。目前，每个池最多可以创建 224 个文件系统。下图说明了 Stratis 存储管理解决方案的元素是如何定位的。 ​存储池可将块设备分组到数据层，或分组到缓存层。数据层侧重于灵活性和完整性，而缓存层则侧重于提高性能。由于缓存层旨在提高性能，因此应使用具有更高每秒输入、输出操作次数（IOPS）的块设备，如 SSD。 ​在内部，Stratis 使用 Backstore 子系统来管理块设备，并使用 Thinpool 子系统来管理池。Backstore 有一个数据层，负责维护块设备磁盘上的元数据，以及检测和纠正数据损坏。缓存层使用高性能块设备，作为数据层之上的缓存。Thinpool 子系统管理与 Straitis 文件系统关联的精简部署卷。该子系统使用 dm-thin 设备映射器驱动程序取代 LVM 进行虚拟卷大小调整和管理。dm-thin 可以创建虚拟大小比较大、采用 XFS 格式，但物理大小比较小的卷。当物理大小快要满时，Stratis 会自动将其扩大。 管理精简配置的文件系统 ​要使用 Stratis 存储管理解决方案来管理精简配置的文件系统，可以安装 stratis-cli 和 stratisd 软件包。stratis-cli 软件包中提供了 stratis 命令，它通过 D-Bus API 将用户请求转换为 stratisd 服务。stratisd 软件包中提供了 stratisd 服务，它实现 D-Bus 接口并管理和监控 Stratis 的元素，如块设备、池和文件系统。当 stratisd 服务处于运行状态时，可以使用 D-Bus API。 ​使用常用工具安装并激活 Stratis： 使用 yum install 命令安装 stratis-cli 和 stratisd； 12345[root@localhost ~]\\# yum install stratis-cli stratisd......Is this ok [y/N]: y......complete! 使用 systemctl 命令激活 stratisd 服务； 1[root@localhost ~]\\# systemctl enable --now stratisd ​使用 stratis 存储管理解决方案执行常见管理操作： 使用 stratis pool create 命令来创建包含一个或多个块设备的池； 1[root@localhost ~]\\# stratis pool create pool1 /dev/vdb ​每个池都是 /stratis 目录下的一个子目录。使用 stratis pool list 命令查看可用池的列表： 123[root@localhost ~]\\# stratis pool listName Total Physical Size Total Physical Usedpool1 5 GiB 52 MiB 使用 stratis pool add-data 命令向池中添加额外的块设备； 1[root@localhost ~]\\# stratis pool add-data pool1 /dev/vdc ​使用 stratis pool list 命令查看可用池的块设备： 1234[root@localhost ~]\\# stratis pool list pool1Pool Name Device Node Physical Size State Tierpool1 /dev/vdb 5 GiB In-use Datapool1 /dev/vdc 5 GiB In-use Data 使用 stratis filesystem create 命令为池创建动态、灵活的文件系统； 1[root@localhost ~]\\# stratis filesystem create pool1 filesystem1 ​Stratis 文件系统的链接位于 /stratis/pool1 目录中。 Stratis 支持通过 stratis filesystem snapshot 命令创建文件系统快照。快照独立于源文件系统。 1[root@localhost ~]\\# stratis filesystem snapshot pool1 filesystem1 snapshot1 使用 stratis filesystem list 命令查看可用文件系统的列表。 12[root@localhost ~]\\# stratis filesystem list...... ​为了确保持久挂载 Stratis 文件系统，请编辑 /etc/fstab 并指定文件系统的详细信息。以下命令显示文件系统 UUID，在 /etc/fstab 中应使用该 UUID 来识别文件系统。 12[root@localhost ~]\\# lsblk --output=UUID /stratis/pool1/filesystem1UUID 31b9363b-add8-4b46-a4bf-c199cd478c55 ​以下是 /etc/fstab 文件中用于持久挂载 Stratis 文件系统的条目示例。 1UUID=31b9363b-add8-4b46-a4bf-c199cd478c55 /dir1 xfs defaults,x-systemd.requires=stratisd.service 0 0 ​x-systemd.requires=stratisd.service 挂载选项可延迟挂载文件系统，直到 systemd 在启动过程中启动 stratisd.service 为止。 如果在 /etc/fstab 中未对 stratis 文件系统使用 x-systemd.requires=stratisd.service 挂载选项，将会导致计算机在下一次重启时引导至 emergency.target。 使用 VDO 压缩存储和删除重复数据 ​红帽企业 Linux8 包含虚拟数据优化器（VDO）驱动程序，可以优化块设备上数据的空间占用。VDO 是一个 Linux 设备映射器驱动程序，它可以减少块设备上的磁盘空间使用，同时最大限度减少数据重复，从而节省磁盘空间，甚至提高数据吞吐量。VDO 包括两个内核模块：kvdo 模块用于以透明的方式控制数据压缩，uds 则可用于重复数据删除。 ​VDO 层位于现有块存储设备（如 RAID设备或本地磁盘）的顶部。这些块设备也可以是加密设备。存储层（如 LVM逻辑卷和文件系统）位于 VDO 设备之上。下图显示了在一个由使用优化存储设备的 KVM 虚拟机构成的基础架构中，VDO 所处的位置。 ​VDO 会按以下顺序对数据实施三个阶段的处理，以减少存储设备上的空间占用： 零块消除将过滤掉仅包含零（0）的数据块，且仅在元数据中记录这些块的信息。非零数据块随即被传递到下一个处理阶段。该阶段将启用VDO设备中的精简配置功能。 重复数据删除将去除几余的数据块。在创建相同数据的多个副本时，VDO 会检测重复数据块并更新元数据，以便使用这些重复块来引用原始数据块，而不会创建几余数据块。通用重复数据删除服务（UDS）内核模块将通过其维护的元数据来检查数据的几余。该内核模块是作为 VDO 的一部分而提供的。 最后一个阶段是压缩。kvdo 内核模块使用 LZ4 压缩对块进行压缩，并以 4KB 块进行分组。 实施虚拟数据优化器 ​利用 VDO 创建的逻辑设备被称为 VDO 卷。VDO 卷与磁盘分区类似；您可以将这些卷格式化为所需的文件系统类型，并像常规文件系统那样进行挂载。此外，您还可以将 VDO 卷用作LVM物理卷。 ​要创建 VDO 卷，请指定块设备以及 VDO 向用户显示的逻辑设备的名称。您可以指定 VDO 卷的逻辑大小（可选）。VDO 卷的逻辑大小可以大于实际块设备的物理大小。 ​由于 VDO 卷采用了精简配置，因此用户只能看到正在使用的逻辑空间，而无法了解实际可用的物理空间。如果在创建卷时未指定逻辑大小，则 VDO 会将实际物理大小视为卷的逻辑大小。这种采用 1:1 的比率映射逻辑大小与物理大小的方式有利于提高性能，但同时也会降低存储空间的使用效率。应根据您的基础架构要求来确定是优先考虑性能还是空间效率。 ​当 VDO 卷的逻辑大小超过实际物理大小时，应使用 vdostats--verbose 命令主动监控卷统计信息，以查看实际使用情况。 启用 VDO ​安装 VDO 和 kmod 软件包，以便在系统中启用 VDO。 12345[root@localhost ~]\\# yum install vdo kmod-kvdo......Is this ok [y/N]: y......complete! 创建 VDO ​要创建 VDO 卷，请运行 vdo create 命令。 12[root@localhost ~]\\# vdo create --name=vdo1 --device=/dev/vdd --vdoLogicalSize=50G...... ​如果省略逻辑大小，则生成的VDO卷将与其物理设备的大小相同。 ​当 VDO 卷就位时，可以将它格式化为所选的文件系统类型并挂载于系统的文件系统层次结构下。 分析 VDO 卷 ​要分析 VDO 卷，请运行 vdostatus 命令。此命令将以 YAML 格式显示有关 VDO 系统的报告以及 VDO 卷的状态。此外，它还显示 VDO 卷的属性。使用 --name= 选项可指定特定卷的名称。如果省略特定卷的名称，vdostatus 命令的输出中将显示所有VDO卷的状态。 12[root@localhost ~]\\# vdo status --name=vdo1...... ​vdolist 命令显示当前启动的 VDO 卷的列表。您可以分别使用 vdostart 和 vdostop 命令来启动和停止 VDO 卷。","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"管理逻辑卷","slug":"Linux | 管理逻辑卷","date":"2022-08-15T06:42:07.887Z","updated":"2022-08-15T06:48:49.165Z","comments":true,"path":"2022-08-15-Linux | 管理逻辑卷.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E7%AE%A1%E7%90%86%E9%80%BB%E8%BE%91%E5%8D%B7.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 逻辑卷管理 (LVM) 概述 ​逻辑卷和逻辑卷管理有助于更加轻松地管理磁盘空间。如果托管逻辑卷的文件系统需要更多空间，可以将其卷组中的可用空间分配给逻辑卷，并且可以调整文件系统的大小。如果磁盘开始出现错误，可以将替换磁盘注册为物理卷放入卷组中，并且逻辑卷的区块可迁移到新磁盘。 LVM 概念 定义 物理设备 物理设备是用于保存逻辑卷中所存储数据的存储设备。它们是块设备，可以是磁盘分区、整个磁盘、RAID 阵列或 SAN 磁盘。设备必须初始化为 LVM 物理卷，才能与 LVM 结合使用。整个设备将用作一个物理卷。 物理卷（PV） 在 LVM 系统中使用设备之前，必须将设备初始化为物理卷。LVM 工具会将物理卷划分为物理区块（PE），它们是充当物理卷上最小存储块的小块数据。 卷组（VG） 卷组是存储池，由一个或多个物理卷组成。它在功能上与基本存储中的整个磁盘相当。一个 PV 只能分配给一个 VG。VG 可以包含未使用的空间和任意数目的逻辑卷。 逻辑卷（LV） 逻辑卷根据卷组中的空闲物理区块创建，提供应用、用户和操作系统所使用的 “存储” 设备。LV 是逻辑区块（LE）的集合，LE 映射到物理区块（PV 的最小存储块）。默认情况下，每个 LE 将映射到一个 PE。设置特定 LV 选项将会更改此映射；例如，镜像会导致每个 LE 映射到两个 PE。 实施 LVM 存储 ​创建 LVM 存储需要几个步骤。第一步是确定要使用的物理设备。在组装完一组合适的设备之后，系统会将它们初始化为物理卷，以便将它们识别为属于 LVM。这些物理卷随机被合并到卷组中。此时将会创建一个磁盘空间池，从中可以分配逻辑卷。利用卷组的可用空间创建的逻辑卷可以格式化为文件系统、作为交换空间激活，也可以实现持久挂载或激活。 ​LVM 提供了一组全面的命令行工具，用于实施和管理 LVM 存储。这些命令行工具可用在脚本中，从而使它们更适于自动化。 创建逻辑卷 ​创建逻辑卷的步骤如下： 准备物理设备 ​使用 parted、gdisk 或 fdisk 创建新分区，以便与 LVM 结合使用。在 LVM 分区上，始终将分区类型设置为 Linux LVM；对于 MBR 分区，使用 0x8e。如有必要，使用 partprobe 向内核注册新分区。 ​也可以使用完整磁盘、RAID 阵列或 SAN 磁盘。 ​只有当没有已准备好的物理设备并且需要需要新物理卷来创建或扩展卷组时，才需要准备物理设备。 1234[root@localhost ~]\\# parted -s /dev/nvme1n0 mkpart primary 1MiB 769MiB[root@localhost ~]\\# parted -s /dev/nvme1n0 mkpart primary 770MiB 1026MiB[root@localhost ~]\\# parted -s /dev/nvme1n0 mkpart set 1 lvm on[root@localhost ~]\\# parted -s /dev/nvme1n0 mkpart set 2 lvm on 创建物理卷 ​使用 pvcreate 将分区（或其他物理设备）标记为物理卷。pvcreate 命令会将物理卷分成若干固定大小的物理区块（PE），如 4MiB 块。 1[root@localhost ~]\\# pvcreate /deb/nvme0n1p2 /dev/nvme0n1p1 ​此命令会将设备 /dev/nvme0n1p2 和 /dev/nvme0n1p1 标记为 PV，准备好分配到卷组中。 ​仅当没有空闲的 PV 可以创建或扩展 VG 时，才需要创建 PV。 创建卷组 ​使用 vgcreate 将一个或多个物理卷结合为一个卷组。卷组在功能上与硬盘相当；利用卷组中的可用物理区块池可以创建逻辑卷。 ​vgcreate 命令行由卷组名后跟一个或多个要分配给此卷组的物理卷组成。 1[root@localhost ~]\\# vgcreate vg01 /dev/nvme0n1p1 /dev/nvme0n1p2 ​此命令将创建名为 vg01 的 VG，他的大小是 /dev/nvme0n1p1 和 /dev/nvme0n1p2 两个 PV 的大小之和（以 PE 单位计）。 ​仅当 VG 尚不存在时，才需要创建 VG。可能会出于管理原因创建额外的 VG，用于管理 PV 和 LV 的使用。否则，可在需要时扩展现有 VG 以容纳新的 LV。 创建逻辑卷 ​使用 lvcreate 可根据卷组中的可用物理区块创建新的逻辑卷。lvcreate 命令中至少包含用于设置 LV 名称的 -n 选项、用于设置 LV 大小（以字节为单位）的 -L 选项或用于设置 LV 大小（以区块数为单位）的 -l 选项，以及托管此逻辑卷的卷组的名称。 1[root@localhost ~]\\# lvcreate -n 1v01 -L 700M vg01 ​这会在 VG vg01 中创建一个名为 lv01、大小为 700 MiB 的LV。针对所请求的大小，如果卷组没有足够数量的可用物理区块，此命令将失败。另外请注意，如果大小无法完全匹配，则将四舍五入为物理区块大小的倍数。 ​您可以使用 -L 选项来指定大小，它预期大小单位为字节、兆字节（二进制兆字节，1048576 字节）、千兆字节（二进制千兆字节）等等。或者，您可以使用 -l 选项，它预期大小指定为若干物理区块。 ​以下列表提供了一些创建 LV 的示例： lvcreate -L 128M：将逻辑卷的大小确定为正好 128MiB。 lvcreate -l 128：将逻辑卷的大小确定为正好 128 个区块。字节总数取决于基础物理卷上物理区块块的大小。 不同的工具将使用传统名称 /dev/vgname/lvname 或内核设备映射程序名 /dev/mapper/vgname-lvname，显示逻辑卷名。 添加文件系统 使用 mkfs 在新逻辑卷上创建 xfs 文件系统。或者，根据首选文件系统创建文件系统，例如 ext4。 1[root@localhost ~]\\# lvcreate -n 1v01 -L 700M vg01 ​要使文件系统在重新启动后依然可用，可以执行以下步骤： 使用 mkdir 创建挂载点。 1[root@localhost ~]\\# mkdir /mnt/data 向 /etc/fstab 文件中添加以下条目： 1/dev/vg01/lv01 /mnt/data xfs defaults 1 2 按名称挂载逻辑卷等同于按 UUID 进行挂载，因为即使最初按名称将它们添加到卷组中，LVM 也会根据 UUID 查找物理卷。 执行 mount /mnt/data，挂载刚刚在 /etc/fstab 中添加的文件系统。 1[root@localhost ~]\\# mount /mnt/data 删除逻辑卷 ​删除逻辑卷的步骤如下： 准备文件系统 ​将必须保留的所有数据移动到另一个文件系统。使用 umount 命令卸载文件系统，然后删除与该文件系统关联的所有 /etc/fstab 条目。 1[root@localhost ~]\\# umount /mnt/data 此操作会破坏所存储的数据，一定要注意备份或移动数据。 删除逻辑卷 ​使用 lvremove DEVICE_NAME 删除不再需要的逻辑卷。 1[root@localhost ~]\\# lvremove /dev/vg01/lv01 ​运行此命令之前，卸载 LV 文件系统。在删除 LV 之前，该命令会提示进行确认。LV 的物理区块会被释放，并可用于分配给卷组中的现有 LV 或新 LV。 删除卷组 ​使用 vgremove VG_NAME 删除不再需要的卷组。 1[root@localhost ~]\\# vgremove vg01 ​VG 的物理卷会被释放，并可用于分配给系统中的现有 VG 或新 VG。 删除物理卷 ​使用 pvremove 删除不再需要的物理卷。使用空格分隔的 PV 设备列表同时删除多个 PV。此命令将从分区（或磁盘）中删除 PV 元数据。分区现已空闲，可重新分配或重新格式化。 1[root@localhost ~]\\# pvremove /dev/nvme0n1p2 /dev/nvmen1p1 查看 LVM 状态信息 物理卷 ​使用 pvdisplay 显示有关物理卷的信息。要列出有关所有物理卷的信息，可以使用不带参数的命令。要列出有关特定物理卷的信息，可以将相应的设备名称传给该命令。 123456789101112131415161718192021[root@localhost ~]\\# vgdisplay vg01--- Volume group ---VG Name vg01System IDFormat lvm2Metadata Areas 2Metadata Sequence No 2VG Access read/writeVG Status resizableMAX LV 0Cur LV 1Open LV 1Max PV 0Cur PV 2Act PV 2VG Size 1016.00 MiBPE Size 4.00MiBTotal PE 254Alloc PE / Size 175 / 700.00 MiBFree PE / Size 79 / 316.00 MiBVG UUID 3snNw3-CF71-CcYG-Llk1-p6EY-rHEv-xFUSez VG Name 卷组的名称； VG Size 是存储池可用于逻辑卷分配的总大小； Total PE 是以 PE 单位表示的总大小； Free PE / Size 显示 VG 中有多少空闲空间可用于分配给新 LV 或扩展现有 LV。 逻辑卷 ​使用 lvdisplay 显示有关逻辑卷的信息。如果未向命令提供任何参数，则将显示有关所有 LV 的信息；如果提供了 LV 设备名称作为参数，此命令将显示有关该特定设备的信息。 1234567891011121314151617[root@localhost ~]\\# lvdisplay /dev/vg01/lv01--- Logical volume ---LV Path /dev/vg01/lv01LV Name lv01VG Name vg01LV UUID 5IyRea-WBZw-xLHK-3h2a-IuVN-YaeZ-i3IRrNLV Write Access read / writeLV Creation host, time host.lab.example.com, 2019-03-28 17:17:47 -0400LV Status available# open 1LV Size 700MiBCurrent LE 175Segments 1Allocation inheritRead ahead sectors auto- current set to 256Block device 252:0 LV Path 显示逻辑卷的设备名称； 某些工具可能会将设备名报告为 /dev/mapper//vgname-lvname；两个名称都表示同一 LV。 VG Name 显示从其分配 LV 的卷组。 LV Size 显示 LV 的总大小。使用文件系统工具确定可用空间和数据存储的已用空间。 Current LE 显示此 LV 使用的逻辑区块数。LE 通常映射到 VG 中的物理区块，并因此映射到物理卷。 扩展逻辑卷 扩展和缩减卷组 ​扩展卷组指可以通过添加额外的物理卷并为逻辑卷分配新的物理区块来为卷组增加更多磁盘空间。 ​缩减卷组指将未使用的物理卷从卷组中删除。首先，使用 pvmove 命令将数据从一个物理卷上的区块移动到卷组中其他物理卷上的区块。通过这种方式，可以将新磁盘添加到现有卷组，将数据从较旧或较慢的磁盘移动到新磁盘，并将旧磁盘从卷组中删除。可在卷组中的逻辑卷正在使用时执行这些操作。 以下操作以 /dev/nvme0n1 为例，命令参数需以实际操作的磁盘为准。 扩展卷组 ​扩展卷组包含以下步骤： 准备物理设备并创建物理卷 像创建新卷组一样，如果还没有准备好物理卷，则必须创建新分区，并准备好将其用作物理卷。 123[root@localhost ~]\\# parted -s /dev/nvme0n1 mkpart primary 1027MiB 1539MiB[root@localhost ~]\\# parted -s /dev/nvme0n1 set 3 lvm on[root@localhost ~]\\# pvcreate /dev/nvme0n1p3 ​仅当没有空闲的 PV 可以扩展 VG 时，才需要创建 PV。 扩展卷组 使用 vgextend 向卷组中添加新物理卷。使用 VG 名称和 PV 设备名称作为 vgextend 的参数。 1[root@localhost ~]\\# vgextend vg01 /dev/nvme0n1p3 ​此命令会对 vg01 VG 进行扩展，扩展幅度为 /dev/nvme0n1p3 PV 的大小。 验证新空间是否可用 使用 vgdisplay 确认额外的物理区块是否可用。检查输出中的 Free PE / Size。他不应当为零。 123456[root@localhost ~]\\# vgdisplay vg01--- Volume group ---VG Name vg01......Free PE / Size 178 / 712.00 MiB...... 缩减卷组 ​缩减卷组包含以下步骤： 移动物理区块 使用 pvmove PV_DEVICE_NAME 将要删除的物理卷中的所有物理区块都重新放置到卷组中的其他物理卷上。其他物理卷中必须有足够数量的空闲区块来容纳这些移动内容。仅当 VG 中存在足够的空闲区块，且所有这些区块都来自其他 PV 时，才能执行此操作。 1[root@localhost ~]\\# pvmove /dev/nvme0n1p3 ​此命令会将 PE 从 /dev/nvme0n1p3 移动到同一 VG 中具有空闲 PE 的 PV。 使用 pvmove 前需备份卷组中所有逻辑卷上存储的数据。如果操作期间意外断电，可能会导致卷组状态不一致。这可能导致卷组中逻辑卷上的数据丢失。 缩减卷组 使用 vgreduce VG_NAME PV_DEVICE_NAME 从卷组中删除物理卷。 1[root@localhost ~]\\# vgreduce vg01 /dev/nvme0n1p3 ​它将从 vg01 VG 中删除 /dev/nvme0n1p3 PV，并可以添加到其他 VG。或者，也可以使用 pvremove 永久停止将设备用作 PV。 扩展逻辑卷和 XFS 文件系统 ​逻辑卷的一个优势在于能够在不停机的情况下增加其大小。可将卷组中的空闲物理区块添加到逻辑卷以扩展其容量，然后可使用逻辑卷扩展所包含的文件系统。 扩展逻辑卷 ​缩减逻辑卷包含以下步骤： 验证卷组是否具有可用的空间 使用 vgdisplay 验证是否有足够的物理区块可供使用。 123456[root@localhost ~]\\# vgdisplay vg01--- Volume group ---VG Name vg01......Free PE / Size 178 / 712.00 MiB...... 扩展逻辑卷 使用 lvextend LV_DEVICE_NAME 将逻辑卷扩展为新的大小。 1[root@localhost ~]\\# lvextend -L +300M /dev/vg01/lv01 ​此命令会将逻辑卷 lv01 的大小增加 300 MiB。请注意大小前面的加号（+），它表示向现有大小增加此值；如无该符号，该值定义 LV 的最终大小。 ​和 lvcreate 一样，存在不同的方法来指定大小：-l 选项预期以物理区块数作为参数。-L 选项则预期以大小（单位为字节、兆字节、千兆字节等等）作为参数。 ​以下列表提供了一些扩展 LV 的示例。 命令 结果 lvextend -l 128 将逻辑卷大小调整为正好 128 个区块。 lvextend -l +128 向逻辑卷的当前大小添加 128 个区块。 lvextend -L 128M 将逻辑卷的大小调整为正好 128 MiB。 lvextend -L +128M 向逻辑卷的当前大小添加 128 MiB。 lvextend -l +50%FREE 向 LV 添加 VG 中当前可用空间的 50%。 扩展文件系统 使用 xfs_growfs mountpoint 可以扩展文件系统以占用已扩展的 LV。使用 xfs_growfs 命令时，必须挂载目标文件系统。在调整文件系统大小时，可以继续使用该文件系统。 1[root@localhost ~]\\# xfs_growfs /mnt/data 常见错误是运行 lvextend 但忘记运行 xfs_growfs。连续运行两个步骤的一种替代方法是在 lvextend 命令中包含 -r 选项。这将使用 fsadm 在扩展 LV 后调整文件系统的大小。它可以用于多种不同的文件系统。 ​验证已挂载文件系统的新大小： 1[root@localhost ~]\\# df -h /mountpoint 扩展逻辑卷和 EXT4 文件系统 ​同样需要先扩展逻辑卷，参考 c. 扩展逻辑卷和 XFS 文件系统 中的 扩展逻辑卷 一节。调整文件系统大小时与 XFS 不同。 验证卷组是否具有可用的空间 使用 vgdisplay VGNAME 验证卷组中是否有足够数量的物理区块可供使用。 扩展逻辑卷 使用 lvextend -l +extents /dev/vgname/lvname 对逻辑卷 /dev/vgname/lvname 进行扩展，扩展的幅度为 extents 值。 扩展文件系统 使用 resize2fs /dev/vgname/lvname 可以扩展文件系统已占用新扩展的 LV。运行扩展命令时，可以挂载并使用文件系统，可以包含 -p 选项以监控调整大小操作的进度。 1[root@localhost ~]\\# resize2fs -p /dev/vgname/lvname xfs_growfs 和 resize2fs 传递的参数类型不同，前者传挂载点、后者传逻辑卷名称。 扩展逻辑卷和交换空间 ​格式化为交换空间的逻辑卷必须卸载后才能进行扩展。 验证卷组是否具有可用的空间 使用 vgdisplay VGNAME 验证卷组中是否有足够数量的物理区块可供使用。 停用交换空间 使用 swapoff -v /dev/vgname/lvname 可以停用逻辑卷上的交换空间。 系统必须有足够内存或交换空间以便被停用的逻辑卷上的交换空间上的内容可以转移到它们上。 扩展逻辑卷 使用 lvextend -l +extents /dev/vgname/lvname 可对逻辑卷 /dev/vgname/lvname 进行扩展，扩展的幅度为 extents 值。 将逻辑卷格式化为交换空间 使用 mkswap /dev/vgname/lvname 可将整个逻辑卷格式化为交换空间。 激活交换空间 使用 swapon -va /dev/vgname/lvname 可以激活逻辑卷上的交换空间。","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"基本的存储管理","slug":"Linux | 基本的存储管理","date":"2022-08-15T06:31:35.176Z","updated":"2022-08-15T06:40:36.998Z","comments":true,"path":"2022-08-15-Linux | 基本的存储管理.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E5%9F%BA%E6%9C%AC%E7%9A%84%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 添加分区、文件系统和持久挂载 磁盘分区 ​通过创建磁盘分区，管理员可以使用其执行不同功能。在以下情况下，磁盘分区是必要或有益的： 限制应用或用户的可用空间； 将操作系统和程序文件与用户文件分隔开； 创建用于内存交换的单独区域； 限制磁盘空间使用，以提高诊断工具和备份映像的性能。 MBR 分区方案 ​MBR 是一种比较传统的分区方案，其支持最多 4 个主分区。在 Linux 系统上，管理员可以使用 扩展分区和逻辑分区来创建最多 15 个分区。由于分区大小数据以 32 位值存储，使用 MBR 方案分区时，最大磁盘和分区大小为 2TB。 ​由于现代存储技术的不断发展，MBR 分区的 2TiB 限制已从理论转化为现在越来越频繁的现实问题，故新的 GUID 分区表（GPT 分区）正在取代 MBR 分区方案。 GPT 分区方案 ​GPT 分区方案依赖于新的固件系统 —— UEFI。GPT 是 UEFI 标准的一部分，可以解决原有基于 MBR 的方案所带来的许多限制。 ​GPT 分区方案最多可提供 128 个分区以及 8ZiB（80 亿 TiB）的分区和磁盘。GPT 分区提供了备份副本来确保数据的安全性，且提供了校验算法来检测 GPT 头和分区表中的错误和损坏。 使用 PARTED 管理分区 ​Parted 分区实用程序同时支持管理 MBR 和 GPT 两种分区。 123456789101112131415161718192021222324252627282930[root@localhost ~]\\# parted -h用法: parted [选项]... [设备 [命令 [参数]...]...]接受以 参数s 执行的 命令s 来管理 设备. 如果未提供任何命令, 将以交互模式运行。选项s: -h, --help 显示此帮助信息 -l, --list 列举所有块设备的分区结构信息 -m, --machine displays machine parseable output -s, --script never prompts for user intervention -v, --version displays the version -a, --align=[none|cyl|min|opt] alignment for new partitions命令s: align-check TYPE N 检查分区 N 的对齐类型(min|opt) help [COMMAND] 打印通用帮助信息, 或针对 COMMAND 的帮助信息 mklabel,mktable LABEL-TYPE 创建新的磁盘标签(分区表) mkpart PART-TYPE [FS-TYPE] START END 创建新分区 name NUMBER NAME 以 NAME 命名分区 NUMBER print [devices|free|list,all|NUMBER] 显示 分区表|可用设备|空闲空间|所有分区|指定分区 (NUMBER) quit 退出程序 rescue START END 恢复在 START 和 END 之间丢失的分区 resizepart NUMBER END 重新规划分区 NUMBER 的大小 rm NUMBER 删除分区 NUMBER select DEVICE 选择要操作的存储设备 disk_set FLAG STATE 更改选定设备上的 FLAG 的状态为 STATE disk_toggle [FLAG] 切换选定设备上的 FLAG 的 FLAG 为 STATE set NUMBER FLAG STATE 更改分区 NUMBER 上的 FLAG 为状态 STATE toggle [NUMBER [FLAG]] 切换分区 NUMBER 的 FLAG 为 STATE unit UNIT 设置默认单位为 UNIT version display the version number and copyright information of GNU Parted 默认情况下，parted 显示以 10 的幂次方表示的所有空间大小（KB、MB、GB）。可以使用 unit 子命令来更改默认设置，该子命令接受以下参数： s 表示扇区； B 表示字节； MiB、GiB 或 TiB（2 的幂次方）； MB、GB 或 TB （10 的幂次方）； 1234567891011[root@localhost ~]\\# parted /dev/nvme0n1 unit s printModel: NVMe Device (nvme)Disk /dev/nvme0n1: 41943040sSector size (logical/physical): 512B/512BPartition Table: msdosDisk Flags: Number Start End Size Type File system Flags 1 2048s 616447s 614400s primary xfs boot 2 616448s 4810751s 4194304s primary linux-swap(v1) 3 4810752s 41943039s 37132288s primary xfs 向新磁盘写入分区表 ​要对新驱动器进行分区，首先必须为其写入磁盘标签。磁盘标签指示了所用的分区方案。 parted 命令的更改是即时生效的，若误用了该命令，注定会导致数据丢失。 ​以 root 用户身份，使用以下命令将 MBR 磁盘标签写入磁盘： 1[root@localhost ~]\\# parted /dev/nvme0n1 mklabel msdos ​若要写入 GPT 磁盘标签，则需使用该命令： 1[root@localhost ~]\\# parted /dev/nvme0n1 mklabel gpt mklabel 子命令会擦除现有分区表，其效果类似于 windows 中的格式化，仅当重复利用旧磁盘而不保留其中的旧有数据时使用。 创建 MBR 分区 ​创建 MBR 磁盘分区包含以下几个步骤： 指定要在其上创建分区的磁盘设备。 以 root 用户身份执行 parted 命令，并指定该磁盘设备名称作为参数。这样将会以交互模式启动 parted 命令并显示命令提示符。 12345[root@localhost ~]\\# parted /dev/nvme0n1GNU Parted 3.2Using /dev/nvme0n1Welcome to GNU Parted! Type &#x27;help&#x27; to view a list of commands.(parted) 使用 mkpart 子命令创建新的主分区或扩展分区。 12(parted) mkpartPartition type? primary/extended? primary # 创建主分区 若需创建多于四个分区，可以适当将后面的分区创建为扩展分区，并在其上创建逻辑分区。 指示要在分区上创建的文件系统类型，如 xfs 或 ext4，此操作不会在分区上创建文件系统，仅为指示分区类型作用。 1File system type? [ext2]? xfs # xfs ​要了解支持哪些文件系统类型，可以使用以下命令进行查询。 1[root@localhost ~]\\# parted /dev/nvme0n1 help mkpart 指定磁盘上新分区开始的扇区。 1Start? 2048s # 第 2948 个扇区开始 ​也可以使用 MB、MiB 等单位，默认单位为 MB。程序会自动舍入进行对齐。对于大多数磁盘而言，起始扇区设置为 2048 的倍数较为安全。 指定应结束新分区的磁盘扇区。 1End? 1000MB # 分区大小 Size = End - Start ​提供了结束位置后，parted 即可利用新分区的详细信息来更新磁盘上的分区表。 退出 parted。 1234(parted) quitInformation: You may need to update /etc/fstab.[root@localhost ~] 运行 udevadm settle 命令。此命令会等待系统检测新分区并在 /dev 目录下创建关联的设备文件，完成操作后才会返回。 12[root@localhost ~] udevadm settle[root@localhost ~] ​上述操作的一条命令版本为： 1[root@localhost ~] parted /dev/nvme0n1 mkpart primary xfs 2048s 1000MB 创建 GPT 分区 ​创建 GPT 磁盘分区包含以下几个步骤： 指定要在其上创建分区的磁盘设备。 以 root 用户身份执行 parted 命令，并指定该磁盘设备名称作为参数。这样将会以交互模式启动 parted 命令并显示命令提示符。 12345[root@localhost ~]\\# parted /dev/nvme0n1GNU Parted 3.2Using /dev/nvme0n1Welcome to GNU Parted! Type &#x27;help&#x27; to view a list of commands.(parted) 使用 mkpart 子命令创建新的主分区或扩展分区。 对于 GPT 方案而言，每个分区都会获得一个名称。 12(parted) mkpartPartition name? []? userdata 指示要在分区上创建的文件系统类型，如 xfs 或 ext4。这并不会在分区上创建文件系统；它仅仅指示分区类型。 1File system type? [ext2]? xfs 指定磁盘上新分区开始的扇区。 1Start? 2048s 指定应结束新分区的磁盘扇区。 1End? 1000MB ​一旦提供了结束位置，parted 即可利用新分区的详细信息来更新磁盘上的分区表。 退出 parted。 1234(parted) quitInformation: You may need to update /etc/fstab.[root@localhost ~]\\# 运行 udevadm settle 命令。 此命令会等待系统检测新分区并在 /dev 目录下创建关联的设备文件。只有在完成上述操作后，他才返回。 12[root@localhost ~]\\# udevadm settle[root@localhost ~]\\# ​作为交互模式的替代方法，您也可以按如下方式创建分区： 1[root@localhost ~]\\# parted /dev/nvme0n1 mkpart userdata xfs 2048s 1000MB 删除分区 ​以下步骤适用于 MBR 和 GPT 两种分区方案。 指定包含要删除的分区的磁盘。 作为 root 用户，以磁盘设备作为唯一参数执行 parted 命令，从而通过命令提示符在交互模式下启动 parted。 12345[root@localhost ~]\\# parted /dev/nvme0n1GNU Parted 3.2Using /dev/nvme0n1Welcome to GNU Parted! Type &#x27;help&#x27; to view a list of commands.(parted) 确定要删除的分区的分区编号。 12345678910(parted) printModel: Virtio Block Device (virtblk)Disk /dev/nvme0n1: 5369MBSector size (logical/physical): 512B/512BPartition Table: gptDisk Flags:Number Start End Size File system Name Flags 1 1049kB 1000MB 999MB xfs userdata 删除分区。 1(parted) rm 1 ​rm 子命令会立即从磁盘上的分区表中删除该分区。 退出 parted。 1234(parted) quitInformation: You may need to update /etc/fstab.[root@localhost ~]\\# 创建文件系统 ​创建块设备后，下一步是向其中添加文件系统。红帽企业 Linux 支持许多不同的文件系统类型，其中两种常见的类型是 XFS 和 ext4。红帽企业 Linux 的安装程序 Anaconda 默认使用 XFS。 ​以 root 用户身份，使用 mkfs.xfs 命令为块设备应用 XFS 文件系统。对于 ext4，可以使用 mkfs .ext4。 1234567891011[root@localhost ~]\\# mkfs.xfs /dev/nvme0n1meta-data=/dev/nvme0n1 isize=512 account=4, agsize=60992 blks = sects=512 attr=2, projid32bit=1 = crc=1 finobt=1, sparse=1, rmapbt=0 = reflink=1data = bsize=4096 blocks=243968, imaxpct=25 = sunit=0 swidth=0 blksnaming =version 2 bsize=4096 ascii-ci=0, ftype=1log =internal log bsize=4096 blocks=1566, version=2 = sectsz=512 sunit=0 blks, lazy-count=1realtime =none extsz=4096 blocks=0, rtextents=0 挂载文件系统 ​关于手动挂载文件系统的方法已在 23. 访问 Linux 文件系统 中阐述，本节重点说明持久挂载文件系统。持久挂载是指系统开机或重启进入系统后自动挂载某块设备而无需进行手动挂载，此行为跟图形用户界面中的自动挂载有区别。 ​要实现持久化挂载可已修改 /etc/fstab 文件，向其添加新的条目。修改完毕后使用 systemctl daemon-reload 命令来实现修改生效。 123456789101112131415[root@localhost ~]\\# cat /etc/fstab## /etc/fstab# Created by anaconda on Wed Jun 2 22:59:16 2021## Accessible filesystems, by reference, are maintained under &#x27;/dev/disk/&#x27;.# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info.## After editing this file, run &#x27;systemctl daemon-reload&#x27; to update systemd# units generated from this file.#UUID=360e2f42-d6de-4209-8487-f36b7cc69cc2 / xfs defaults 0 0UUID=529dd49b-7b72-4394-8fbb-98eb7f24de1e /boot xfs defaults 0 0UUID=bb97577f-bf23-4a75-8ff1-46b7dce21eb9 none swap defaults 0 0 ​fstab 文件的条目的第一个字段指定设备。本示例使用 UUID 来指定设备（推荐）。创建文件系统时会在其超级块中创建和存储 UUID。或者可以使用设备文件。 列出块设备的 UUID 可以使用 lsblk 或 blkid 命令： 123456789101112131415[student@localhost ~]\\$ lsblk -fsNAME FSTYPE LABEL UUID MOUNTPOINTsr0 nvme0n1p1 xfs 529dd49b-7b72-4394-8fbb-98eb7f24de1e /boot└─nvme0n1 nvme0n1p2 swap bb97577f-bf23-4a75-8ff1-46b7dce21eb9 [SWAP]└─nvme0n1 nvme0n1p3 xfs 360e2f42-d6de-4209-8487-f36b7cc69cc2 /└─nvme0n1 [student@localhost ~]\\$ sudo blkid[sudo] password for student: /dev/nvme0n1: PTUUID=&quot;3c479f3a&quot; PTTYPE=&quot;dos&quot;/dev/nvme0n1p1: UUID=&quot;529dd49b-7b72-4394-8fbb-98eb7f24de1e&quot; BLOCK_SIZE=&quot;512&quot; TYPE=&quot;xfs&quot; PARTUUID=&quot;3c479f3a-01&quot;/dev/nvme0n1p2: UUID=&quot;bb97577f-bf23-4a75-8ff1-46b7dce21eb9&quot; TYPE=&quot;swap&quot; PARTUUID=&quot;3c479f3a-02&quot;/dev/nvme0n1p3: UUID=&quot;360e2f42-d6de-4209-8487-f36b7cc69cc2&quot; BLOCK_SIZE=&quot;512&quot; TYPE=&quot;xfs&quot; PARTUUID=&quot;3c479f3a-03&quot; ​第二个字段指定挂载点，通过它可以访问目录结构中的块设备，挂载点必须存在于父文件系统中。 ​第三个字段包含文件系统类型，如 xfs、ext4、swap（交换分区）等。 ​第四个字段的值可以取以逗号分隔的多个应用于设备的选项。常见值的意义如下： 选项 描述 rw 按可读可写权限挂载。 suid 允许文件或目录的所属用户位和所属组位生效。 exec 允许执行二进制程序。 dev 解释字符或屏蔽特殊设备于文件系统上。 auto 可以使用 mount -a 手动挂载上。 nouser 不允许普通用户手动挂载此设备。 async 异步存储（性能较佳），将内容写入日志在保存到磁盘。 defaults 以上选项的合集。 ​第五个字段的值表示 ”指定分区是否被 dump 程序备份“，0 代表不备份，1 代表备份，2 代表不定期备份。 ​第六个字段的值表示 ”指定分区是否被 fsck 程序检测“, 0 代表不检测，其他数字代表检测的优先级，递增优先级越低。 添加新条目于 /etc/fstab 中后需使用 mount -a 选项来测试下挂载是否成功，确保无误后再重启测试（有可能会导致系统无法启动）。 修改完 /etc/fstab 中的条目需使用 mount -o remount 命令来重新挂载（mount -a 命令对已挂载上的同名设备不会重新挂载）。 管理交换空间 ​交换空间是受 Linux 内核内存管理子系统控制的磁盘区域。内核通过使用交换空间将不活动的内存页暂存在交换空间中来节省 RAM，交换空间一般以磁盘分区的形式存在，称为 交换分区。系统内存和交换分区组合在一起称为虚拟内存。由于交换分区位于磁盘上，其读取和写入速度较慢。 ​关于交换分区的划定大小有下表的建议： RAM 交换分区大小 允许休眠功能时的交换内存大小 2GiB 或 以下 RAM 大小 x 2 RAM 大小 x 3 介于 2GiB 和 8GiB 之间 与 RAM 大小 相同 RAM 大小 x 2 介于 8GiB 和 64GiB 之间 至少 4GiB RAM 大小 x 1.5 64 GiB 以上 至少 4GiB 不建议开启休眠功能 ​休眠：指关闭计算机电源之前将内存内容转储到交换分区（注意：硬盘是非易失性存储设备），重新打开计算机后系统会从交换分区中恢复内存上的内容，无需完全启动。 创建交换空间 ​创建交换空间的基本操作可概述为：创建文件系统类型为 linux-swap 的分区、为设备放置交换签名。 ​以前 parted 工具可以根据分区文件系统类型来确定是否应激活设备，但现在即使该程序不再使用分区文件系统类型，设置此类型也可以使管理员快速确定该分区的用途。 12345678910111213141516171819202122232425262728293031323334[root@localhost ~]\\# parted /dev/nvme0n1GNU Parted 3.2Using /dev/nvme0n1Welcome to GNU Parted! Type &#x27;help&#x27; to view a list of commands.(parted) printModel: Virtio Block Device (virtblk)Disk /dev/nvme0n1: 5369MBSector size (logical/physical): 512B/512BPartition Table: gptDisk Flags:Number Start End Size File system Name Flags 1 1049kB 1001MB 1000MB data(parted) mkpartPartition name? []? swap1File system type? [ext2]? linux-swapStart? 1001MBEnd? 1257MB(parted) printModel: Virtio Block Device (virtblk)Disk /dev/nvme0n1: 5369MBSector size (logical/physical): 512B/512BPartition Table: gptDisk Flags:Number Start End Size File system Name Flags 1 1049kB 1001MB 1000MB data 2 1001MB 1257MB 256MB linux-swap(v1) swap(parted) quitInformation: You may need to update /etc/fstab.[root@localhost ~]\\# ​创建分区后，运行 udevadm settle 命令。此命令会等待系统检测新分区并在 /dev 中创建关联的设备文件。只有在完成上述操作后，它才返回。 12[root@localhost ~]\\# udevadm settle[root@localhost ~]\\# 格式化设备 ​mkswap 命令向设备应用交换签名。与其他格式化实用程序不同，mkswap 在设备开头写入单个数据块，而将设备的其余部分保留为未格式化，这样内核就可以使用它来存储内存页。 123[root@localhost ~]\\# mkswap /dev/nvme0n1Setting up swapspace version 1, size = 244 MiB(255848448 bytes) no label, UUID=39e2667a-9458-42fe-9665-c5c854605881 激活交换空间 ​可以使用 swapon 命令激活已格式化的交换空间。 ​使用 swapon 并将设备作为参数，或者使用 swapon -a 来激活 /etc/fstab 文件中列出的所有交换空间。使用 swapon --show 和 free 命令检查可用的交换空间。 123456789[root@localhost ~]\\# free total used free shared buff/cache availableMem: 1873036 134688 1536436 16748 201912 1576044Swap: 0 0 0[root@localhost ~]\\# swapon /dev/nvme0n1[root@localhost ~]\\# free total used free shared buff/cache availableMem: 1873036 135044 1536040 16748 201952 1575690Swap: 249852 0 249852 ​可以使用 swapoff 命令停用交换空间。如果交换空间具有写入的页面，swapoff 会尝试将这些页面移动到其他活动交换空间或将其写回到内存中。如果无法将数据写入到其他位置，则 swapoff 命令会失败，并显示错误，而交换空间仍保持活动。 持久激活交换空间 ​要想在每次启动时都激活交换空间，请在 /etc/fstab 文件中放置一个条目。基于上面创建的交换空间，以下示例显示了 /etc/fstab 中比较典型的一行。 1UUID=39e2667a-9458-42fe-9665-c5c854605881 swap swap defaults 0 0 ​该示例使用 UUID 作为第一个字段。格式化设备时，mkswap 命令会显示该 UUID。如果丢失了 mkswap 的输出，请使用 lsblk --fs 命令。作为替代方法，您也可以在第一个字段中使用设备名称。 ​第二个字段通常为 mount point 保留。但是，由于交换设备无法通过目录结构访问，因此该字段取占位符值为 swap 或者 none。 ​第三个字段是文件系统类型。交换空间的文件系统类型是 swap。 ​第四个字段是选项，本示例中使用了 defaults 选项，关于此选项的介绍可以参见上文。 ​最后两个字段是 dump 标志和 fsck 顺序，这两个字段的值默认为 0 就行。 ​在 /etc/fstab 文件中添加或删除条目时，可以运行 systemctl daemon-reload 命令或重启服务器，以便让 systemd 注册新配置。 1[root@localhost ~]\\# systemctl daemon-reload 设置交换空间优先级 ​默认情况下，系统会按顺序使用交换空间，即内核先使用第一个已激活交换空间，直至其空间已满，然后开始使用第二个交换空间。不过，您也可以为每个交换空间定义一个优先级，从而强制按该顺序使用交换空间。 ​要设置优先级，请在 /etc/fstab 中使用 pri 选项。内核会首先使用优先级最高的交换空间。默认优先级为 -2。 ​以下示例显示了 /etc/fstab 中定义的三个交换空间。内核首先使用最后一个条目，其优先级为 pri=10。当该空间已满时，他将使用第二个条目，其优先级为 pri=4。最后，它将使用第一个条目，其默认优先级为 -2。 123UUID=a2345678-9458-42fe-9665-c5c854605881 swap swap defaults 0 0UUID=b3245c23-9458-42fe-9665-c5c854605881 swap swap defaults 0 0UUID=39e2667a-9458-42fe-9665-c5c854605881 swap swap defaults 0 0 ​使用 swapon --show 可以显示交换空间的优先级。 ​当交换空间具有相同的优先级时，内核会以轮询方式向其中写入。","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"使用 SELinux 确保系统安全性","slug":"Linux | 使用 SELinux 确保系统安全性","date":"2022-08-15T06:25:32.733Z","updated":"2022-08-15T06:29:27.021Z","comments":true,"path":"2022-08-15-Linux | 使用 SELinux 确保系统安全性.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E4%BD%BF%E7%94%A8%20SELinux%20%E7%A1%AE%E4%BF%9D%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A8%E6%80%A7.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 SELinux 简述 ​SELinux 是 Security Enhanced Linux 的简称。 ​SELinux 在 Linux 中具有重要的安全用途，它可以允许或拒绝访问文件及其他资源，且精准度相比用户权限要大幅提高。SELinux 相比普通的文件权限控制提供了更多安全细节，不仅可以限制谁能读取、写入、执行某文件，还能控制如何来使用该文件。 ​SELinux 由应用开发人员定义的若干策略组成，这些策略准确声明了对于应用使用的每个二进制可执行文件、配置文件和数据文件，哪些操作和访问权限是恰当且被允许的。这被称为目标政策，因为会编写一个策略以涵盖单个应用的活动。策略声明了各个程序、文件和网络端口上放置的预定义标签。 ​SELinux 实施了一组可以防止一个应用程序的弱点影响其他应用或基础系统的访问规则。SELinux 提供了一个额外的安全层，此外还增加了一层复杂结构，这使得 SELinux 的学习成本增加，但执行政策意味着系统某一部分的弱点不会扩散到其他部分。如果 SELinux 在特定的子系统上运行不佳，则可以关闭该特定服务的执行，直至找到潜在问题的解决方案。 ​SELinux 有三种模式： 强制（Enforcing）：SELinux 强制执行访问控制规则。计算机通常在此模式下运行； 许可（Permissive）：SELinux 处于活动状态，但不强制执行访问控制规则，而是记录违反规则的警告。该模式主要用于测试和故障排除； 禁用（Disable）：SELinux 完全关闭 —— 不拒绝任何 SELinux 违规，甚至不予记录。不建议禁用 SELinux。 SELinux 工作原理 ​SELinux 是用于确定哪个进程可以访问哪些文件、目录和端口的一组安全规则。每个文件、进程、目录和端口都具有专门的安全标签，称为 SELinux 上下文。上下文是一个名称，SELinux 策略使用它来确定某个进程能否访问文件、目录或端口。除非显式规则授予访问权限，否则，在默认情况下，策略不允许任何交互。如果没有允许规则，则不允许访问。 ​SELinux 标签具有多种上下文：用户、角色、类型和敏感度。目标策略会根据三个上下文（即类型上下文）来制定自己的规则。类型上下文名称通常以 _t 结尾。 ​ unconfined_u:object_r:httpd_sys_content_t:s0 /var/www/html/file2 ​ SELinux 用户 角色 类型 级别 文件 ​说明： Web 服务器的类型上下文是 httpd_t。通常位于 /var/www/html 中的文件和目录的类型上下文是 httpd_sys_content_t。通常位于 /tmp 和 /var/tmp 中的文件和目录上下文是 tmp_t。Web 服务器端口的类型上下文是 http_port_t。 ​Apache 具有类型上下文 httpd_t。有一个策略规则允许 Apache 访问具有 httpd_sys_content_t 类型上下文的文件和目录。默认情况下，在 var/www/html 和其他 Web 服务器目录中找到的文件具有 httpd_sys_content_t 类型上下文。策略中没有允许规则适用于通常位于 /tmp 和 /var/tmp 中的文件，因此不允许访问。在启用 SELinux 的情况下，破坏了Web服务器进程的恶意用户将无法访问 /tmp 目录。 ​MariaDB 服务器具有类型上下文 mysqld_t。默认情况下，在 /data/mysql 中找到的文件具有 mysqld_db_t 类型上下文。该类型上下文允许 MariaDB 访问这些文件，但禁止其他服务（如Apache Web服务）访问。 许多处理文件的命令都使用 -Z 选项来显示或设置 SELinux 上下文。例如，ps、ls、cp 和 mkdir 都使用 -Z 选项显示或设置 SELinux 上下文。 12345678910111213[root@localhost ~]\\# ps axZ | head -n 3LABEL PID TTY STAT TIME COMMANDsystem_u:system_r:init_t:s0 1 ? Ss 0:05 /usr/lib/systemd/systemd --switched-root --system --deserialize 18system_u:system_r:kernel_t:s0 2 ? S 0:00 [kthreadd][root@localhost ~]\\# ls -Z /homeunconfined_u:object_r:user_home_dir_t:s0 student[root@localhost ~]\\# ls -Z /var/log/cupssystem_u:object_r:cupsd_log_t:s0 access_logsystem_u:object_r:cupsd_log_t:s0 access_log-20210819system_u:object_r:cupsd_log_t:s0 error_logsystem_u:object_r:cupsd_log_t:s0 error_log-20210819system_u:object_r:cupsd_log_t:s0 page_logsystem_u:object_r:cupsd_log_t:s0 page_log-20210819 SELinux 工作模式 ​SELinux 子系统提供了显示和更改模式的工具。要确定当前的 SELinux 模式，可以运行 getenforce 命令： 12[root@localhost ~]\\# getenforceEnforcing ​要临时更改 SELinux 工作模式，可以使用 setenforce 命令： 12[root@localhost ~]\\# setenforceusage: setenforce [ Enforcing | Permissive | 1 | 0 ] 可以在系统启动时通过将向内核传递参数来设置 SELinux 模式：内核参数 enforcing=0 将以许可模式启动系统；值 enforcing=1 则设置强制模式。此外，您还可以通过传递内核参数 selinux=0 来彻底禁用 SELinux。值 selinux=1 将启用 SELinux。 ​可以在 /etc/selinux/config 文件来持久配置 SELinux。内核参数会覆盖此设置。 1234567891011# This file controls the state of SELinux on the system.# SELINUX= can take one of these three values:# enforcing - SELinux security policy is enforced.# permissive - SELinux prints warnings instead of enforcing.# disabled - No SELinux policy is loaded.SELINUX=enforcing# SELINUXTYPE= can take one of these three values:# targeted - Targeted processes are protected,# minimum - Modification of targeted policy. Only selected processes are protected. # mls - Multi Level Security protection.SELINUXTYPE=targeted SELinux 上下文 ​在运行 SELinux 的系统上，所有进程和文件都会有响应的标签。标签代表了与安全有关的信息，称为 SELinux 上下文。 ​新文件通常从父目录继承其 SELinux 上下文，从而确保它们具有适当的上下文。但是，有两种不同的方式可能会破坏该继承过程。首先，如果您在与最终目标位置不同的位置创建文件，然后移动文件，则该文件将具有创建它时所在目录的 SELinux 上下文，而不是目标目录的 SELinux 上下文。其次，如果是复制一个保留 SELinux 上下文的文件（正如使用 cp -a 命令），则 SELinux 上下文将反映原始文件的位置。 ​以下示例演示了继承关系及存在的缺陷。以 /tmp 中创建的两个文件为例，一个移动到 /var/www/html，另一个复制到同一目录中。移动到 /var/www/html 目录的文件保留了 /tmp 目录的文件上下文。复制到 /var/www/html 目录中的文件则继承了 /var/www/html 目录的 SELinux 上下文。 ​使用 ls -Z 命令显示文件的 SELinux 上下文。 12[root@localhost ~]\\# ls -Z /var/lib/nfs/etabsystem_u:object_r:var_lib_nfs_t:s0 /var/lib/nfs/etab ​使用 ls -Zd 命令显示目录的 SELinux 上下文。 12[root@localhost ~]\\# ls -dZ /var/lib/nfssystem_u:object_r:var_lib_nfs_t:s0 /var/lib/nfs 更改文件的 SELinux 上下文 ​用于更改文件 SELinux 上下文的命令包括：semanage fcontext、restorecon 和 chcon。 ​为文件设置 SELinux 上下文的首选方法是使用 semanage fcontext 命令来声明文件的默认标签，然后使用 restorecon 命令将该上下文应用于文件。这样可确保标签符合预期，即便在对文件系统完全重新标记之后也是如此。 ​chcon 命令更改 SELinux 上下文。chcon 设置存储在文件系统中的文件安全上下文。它对于测试和实验很有用。但是，它不会将上下文更改保存到 SELinux 上下文数据库中。当 restorecon 命令运行时，chcon 命令所做的更改也同样无法保留。此外，如果对整个文件系统进行重新标记，则使用 chcon 更改过的文件的 SELinux 上下文将恢复。 12345678910111213# 1. 创建测试目录并查看其 SELinux 上下文[root@localhost ~]\\# mkdir testdir[root@localhost ~]\\# ls -dZ testdirunconfined_u:object_r:admin_home_t:s0 testdir# 2. 使用 chcon 命令修改其 SELinux 上下文[root@localhost ~]\\# chcon -t var_lib_nfs_t testdir[root@localhost ~]\\# ls -dZ testdirunconfined_u:object_r:var_lib_nfs_t:s0 testdir# 3. 使用 restorecon 命令重置其 SELinux 上下文[root@localhost ~]\\# restorecon -v testdirRelabeled /root/testdir from unconfined_u:object_r:var_lib_nfs_t:s0 to unconfined_u:object_r:admin_home_t:s0[root@localhost ~]\\# ls -dZ testdirunconfined_u:object_r:admin_home_t:s0 testdir 定义 SELinux 默认文件上下文规则 ​semanager fcontext 命令可显示和修改 restorecon 用来设置默认文件上下文的规则。它使用扩展正则表达式来指定路径和文件名。fcontext 规则中最常用的扩展正则表达式是 (/.*)?，表示 “可选择匹配后跟任何数量字符的/” 。它将会匹配在表达式前面列出的目录并递归地匹配该目录中的所有内容。 ​semanage fcontext 命令的选项： 选项 描述 -a, --add 添加指定对象类型的记录 -d, --delete 删除指定对象类型的记录 -l, --list 列出指定对象类型的记录 restorecon 命令依赖于 policycoreutil 软件包，semanage 命令依赖于 policycoreutil-python 软件包。 123[root@localhost ~]\\# semanage fcontext -l | grep var/lib/nfs/var/lib/nfs(/.*)? all files system_u:object_r:var_lib_nfs_t:s0 /var/lib/nfs/rpc_pipefs(/.*)? all files &lt;&lt;None&gt;&gt; ​接 1 中的例子（文件已创建），此次永久设置其 SELinux 上下文： 123456789101112131415# 4. 将 /root/testdir 的类型上下文永久修改为 var_lib_nfs_t（继承）[root@localhost ~]\\# semanage fcontext -a -t var_lib_nfs_t &#x27;/root/testdir(/.*)?&#x27;[root@localhost ~]\\# ls -dZ testdir/unconfined_u:object_r:admin_home_t:s0 testdir/[root@localhost ~]\\# restorecon -RFvv testdir/Relabeled /root/testdir from unconfined_u:object_r:admin_home_t:s0 to system_u:object_r:var_lib_nfs_t:s0# 5. 尝试在此目录下创建文件再验证：[root@localhost ~]\\# touch testdir/test.txt[root@localhost ~]\\# ls -Z testdir/test.txt unconfined_u:object_r:var_lib_nfs_t:s0 testdir/test.txt# 6. 删除刚才的配置[root@localhost ~]\\# semanage fcontext -d -t var_lib_nfs_t &#x27;/root/testdir(/.*)?&#x27;[root@localhost ~]\\# restorecon -RFvv testdir/Relabeled /root/testdir from system_u:object_r:var_lib_nfs_t:s0 to system_u:object_r:admin_home_t:s0Relabeled /root/testdir/test.txt from unconfined_u:object_r:var_lib_nfs_t:s0 to system_u:object_r:admin_home_t:s0 使用布尔值调整 SELinux 策略 ​SELinux 布尔值是可更改 SELinux 策略行为的参数。SELinux 布尔值是可以启用或禁用的规则。安全管理员可以使用 SELinux 布尔值来有选择地调整策略。 selinux-policy-doc 软件包附带的 SELinux man page 中介绍了可用布尔值的用途。使用 man -k '_selinux' 命令可以列出这些 man page。 ​使用 getsebool 命令列出机器状态的布尔值。 12345678910111213141516# 选项：-a # 列出所有配置# 例子：[root@localhost ~]\\# getsebool -a | head -n 10abrt_anon_write --&gt; offabrt_handle_event --&gt; offabrt_upload_watch_anon_write --&gt; onantivirus_can_scan_system --&gt; offantivirus_use_jit --&gt; offauditadm_exec_content --&gt; onauthlogin_nsswitch_use_ldap --&gt; offauthlogin_radius --&gt; offauthlogin_yubikey --&gt; offawstats_purge_apache_log_files --&gt; off[root@localhost ~]\\# getsebool httpd_enable_homedirshttpd_enable_homedirs --&gt; off ​使用 setsebool 命令修改布尔值。 12345# 选项：-P # 将设置持久化到政策文件中# 例子：[root@localhost ~]\\# setsebool httpd_enable_homedirs on[root@localhost ~]\\# getsebool -P httpd_enable_homedirs off ​使用 semanage boolean -l 将报告布尔值是否为持久值，并提供该布尔值的简短描述。 12[root@localhost ~]\\# semanage boolean -l | grep httpd_enable_homedirs httpd_enable_homedirs (off , off) Allow httpd to enable homedirs ​使用 semanage boolean -l -C 列出当前状态与默认配置不同的布尔值. 1[root@localhost ~]\\# semanage boolean -l -C 排查和解决 SELinux 问题 ​解决因 SELinux 阻止而使得某些应用无法访问某些文件时应注意以下原则： 在考虑任何调整之前，应了解到 SELinux 禁止意图访问的这一做法也许很正确，如 Web 服务器对 /home 的访问； 最常见的 SELinux 问题是使用不正确的文件上下文，这种情况下可以运行 restorecon 来更正因为移动文件产生的文件访问问题； 对于严苛限制性访问的另一个补救措施可以是调整布尔值，如 ftpd_anon_write 布尔值控制匿名 FTP 用户能否上传文件； SELinux 策略可能存在阻止合法访问的漏洞，此种情况极少。 监控 SELinux 冲突 依赖软件包：setroubleshoot-server。安装后 SELinux 消息将会发送至 /var/log/messages。 ​setroubleshoot-server 侦听 /var/log/audit/audit.log 中的审核消息，并发送简短摘要到 /var/log/messages。该摘要包括 SELinux 冲突的唯一标识符（UUID），可用于收集更多信息。sealert -l UUID 命令用于生成特定事件的报告。使用 sealert -a /var/log/audit/audit.log 可以在该文件中生成所有事件的报告。 使用 ausearch 命令可以检索 /var/log/audit.log 中的日志内容，-m 选项指定消息类型，-ts 指定时间，如： 12[root@localhost ~]\\# ausearch -m AVC -ts recent&lt;no matches&gt; 以标准 Apache Web 服务器为例 ​在 root 用户家目录创建 html 文件并将其移动到 Apache 静态页存放目录，启动 Apache 服务后访问： 12345678[root@localhost ~]\\# touch /root/file &amp;&amp; mv /root/file /var/www/html[root@localhost ~]\\# systemctl start httpd[root@localhost ~]\\# curl http://localhost/file&lt;!DOCTYPE HTML PUBLIC &quot;-//IFTF//DTD HTML 2.0//EN&quot;&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;403 Forbidden&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Forbidden&lt;/h1&gt;&lt;p&gt;You don\\`t have permission to access /file on this server.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; ​按理说 file 文件在 Apache 的静态页目录里，一般不会出现访问被拒绝的情况，但是它却返回了 permission denied 的错误提示页面，可以通过查看 1.监控 SELinux 冲突 里的两个文件来分析问题： 1234567[root@localhost ~]\\# tail /var/log/audit/audit.logtype=AVC msg=audit(1392944135.482:429): avc: denied &#123; getattr &#125; for pid=1609 comm=&quot;httpd&quot; path=&quot;/var/www/html/file&quot; dev=&quot;sda1&quot; ino=8980981 scontext=system_u:system_r:httpd_t:s0 tcontext=unconfined_u:object_r:admin_home_t:s0 tclass=file[root@localhost ~]\\# tail /var/log/messagesOct 8 10:18:20 localhost setroubleshoot: SELinux is preventing /usr/sbin/httpd from getattr access on the file. For complete SELinux messages, run `sealert -l 12345678-1234-5678-1234567890ab`. ​根据提示可以使用 sealert -l 12345678-1234-5678-1234567890ab 来查看更多信息，包括可能的解决办法： 123456789101112131415161718192021222324252627282930313233343536373839404142[root@localhost ~]\\# sealert -l 12345678-1234-5678-1234567890abSELinux is preventing /usr/sbin/httpd from getattr access on the file.***** Plugin catchall (100. confidence) suggests *****************************************If you believe that httpd should be allowed getattr access on the file by default.Then you should report this as a bug.You can generate a local policy module to allow this access. Doallow this access for now by executing:# grep httpd /var/log/audit/audit.log | audit2allow -M mypol# semodule -i mypol.ppAdditional Information:Source Context system_u:system_r:httpd_t:s0Target Context unconfined_u:object_r:admin_home_t:s0Target Objects [ file ]Source httpdSource Path /usr/sbin/httpdPort &lt;Unknown&gt;Host localhostSource RPM Packages httpd-2.4.6-14.el7.x86_64Target RPM PackagesPolicy RPM selinux-policy-3.12.1-124.el7.noarchSelinux Enabled TruePolicy Type targetedEnforcing Mode Enforcing......Raw Audit Messagestype=AVC msg=audit(1392944135.482:429): avc: denied &#123; getattr &#125; for pid=1609 comm=&quot;httpd&quot; path=&quot;/var/www/html/file&quot; dev=&quot;sda1&quot; ino=8980981 scontext=system_u:system_r:httpd_t:s0 tcontext=unconfined_u:object_r:admin_home_t:s0 tclass=filetype=SYSCALL msg=audit(1392944135.482:429): arch=x86_64 syscall=lstat success=no exit=EACCES a0=7f9fed0edea88 a1=7fff7bffc770 a2=7fff7bffc770 a3=0 items=0 ppid=1608 pid=1609 auid=4294967295 uid=48 gid=48 euid=48 suid=48 fsuid=48 egid=48 sgid=48 fsgid=48 tty=(none) ses=4294967295 comm=httpd exe=/usr/sbin/httpd subj=system_u:system_r:httpd_t:s0 key=(null)Hash: httpd,httpd_t,admin_home_t,file,getattr ​从该详细信息的 &quot;Raw Audit Messages&quot; 部分可以看出来目标文件 /var/www/html/file 正是问题所在：目标上下文 tcontext 并不属于 Web 服务器。可以使用 restorecon /var/www/html/file 命令修复此文件上下文。","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"使用 ACL 控制对文件的访问","slug":"Linux | 使用 ACL 控制对文件的访问","date":"2022-08-15T06:23:02.784Z","updated":"2022-08-15T06:32:10.133Z","comments":true,"path":"2022-08-15-Linux | 使用 ACL 控制对文件的访问.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E4%BD%BF%E7%94%A8%20ACL%20%E6%8E%A7%E5%88%B6%E5%AF%B9%E6%96%87%E4%BB%B6%E7%9A%84%E8%AE%BF%E9%97%AE.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 概述 ​ACL,即访问控制列表，它可以根据实际要求指定多个用户和组以不同的文件权限集来访问文件。借助 ACL，可以使用与常规文件权限相同的权限标志（读取、写入和执行）向由用户名、组名、UID 或 GID 标识的多个用户和组授予权限。除了文件所有者和文件的组从属关系之外，这些额外的用户和组分别被称为指定用户和指定组，因为他们不是在长列表中指定的，而在 ACL 中指定的。 ​用户可以对属于自己的文件和目录设置 ACL。被分配了 CAP_FOWNER Linux 功能的特权用户可以对任何文件或目录设置 ACL。新文件和子目录会自动从父目录的默认 ACL（若已设置）中继承 ACL 设置。与常规文件的访问规则相似，父目录层次结构至少需要其他搜索（执行）权限集，以便启用指定用户和指定组的访问权限。 ​挂载的文件系统需指定启用 ACL 支持，其中 XFS 文件系统内置有 ACL 支持，ext4 或 ext4 默认情况下会启用 acl 选项，但在早期版本中，应确认是否启用了 ACL 支持。要启用文件系统 ACL 支持，须在 mount 命令或 /etc/fstab 配置文件的文件系统条目中使用 ACL 选项。 查看 ACL 权限 ​使用 ls -l 命令仅查看文件最少的 ACL 设置详细信息： 1234567[root@localhost ~]\\# ls -ltotal 16-rw-r--r--. 1 root root 18 Sep 16 17:01 1-rw-------. 1 root root 2760 Jun 3 07:16 anaconda-ks.cfg-rw-------. 1 root root 2078 Jun 3 07:16 original-ks.cfg-rw-r--r--. 1 root root 140 Sep 16 17:31 tmp.sh# 权限列最后一个字符为加号(+)代表该文件上存在若干条目的拓展 ACL 结构，但我没找到这样的文件。 使用 chmod 命令更改具有 ACL 的文件的组权限则不会更改组所有者权限，而是更改 ACL 掩码。如果目的是更新文件的组所有者权限，需使用 setfacl -m g::perms &lt;file&gt;。 ​使用 getfacl &lt;file&gt; 查看文件的 ACL 详细信息。 123456789101112[root@localhost ~]\\# getfacl /run/log/journal/6651ee1da4824a37975cd5245c8cb076/system.journal getfacl: Removing leading &#x27;/&#x27; from absolute path names# file: run/log/journal/6651ee1da4824a37975cd5245c8cb076/system.journal# owner: root# group: systemd-journaluser::rw-group::r--group:adm:r--group:wheel:r--mask::r--other::--- 12345678[root@localhost ~]\\# getfacl .# file: .# owner: root# group: rootuser::r-xgroup::r-xother::--- ​一个进程能否访问文件，将按照以下规则应用文件权限和 ACL： 如果正在以文件所有者身份运行进程，则应用文件的用户 ACL 权限； 如果正在以指定用户 ACL 条目中列出的用户身份运行进程，则应指定用户 ACL 权限（只要掩码允许）； 如果正在以与文件的组所有者相匹配的组身份运行进程，或者以具有显示指定组 ACL 条目的组身份运行进程，则应用相匹配的 ACL 权限（只要掩码允许）； 否则，将应用文件的其他 ACL 权限。 当 systemd-journald 配置为使用持久存储时，系统管理员应在 /var/log/journal 文件夹上设置 ACL。 ​systemd-udevd 监听内核发出的设备事件，并根据 udev 规则处理每个事件，该服务的功能相当于 Windows 上的设备管理器。它根据一组 udev 规则，来启用某些设备的 uaccess 标记，如 CD/DVD 播放器或刻录机、USB 存储设备、声卡等等。每个登陆 GUI 的用户将会刷新热插拔设备的 ACL。 1234567891011[root@localhost ~]\\# getfacl /dev/sr0getfacl: Removing leading &#x27;/&#x27; from absolute path names# file: dev/sr0# owner: root# group: cdromuser::rw-user:student:rw-group::rw-mask::rw-other::--- 更改 ACL 权限 ​使用 setfacl -m &lt;acl&gt; file 或 setfacl -M &lt;file&gt; file 来修改文件的 acl 规则。（添加或修改、不会舍弃其他规则）。 1234567891011[root@localhost ~]\\# setfacl -m u:student:rwx tmp.sh[root@localhost ~]\\# getfacl tmp.sh# file: tmp.sh# owner: root# group: rootuser::rw-user:student:rwxgroup::r--mask::rwxother::r-- ​使用 setfacl --set &lt;acl&gt; file 或 setfacl --set-file &lt;file&gt; file 选项来完全替代文件的 acl 规则。（应用新规则，舍弃所有旧规则） ​通过管道将 fileA 文件的 ACL 规则应用至 fileB： 1[root@localhost ~]\\# getfacl fileA | setfacl --set-file=- fileB # - 可以指定使用 stdin 文件 ​使用 -R 选项可以递归的修改目录中文件的 ACL。 1[root@localhost ~]\\# setfacl -R -m u:name:rx directory ​使用 setfacl -x &lt;acl&gt; file 来删除 acl 条目： 1[root@localhost ~]\\# setfacl -x u:name, g:name file ​使用 setfacl -b file 来删除文件的所有 ACL 条目： 123456789[root@localhost ~]\\# setfacl -b tmp.sh[root@localhost ~]\\# getfacl tmp.sh# file: tmp.sh# owner: root# group: rootuser::rw-group::r--other::r-- ​为了确保在目录中创建的文件和目录继承特定的 ACL，须在目录上使用默认 ACL。 1[root@localhost ~]\\# setfacl -m d:u:name:rx directory ​使用 setfacl -k directory 命令删除目录的所有默认 ACL 条目。 1[root@localhost ~]\\# setfacl -k directory","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"系统性能调优","slug":"Linux | 系统性能调优","date":"2022-08-15T06:18:03.264Z","updated":"2022-08-15T06:20:03.403Z","comments":true,"path":"2022-08-15-Linux | 系统性能调优.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 概述 ​系统管理员可以基于多种用例工作负载来调整各种设备设置，以此优化系统性能。tuned 守护进程会利用反映特定工作负载要求的调优配置文件，以静态和动态两种方式应用调优调整。 静态调优 ​tuned 守护进程会在服务启动时或选择新的调优配置文件时应用系统设置。静态调优会对配置文件中由 tuned 在运行时应用的预定义 kernel 参数进行配置。对于静态调优而言，内核参数是针对整体性能预期而设置的，不会随着活跃度的变化而进行调整。 动态调优 ​对于动态调优而言，tuned 守护进程会监视系统活动，并根据运行时行为的变化来调整设置。从所选调优配置文件中声明的初始设置开始，动态调优会不断进行调优调整以适应当前工作负载。 配置文件 ​tuned 应用提供的配置文件分为以下几个类别： 节能型配置文件； 性能提升型配置文件； ​性能提升型配置文件中包括侧重于以下方面的配置文件： 存储和网络的低延迟； 存储和网络的高吞吐量； 虚拟机性能； 虚拟化主机性能。 调优配置文件 用途 balanced(均衡) 适合需要在节能和性能之间进行折衷的系统。 desktop 从 balanced 配置文件衍生而来。加快交互式应用响应速度。 throughput-performance 调优系统，以获得最大吞吐量。 latency-performance 适合需要牺牲能耗来获取低延迟的服务器系统。 network-latency 从 latency-performance 配置文件衍生而来。它可以启用额外的网络调优参数以提供低网络延迟。 network-throughput 从 throughput-performance 配置文件衍生而来。应用其他网络调优参数，以获得最大网络吞吐量。 powersave 调优系统，以最大程度实现节能。 oracle 基于 throughput-performance 配置文件，针对 oracle 数据库负载进行优化。 virtual-guest 当系统在虚拟机上运行时，调优系统以获得最高性能。 virtual-host 当系统充当虚拟机宿主机时，调优系统以获得最高性能。 ​除此之外还有：accelerator-performance、hpc-compute、intel-sst、optimize-serial-console 等配置文件。 从命令行管理调优配置文件 ​使用 tuned-adm 命令来更改 tuned 守护进程的设置。此命令可以查询当前设置、列出可用的配置文件、为系统推荐调优配置文件、直接更改配置文件或关闭调优。 ​系统管理员使用 tuned-adm active 来确定当前活动的调优配置文件。 12[root@localhost ~]\\# tuned-adm activeCurrent active profile: virtual-guest ​使用 tuned-adm list 命令可以列出所有可用的调优配置文件，包括内置的配置文件和系统管理员创建的自定义调优配置文件。 12345678910111213141516[root@localhost ~]\\# tuned-adm listAvailable profiles:- accelerator-performance - Throughput performance based tuning with disabled higher latency STOP states- balanced - General non-specialized tuned profile- desktop - Optimize for the desktop use-case- hpc-compute - Optimize for HPC compute workloads- intel-sst - Configure for Intel Speed Select Base Frequency- latency-performance - Optimize for deterministic performance at the cost of increased power consumption- network-latency - Optimize for deterministic performance at the cost of increased power consumption, focused on low latency network performance- network-throughput - Optimize for streaming network throughput, generally only necessary on older CPUs or 40G+ networks- optimize-serial-console - Optimize for serial console use.- powersave - Optimize for low power consumption- throughput-performance - Broadly applicable tuning that provides excellent performance across a variety of common server workloads- virtual-guest - Optimize for running inside a virtual guest- virtual-host - Optimize for running KVM guestsCurrent active profile: virtual-guest ​使用 tuned-adm profile &lt;profilename&gt; 激活更加符合当前机器调优要求的其它配置文件。 123[root@localhost ~]\\# tuned-adm profile desktop[root@localhost ~]\\# tuned-adm activeCurrent active profile: desktop ​使用 tuned-adm recommend 命令来获得系统推荐的调优配置文件，该机制用于在安装后确定系统的默认配置文件。 12[root@localhost ~]\\# tuned-adm recommendvirtual-guest ​使用 tuned-adm off 关闭 tuned-adm 调优。 123[root@localhost ~]\\# tuned-adm off[root@localhost ~]\\# tuned-adm activeNo current active profile. ​如需开启调优，使用 tuned-adm profile &lt;profilename&gt; 启用调优配置文件即可。 调优进程调度 ​计算机系统上运行的进程线程数超出了 CPU 数量，通过使用多任务技术，Linux 和其他操作系统可运行超出其处理单元数的进程。操作系统进程调度程序在单个核心上的进程之间快速切换，从而给人一种有多个进程在同时运行的印象。 ​不同进程的重要程度不同，进程调度程序可以配置为针对不同的进程采用不同的调度策略。常规系统上运行的大多数进程所使用的调度策略称为 SCHED_OTHER（也称为SCHED_NORMAL），但还有其他一些策略可满足各种各样的工作负载需求。为进程设置静态的 nice 值可以设置进程的静态优先度。Linux 的 nice 值范围为 -20 到 19，数值越大则优先级越低，默认情况下，进程将继承其父进程的 nice 级别，通常为 0，优先级较高的进程更加容易获得 CPU 资源。 查看进程的 nice 级别 ​使用 top 命令可通过交互方式查看和管理进程。该命令的输出默认显示 nice 级别（NI列）和优先级（PR列），在 top 界面中，nice 级别映射至内部系统优先级的关系是：NI值 + 20 = PR值。 123456789101112131415[root@localhost ~]\\# toptop - 14:55:11 up 6:11, 2 users, load average: 0.05, 0.01, 0.00Tasks: 333 total, 1 running, 332 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.5 us, 0.2 sy, 0.0 ni, 99.0 id, 0.0 wa, 0.2 hi, 0.2 si, 0.0 stMiB Mem : 3709.4 total, 1792.8 free, 1289.7 used, 626.9 buff/cacheMiB Swap: 2048.0 total, 2048.0 free, 0.0 used. 2169.3 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2374 student 20 0 2854124 180868 92620 S 0.7 4.8 0:22.67 gnome-shell 2010 gdm 20 0 2789052 159172 89064 S 0.3 4.2 0:13.35 gnome-shell 1 root 20 0 180464 14660 9212 S 0.0 0.4 0:06.62 systemd 2 root 20 0 0 0 0 S 0.0 0.0 0:00.09 kthreadd 3 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 rcu_gp 4 root 0 -20 0 0 0 I 0.0 0.0 0:00.00 rcu_par_gp . ...... ​使用 ps 命令搭配适当的选项也可以查看到进程的 nice 值，该命令结果中值为 - 的 nice 值代表该进程按照其他调度策略运行，并被调度程序解读为具有较高的优先级。进程采用的进程调度方式可在 CLS 列查看，其中 TS 代表采用了 SCHED_NORMAL 调度策略运行。 123456789[root@localhost ~]\\# ps axo pid,comm,cls,nice --sort=-nice PID COMMAND CLS NI 34 khugepaged TS 19 1017 alsactl IDL - 2763 tracker-miner-a IDL - 2764 tracker-miner-f TS 19 33 ksmd TS 5 1034 rtkit-daemon TS 1 .... ...... 以指定 nice 值启动某进程 ​使用 nice 命令来以指定 nice 值（默认为 10）来启动一个程序。 12345[root@localhost ~]\\# nice sha1sum /dev/zero &amp;[1] 6788[root@localhost ~]\\# ps -o pid,comm,nice 6788 PID COMMAND NI 6788 sha1sum 10 ​可以使用 -n 选项来指定 nice 值。 12345[root@localhost ~]\\# nice -n 20 sha1sum /dev/zero &amp; # 指定 nice 超出边界则会以边界值为准[1] 6808[root@localhost ~]\\# ps -o pid,comm,nice 6808 PID COMMAND NI 6808 sha1sum 19 更改运行中的进程的 nice 值 ​使用 renice 命令更改运行中的进程的 nice 值。 12[root@localhost ~]\\# renice -n 15 68086808 （process ID）old priority 19, new priority 15 ​也可以搭配 top 命令，在 top 界面中，按下 r 选项会提示：PID to renice [default pid = ****]，然后输入要更改的进程的 pid 和 nice 级别。 123456789101112top - 15:19:05 up 6:35, 2 users, load average: 0.00, 0.02, 0.04Tasks: 333 total, 1 running, 332 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.1 us, 0.1 sy, 0.0 ni, 99.6 id, 0.0 wa, 0.1 hi, 0.1 si, 0.0 stMiB Mem : 3709.4 total, 1792.2 free, 1290.1 used, 627.1 buff/cacheMiB Swap: 2048.0 total, 2048.0 free, 0.0 used. 2168.9 avail Mem PID to renice [default pid = 2522] PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2522 root 20 0 205208 32316 10372 S 0.2 0.9 0:49.24 sssd_kcm 1039 root 20 0 369624 12628 10504 S 0.1 0.3 0:34.17 vmtoolsd 2739 student 20 0 534444 38860 31804 S 0.1 1.0 0:34.34 vmtoolsd 6904 root 20 0 65620 5364 4328 R 0.1 0.1 0:00.04 top .... ......","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"管理临时文件","slug":"Linux | 管理临时文件","date":"2022-08-15T06:15:46.625Z","updated":"2022-08-15T06:17:04.932Z","comments":true,"path":"2022-08-15-Linux | 管理临时文件.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E7%AE%A1%E7%90%86%E4%B8%B4%E6%97%B6%E6%96%87%E4%BB%B6.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 概述 ​现代操作文件会在运行时产生大量的临时文件和目录，有些应用（和用户）会使用 /tmp 目录来保存临时数据，还有一些应用（和用户）则使用更特定于任务的位置，如守护进程以及 /run 下特定于用户的易失性（存储于内存，断电或重启丢失）目录。 ​为了保持系统充分运行，有必要创建那些不存在的目录和文件，因为守护进程和脚本可能会依靠它们的存在，而清除旧文件后就不会填满磁盘空间或提供错误信息。 ​RHEL 7 以上引入了一个名为 systemd-tmpfiles 的新工具，它提供了一种结构化和可配置的方法来管理临时目录和文件。在 systemd 启动系统后，其中一个最先启动的服务单元是 systemd-tmpfiles-setup。该服务运行命令 systemd-tmpfiles --create --remove。此命令从 /usr/lib/tmpfiles.d/*.conf、/run/tmpfiles.d/*.conf 和 /etc/tmpfiles.d/*.conf 读取配置文件。系统会删除这些配置文件中标记的要删除的任何文件和目录，并且会创建标记要创建（或修复权限）的任何文件和目录，并使其拥有正确的权限（如有必要）。 使用定时器清理临时文件 ​RHEL 内建了一个名为 systemd-tmpfiles-clean.timer 的 systemd 定时器单元定时触发 systemd-tmpfiles-clean.service 来执行 systemd-tmpfiles --clean 命令。 ​定时器 systemd-tmpfiles-clean.timer 文件的内容： 123456789101112131415161718# SPDX-License-Identifier: LGPL-2.1+# # This file is part of systemd.## systemd is free software; you can redistribute it and/or modify it# under the terms of the GNU Lesser General Public License as published by# the Free Software Foundation; either version 2.1 of the License, or# (at your option) any later version.[Unit]Description=Daily Cleanup of Temporary DirectoriesDocumentation=man:tmpfiles.d(5) man:systemd-tmpfiles(8)[Timer]# 表示 systemd-tmpfiles-clean.service 将在系统启动 15min 后被触发OnBootSec=15min# 表示在上一次激活服务单元 1d 后再次触发 systemd-tmpfiles-clean.serviceOnUnitActiveSec=1d ​服务单元 systemd-tmpfiles-clean.service 文件的内容： 123456789101112131415161718192021## This file is part of systemd.## systemd is free software; you can redistribute it and/or modify it# under the terms of the GNU Lesser General Public License as published by# the Free Software Foundation; either version 2.1 of the License, or# (at your option) any later version.[Unit]Description=Cleanup of Temporary DirectoriesDocumentation=man:tmpfiles.d(5) man:systemd-tmpfiles(8)DefaultDependencies=noConflicts=shutdown.targetAfter=local-fs.target time-sync.targetBefore=shutdown.target[Service]Type=oneshotExecStart=/usr/bin/systemd-tmpfiles --cleanSuccessExitStatus=65IOSchedulingClass=idle ​可以在 /etc/systemd/system 里更改 systemd-tmpfiles-clean.timer 的内容来定制自己的临时文件清理频率。 手动清理临时文件 ​命令 systemd-tmpfiles --clean 解析的配置文件与 systemd-tmpfiles --create 命令相同，但前者不会创建文件和目录，而是会清除在比配置文件中定义的最长期限更近的时间尚未访问、更改或修改的所有文件。 ​systemd-tmpfiles到的配置文件的基本语法由七列构成：”类型“、”路径“、”模式“、”UID“、”GID“、”期限“ 和 ”参数“。类型指的是 systemd-tmpfiles 应执行的操作；例如 d 表示创建还不存在的目录，或者 Z 表示以递归方式恢复 SELinux 上下文以及文件权限和所有权。示例： 123456d /run/systemd/seats 0755 root root -# 在创建文件和目录时，如果目录 /run/systemd/seats 还不存在，则创建该目录，所有者为用户 root 和组 root ，权限设置为 rwxr-x-r-x。系统不会自动清除该目录。D /home/student 0700 student student 1d# 如果目录 /home/student 还不存在，则创建该目录。如果存在，则清空其所有内容。运行 systemd-tmpfiles --clean 时，删除在超过一天时间内尚未被访问、更改或删除的所有文件。L /run/fstablink - root root - /etc/fstab# 创建指向 /etc/fstab 的符号链接 /run/fstab。绝对不要自动清除这一行。 配置文件优先级 ​配置文件可位于三个位置： /etc/tmpfiles.d/*.conf /run/tmpfiles.d/*.conf /usr/lib/tmpfiles.d/*.conf ​*/usr/lib/tmpfiles.d* 中的文件是由相关 RPM 软件包提供的，不应编辑这些文件。/run/tmpfiles.d/ 下的文件本身是易失性文件，通常由守护进程用来管理自己的运行时临时文件。/etc/tmpfiles.d/ 下的文件旨在供管理员配置自定义临时位置，以及覆盖供应商提供的默认值。 ​同名文件生效优先级：/etc/tmpfiles.d/ &gt; /run/tmpfiles.d/ &gt; /usr/lib/tmpfiles.d/。","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"设置任务计划","slug":"Linux | 设置计划任务","date":"2022-08-15T04:40:39.381Z","updated":"2022-08-15T04:42:56.774Z","comments":true,"path":"2022-08-15-Linux | 设置计划任务.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E8%AE%BE%E7%BD%AE%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 设置一次性任务 ​使用 at 命令可以设置在将来某个设定的点运行一个命令或一组命令。此命令的执行和生效依赖于 atd 服务，要使用该命令，请确保已经安装该软件包且 atd 服务已经启动。 ​使用 at 设置的任务会进入 a 到 z 26 个队列，作业按字母顺序排列，队列越往后则优先级越低。 用法 ​使用 at TIMESPEC 来设置新的作业： 123[root@localhost ~]\\# at now + 5minwarning: commands will be executed using /bin/shat&gt; # 接着输入自己想设置的命令，按 Ctrl + D 来完成输入 ​对于复杂的长串命令，使用重定向导入要比手动输入更方便，如： 1[root@localhost ~]\\# at now + 5min &lt; myscript.txt # 其中 myscript.txt 中已设置好要执行的命令 ​其中 TIMESPEC 的形式较为灵活，以下列出了一些可用的形式： now + 5min; teatime tomorrow;（下午茶时间为 16:00） noon + 4days; 5pm august 3 2021。 管理计划的任务 ​使用命令 atq 或 at -l 来获得当前用户的待处理作业的列表。 123[root@localhost ~]\\# at -l3 Fri Sep 17 11:04:00 2021 a root# 编号 日期 时间 所处的队列编号 作业所有者即执行者 ​使用命令 at -c JOBNUMBER 命令查看指定作业编号的计划作业的环境和执行内容。 123456[root@localhost ~]\\# at -c 3#!/bin/sh# atrun uid=0 gid=0# mail root 0umask 22...... ​使用命令 atrm JOBNUMBER 命令来删除计划的作业。 12[root@localhost ~]\\# atrm 3Cannot find jobid 3 使用 watch 命令可以设置每一段时间执行命令并将其结果输出到标准输出设备上。 设置周期性作业 ​使用 crontab 命令可以设置周期性执行的作业，此命令的设置和执行依赖于 crond 守护进程，crond 守护进程会读取多个配置文件（每个用户对应一个配置文件）以及一组系统范围内的文件。这些配置文件使用户和管理员拥有细微的控制权，可以控制应执行周期作业的时间。 用法 命令 用途 crontab -l 列出当前用户的计划作业 crontab -r 删除当前用户的所有作业 crontab -e 编辑当前用户的作业 crontab filename 删除所有作业，并替换为从 filename 读取的作业。如果没有指定文件，则使用 stdin。 Root 用户可以使用 crontab -u &lt;USER&gt; 命令来管理其他用户的作业，不应以 root 用户直接设置系统作业，而应通过修改 /etc/crontab 配置文件。 ​crontab -e 命令会默认调用 vim 编辑器（除非 EDITOR 环境变量指定其他设置）来编辑任务计划设置文件，每行只输入一个作业，除此之外也可使用注释、变量以及空行。其中常见变量的设置包括 SHELL 变量和 MAILTO 变量。 ​Crontab 文件中的字段按以下顺序显示：分钟、小时、日、月、星期、命令。 若指定的日和星期都不是 *，则该命令会在每个指定的日期或星期执行。 ​前五个字段全部使用相同的语法规则： * 表示 “无关紧要” 或始终； 数字 可用于指定不同时间概念，特别是 1-6 分别表示星期一至星期六，0 或 7 都可以代表星期天； x-y 表示范围，(x，y]； x,y 表示列表，列表也可包含范围，如分钟列可以设置成 5, 10-13, 17； */x 表示每 x 时间的间隔，如指定分钟列 */7 代表每 7 分钟运行一次作业。 ​此外，月份和星期也可以使用三个字母的缩写来表示，如：Jan、Feb、Mar...以及 Mon、Tue、Wed...。 命令字段中若包含未转义的 % 符号，则该百分比符号将被当作换行字符，且百分比之后的所有内容将传给 stdin 中的命令。 作业示例 ​以下作业将在每年 2 月 2 日上午 9 点准点执行命令 /usr/local/bin/yearly_backup。 10 9 2 2 * /usr/local/bin/yearly_backup ​以下作业将在每个工作日午夜前的两分钟运行命令 /usr/local/bin/daily_report。 158 23 * * 1-5 /usr/local/bin/daily_report ​以下作业将在每个工作日（周一到周五）上午 9 点执行 mutt 命令，从而将邮件消息 Checking in 发送给收件人 boss@example.com 。 10 9 * * 1-5 mutt -s &quot;Check in&quot; boss@example % Hi there boss, just checking in. 周期性系统作业 ​这部分内容可以参考文章：https://cloud.tencent.com/developer/article/1619542，写的非常详细。 ​系统管理员经常需要运行周期性作业，最佳的做法是从系统账户而不是从用户账户运行这些作业，即不用使用 crontab 命令来安排这些作业，而是要使用系统范围的 crontab 文件。 ​/etc/crontab 文件的语法跟普通用户创建 crontab 任务类似，crontab 文件中需额外指定一个用户字段： 12345678910[root@localhost ~]\\# cat /etc/crontab | grep ^# # For details see man 4 crontabs# Example of job definition:# .---------------- minute (0 - 59)# | .------------- hour (0 - 23)# | | .---------- day of month (1 - 31)# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * user-name command to be executed ​周期性系统作业可以在两个位置定义：/etc/crontab 文件和 /etc/cron.d 目录中的自定义文件（推荐）。除此之外，crontab 系统中还包含需要每小时、每天、每周和每月运行的脚本的存储库，这些存储库分别对应于名为 /etc/cron.hourly、/etc/cron.daily、/etc/cron.weekly、/etc/cron.monthly 的目录。这些目录中存放的是脚本文件而不是 crontab 配置文件。 这些文件夹中的脚本文件需要被授予执行权限，否则将不会触发。 ​为了处理由于系统关机等某些原因导致的一些任务计划由于超出时间范围而未被 crontab 执行的问题，anacron 被引入，anacron 每小时被 crond 服务执行一次以检查一些任务计划是否在设定的时间执行，若有则执行该任务，待执行完毕或者无任何逾期的任务计划时就会结束 anacron 进程。 ​在 /etc/cron.hourly 可以找到 anacron 的配置执行文件： 123456789101112131415161718192021222324252627#!/bin/sh# Check whether 0anacron was run today alreadyif test -r /var/spool/anacron/cron.daily; then day=`cat /var/spool/anacron/cron.daily`fiif [ `date +%Y%m%d` = &quot;$day&quot; ]; then exit 0fi# Do not run jobs when on battery poweronline=1for psupply in AC ADP0 ; do sysfile=&quot;/sys/class/power_supply/$psupply/online&quot; if [ -f $sysfile ] ; then if [ `cat $sysfile 2&gt;/dev/null`x = 1x ]; then online=1 break else online=0 fi fidoneif [ $online = 0 ]; then exit 0fi/usr/sbin/anacron -s SYSTEMD 定时器 一些操作系统设定的计时器 12345678[root@localhost etc]\\# systemctl status *timer● dnf-makecache.timer - dnf makecache --timer Loaded: loaded (/usr/lib/systemd/system/dnf-makecache.timer; enabled; vendor preset&gt; Active: active (waiting) since Fri 2021-09-17 09:07:25 CST; 6h ago Trigger: Fri 2021-09-17 16:23:21 CST; 36min leftSep 17 09:07:25 localhost.localdomain systemd[1]: Started dnf makecache --timer....... 自定义定时器 ​在 /etc/systemd/system 下添加自定义定时器单元配置文件，并添加如下配置： 1234567891011121314151617[Unit]Description=”对该定时器功能的描述“[Timer]# 任务执行的时间OnCalendar=*-*-* *:*:00 # 精度（秒），允许浮动的偏差AccuracySec=24h# 是否Persistent=true# 最大随机延迟时间#RandomizedDelaySec=14400# 定时器被激活时执行的服务Requires=MyService.service[Install]WantedBy=timers.target","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"提高命令行生产效率","slug":"Linux | 提高命令行生产效率","date":"2022-08-15T04:31:08.599Z","updated":"2022-08-15T04:35:30.416Z","comments":true,"path":"2022-08-15-Linux | 提高命令行生产效率.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E6%8F%90%E9%AB%98%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%94%9F%E4%BA%A7%E6%95%88%E7%8E%87.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 编写简单的 BASH 脚本 ​Shell 脚本可以大幅提高工作效率，对处理重复、复杂的任务很有用。精通 Shell 脚本编写是 Linux 从业者的基本要求。 ​Shell 脚本是一个可执行文件，其内容是一系列命令和逻辑的集合。 ​Shell 脚本的第一行以 “#!” 开头，后面跟为执行该脚本的内容时所需要的正确的命令解释器的绝对路径，如： 1#!/bin/bash ​Shell 脚本必须被赋予执行权限，才能作为常规命令运行。使用 chmod 命令可为其添加执行权限，并且可能需要与 chown 命令组合来更改脚本的文件所有权，仅为脚本的目标用户授予执行权限。 ​将脚本放在 shell 的 PATH 环境变量中所列出的某个目录下，则可以像其他命令那样单独用文件名来调用 shell 脚本。但应注意自己编写的脚本名需要区别于 linux 系统命令或已有的脚本文件。 编写脚本的两个须知点 特殊字符的字面化处理 ​一些字符或词语对 shell 来说有特殊含义，在使用这些字符和词语的时候如果只想用其字面值的话则需要以下三种方法来取消或转义对应特殊字符或词语。 ​前缀转义字符来输出 # 号： 1234[root@localhost ~]\\# echo #1 is here[root@localhost ~]\\# echo \\#1 is here\\#1 is here # md 格式冲突，请忽略输出结果中的转义符号，下同 使用单引号括起需要多次转义的语句而不用分别进行转义： 1234[root@localhost ~]\\# echo \\#1 is here, but where is \\#2?\\#1 is here, but where is \\#2?[root@localhost ~]\\# echo &#x27;#1 is here, but where is #2&#x27;\\#1 is here, but where is \\#2 ​使用双引号可以阻止通配和 shell 扩展，但依然允许命令和变量替换，单引号则进一步不允许命令和变量替换。问号也是一个需要防止扩展的元字符。 12345678910111213141516[root@localhost ~]\\# var=$(hostname -s); echo $var # 将命令的执行结果进行变量赋值： VAR=$&#123;COMMAND&#125;localhost[root@localhost ~]\\# echo &quot;****** hostname is $&#123;var&#125; ******&quot;****** hostname is localhost ******[root@localhost ~]\\# echo Your username variable is \\$USER. # 对 $ 进行了转义、因而 $ 失去了原有作用Your username variable is $USER.[root@localhost ~]\\# echo &quot;Variable $var is evaluate to $(hostname -s)&quot;Variable localhost is evaluate to localhost[root@localhost ~]\\# echo &#x27;Variable $var is evaluate to $(hostname -s)&#x27;Variable $var is evaluate to $(hostname -s)[root@localhost ~]\\# echo &quot;\\&quot;Hello,world and $var\\&quot;&quot;; echo &#x27;&quot;Hello,world and $var&quot;&#x27;&quot;Hello,world and localhost&quot;&quot;Hello,world and $var&quot;[root@localhost ~]\\# echo &quot;&#x27;Hello,world and $var&#x27;&quot;; echo \\&quot;&quot;Hello,world and $var&quot;\\&quot;&#x27;Hello,world and localhost&#x27;&quot;Hello,world and localhost&quot; 多使用 echo 命令来输出执行状态信息 ​最好将普通提示信息输出至标准输出，而将错误信息输出至错误输出。 123456#!/bin/bash......echo &quot;Something has done!&quot;;......echo &quot;Error: Something went wrong and need to exit!&quot; &gt;&amp;2;...... 脚本编写之循环 ​Bash 的 for 循环结构使用以下语法： 123for VARIABLE in LIST; doCOMMAND VARIABLEdone ​以下语句的输出结果是一样的： 12345678910# 语句一[root@localhost ~]\\# for HOST in host1 host2 host3; do echo $HOST; done# 语句二[root@localhost ~]\\# for HOST in host&#123;1,2,3&#125;; do echo $HOST; done# 语句三[root@localhost ~]\\# for HOST in host&#123;1...3&#125;; do echo $HOST; done# 输出结果host1host2host3 ​查询安装的跟内核相关的包并输出其安装时间： 123456789101112[root@localhost ~]\\# for PKG in $(rpm -qa | grep &quot;kernel&quot;); \\do echo &quot;$PKG was installed in $(date -d @$(rpm -q --qf &quot;%&#123;INSTALLTIME&#125;\\n&quot; $PKG))&quot;; \\donekernel-tools-4.18.0-240.el8.x86_64 was installed in Thu Jun 3 07:08:19 CST 2021kernel-core-4.18.0-240.el8.x86_64 was installed in Thu Jun 3 07:05:38 CST 2021kernel-tools-libs-4.18.0-240.el8.x86_64 was installed in Thu Jun 3 07:04:20 CST 2021abrt-addon-kerneloops-2.10.9-20.el8.x86_64 was installed in Thu Jun 3 07:08:21 CST 2021kernel-modules-4.18.0-240.el8.x86_64 was installed in Thu Jun 3 07:06:03 CST 2021kernel-devel-4.18.0-240.el8.x86_64 was installed in Thu Jun 3 07:10:07 CST 2021kernel-4.18.0-240.el8.x86_64 was installed in Thu Jun 3 07:09:28 CST 2021kernel-headers-4.18.0-240.el8.x86_64 was installed in Thu Jun 3 07:04:49 CST 2021# date -d @时间戳 # 将某一时间戳（1970 年 01 月 01 日 08 时整起经过的秒数）转换成标准日期格式 ​输出 2 - 10 之间的所有偶数： 1234567[root@localhost ~]\\# for EVEN in $(seq 2 2 10); do echo &quot;$EVEN&quot;; done246810# seq 命令：生成数字序列。seq 2 2 10，从 2 开始，每次增加 2，直至 10。 ​一个疑问： 12345678910# 这是为啥？[root@localhost ~]\\# for VAR in var&#123;$(seq -s , 0 1 5)&#125;; do echo $VAR; donevar&#123;0,1,2,3,4,5&#125;[root@localhost ~]\\# for NUM in $(seq 0 1 5); do echo var$NUM; done var0var1var2var3var4var5 ​Shell 脚本在处理完自己的所有内容后，脚本会退出到调用它的进程。若需在脚本执行完成之前退出执行，可以通过在脚本中使用 exit 命令来实现。可以为 exit 命令指定一个参数来表明整个操作的执行状态，其中 0 代表成功执行，其他非零值均代表存在错误。可以使用不同的非零值来代表不同的错误类型，退出后，该命令、脚本进程的执行结果将传回父进程，可以访问变量 ？ 来获取子进程的执行结果。如： 1234[root@localhost ~]\\# rmdir DirThatNotExistedrmdir: failed to remove &#x27;DirThatNotExisted&#x27;: No such file or directory[root@localhost ~]\\# echo $? # ？变量的值是随时根据子进程的执行结果改变的1 如果不使用任何参数调用 exit 命令，那么脚本将退出并且将最后执行的命令的退出状态传递给父进程。 为确保脚本不会由于意外情况轻易中断，一种良好的做法是不要进行与输入有关的假设，如命令行参数、用户输入、命令替换、变量扩展及文件名扩展。可以使用 Bash 的 test 命令来执行完整性检查。 ​与所有命令一样，test 命令会在完成后生成一个退出代码，该退出代码存储为值 $?。要查看测试的结论，请在执行 test 命令后立即显示 $? 的值。 常用运算符 ​Bash 测试命令语法：[&lt;TESTEXPRESSION&gt;]，较新的扩展测试命令：[&lt;TESTEXPRESSION&gt;]（Bash 2.02 及更高版本可用，可提供诸如通配模式匹配和正则表达式模式匹配等功能）。 算数比较运算符 比较运算符 描述 示例 num1 -eq num2 等于 [ 1 -eq 1 ] num1 -ne num2 不等于 [ 1 -ne 1 ] num1 -lt num2 小于 [ 1 -lt 2 ] num1 -le num2 小于等于 [ 2 -le 2 ] num1 -gt num2 大于 [ 8 -gt 2 ] num1 -ge num2 大于等于 [ 2 -gt 2 ] 1234567891011121314[root@localhost ~]\\# [ 1 -eq 1 ]; echo $? # -eq：等于，1 等于 1 ？0 # true[root@localhost ~]\\# [ 1 -ne 1 ]; echo $? # -ne：不等于，1 不等于 1 ？1 # false[root@localhost ~]\\# [ 8 -gt 2 ]; echo $? # -gt：大于，8 大于 2 ？0 # true[root@localhost ~]\\# [ 2 -ge 2 ]; echo $? # -ge：大于等于，2 大于等于 2 ？0 # true[root@localhost ~]\\# [ 2 -lt 2 ]; echo $? # -lt：小于，2 小于 2 ？1 # false[root@localhost ~]\\# [ 1 -lt 2 ]; echo $? # -lt：小于，1 小于 2 ？0 # true[root@localhost ~]\\# [ 1 -le 2 ]; echo $? # -le：小于等于，1 小于等于 2 ？0 # true 字符串比较运算符 注意引号的使用，这是防止空格扰乱代码的好方法。[ ] 语句中两侧的空格以及运算符两侧的空格是必须的。 比较运算符 描述 示例 -z string 若 string 长度为 0，则为真 [ -z &quot;$MyVariable&quot; ] -n string 若 string 长度为 0，则为真 [ -n &quot;$MyVariable&quot; ] string1 = string2 若 string1 与 string2 相同，则为真 [ &quot;$MyVariable&quot; = &quot;Some words&quot; ] string1 != string2 若 string1 与 string2 不同，则为真 [ &quot;$MyVariable&quot; != &quot;Some words&quot; ] string1 == string2 若 string1 与 string2 相同，则为真 [ &quot;$MyVariable&quot; == &quot;Some words&quot; ] 12345678910[root@localhost ~]\\# [ abc = abc ]; echo $?0[root@localhost ~]\\# [ abc == def ]; echo $?1[root@localhost ~]\\# [ abc != def ]; echo $?0[root@localhost ~]\\# [ -z &quot;&quot; ]; echo $?0[root@localhost ~]\\# [ -n &quot;&quot; ]; echo $?1 文件比较运算符 比较运算符 描述 示例 -e filename 若 filename 存在，则为真 [ -e /var/log/syslog ] -d filename 若 filename 存在，则为真 [ -d /tmp/mydir ] -f filename 若 filenamee 为常规文件，则为真 [ -f /usr/bin/grep ] -L filename 若 filename 为符号链接，则为真 [ -L /usr/bin/grep ] -r filename 若 filename 为可读，则为真 [ -r /var/log/syslog ] -w filename 若 filename 为可写，则为真 [ -w /root/log.txt ] -x filename 若 filename 为可执行，则为真 [ -x /usr/bin/grep ] filename1 -nt filename2 若 filename1 比 filename2 新，则为真 [ /tmp/install/etc/services -nt /etc/services ] filename1 -ot filename2 若 filename1 比 filename2 旧，则为真 [ /boot/bzImage -ot arch/i386/boot/bzImage ] 123456789101112131415161718[root@localhost ~]\\# [ -e /var/log/syslog ]; echo $?1[root@localhost ~]\\# [ -d /tmp/mydir ]; echo $?1[root@localhost ~]\\# [ -f /usr/bin/grep ]; echo $?0[root@localhost ~]\\# [ -L /usr/bin/grep ]; echo $?1[root@localhost ~]\\# [ -r /var/log/syslog ]; echo $?1[root@localhost ~]\\# [ -w /root/log.txt ]; echo $?1[root@localhost ~]\\# [ -x /usr/bin/grep ]; echo $?0[root@localhost ~]\\# [ /tmp/install/etc/services -nt /etc/services ]; echo $?1[root@localhost ~]\\# [ /boot/bzImage -ot arch/i386/boot/bzImage ]; echo $?1 脚本编写之条件 ​Bash 中最简单的 if 条件判断语句的格式如下： 1234if &lt;CONDITION&gt;; then &lt;STATEMENT&gt; ...fi ​以下代码段演示使用 if 语句判断若 psacct 服务未处于活动状态则启动该服务： 123[root@localhost ~]\\# systemctl is-active psacct &gt; /dev/null 2&gt;&amp;1[root@localhost ~]\\# if [ $? -ne 0 ]; then sudo systemctl start psacct; fi[root@localhost ~]\\# ​两条线的 if 条件判断语句： 1234567if &lt;CONDITION&gt;; then &lt;STATEMENT&gt; ...else &lt;STATEMENT&gt; ...fi ​以下代码段演示了使用 if/then/else 语句来启动 psacct 服务（若其未处于活动状态）和停止该服务（如果其处于活动状态）。 123456[root@localhost ~]\\# systemctl is-active psacct &gt; /dev/null 2&gt;&amp;1[root@localhost ~]\\# if [ $? -ne 0 ]; then \\&gt; sudo systemctl start psacct \\&gt; else \\&gt; sudo systemctl stop psacct \\&gt; fi ​多线的 if 条件判断语句： 12345678910if &lt;CONDITION&gt;; then &lt;STATEMENT&gt; ...elif &lt;CONDITION&gt;; then &lt;STATEMENT&gt; ...else &lt;STATEMENT&gt; ...fi ​以下代码段演示了使用 if/then/elif/then/else 语句来运行 mysql 客户端（若 mariadb 服务处于活动状态），运行 psql 客户端（若 postgresql 服务处于活动状态）或运行 sqlite3 客户端（若 mariadb 和 postgresql 服务均未处于活动状态）。 1234567891011[root@localhost ~]\\# systemctl is-active mariadb &gt; /dev/null 2&gt;&amp;1[root@localhost ~]\\# MARIADB_ACTIVE=$?[root@localhost ~]\\# sudo systemctl is-active postgresql &gt; /dev/null 2&gt;&amp;1[root@localhost ~]\\# POSTGRESQL_ACTIVE=$?[root@localhost ~]\\# if [ &quot;$MARIADB_ACTIVE&quot; -eq 0 ]; then \\&gt; mysql \\&gt; elif [ &quot;$POSTGRESQL_ACTIVE&quot; -eq 0 ]; then \\&gt; psql \\&gt; else \\&gt; sqlite3 \\&gt; fi 使用正则表达式 ​用法可以参考此网站：https://regexr.com/。 ​查看配置文件时忽略注释和空白行： 12345678[root@localhost ~]\\# cat /etc/ssh/sshd_config | grep -v &quot;#&quot; | grep -v ^$HostKey /etc/ssh/ssh_host_rsa_keyHostKey /etc/ssh/ssh_host_ecdsa_keyHostKey /etc/ssh/ssh_host_ed25519_keySyslogFacility AUTHPRIVPermitRootLogin yesAuthorizedKeysFile .ssh/authorized_keys......","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"访问 Linux 文件系统","slug":"Linux | 访问 Linux 文件系统","date":"2022-08-15T04:10:23.992Z","updated":"2022-08-15T04:15:07.355Z","comments":true,"path":"2022-08-15-Linux | 访问 Linux 文件系统.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E8%AE%BF%E9%97%AE%20Linux%20%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 文件系统和存储设备 ​Linux 服务器上的文件是按照文件系统层次结构（一棵颠倒的目录树）访问的，不同目录下的文件可能存储在不同的存储设备下。某个存储设备的文件系统要想接入当前系统的文件系统中需要将其挂载到当前系统文件系统中的某个空目录上，该目录被称为 “挂载点”。进行挂载后便可以访问该设备存储的文件，该挂载点相当于该存储设备的根目录。 文件系统、存储和块设备 ​在 Linux 中，对存储设备的低级别访问是由一种称为块设备的特殊类型文件提供的。在挂载这些设备前，必须先使用文件系统对其进行格式化。 ​块设备文件和其他的设备文件一起存储在 /dev 目录中。设备文件是由操作系统自动创建的。在红帽企业 Linux 中，检测到的第一个 SATA/PATA 、SAS、SCSI 或 USB 硬盘驱动器被称为 /dev/sda，第二个被称为 /dev/sdb，以此类推。这些名称代表整个硬盘驱动器。 设备类型 设备命名模式 SATA/SAS/USB 附加存储 /dev/sda、/dev/sdb... virtio-blk 超虚拟化存储（部分虚拟机） /dev/nvme0、/dev/nvme1 NVMe 附加存储（很多 SSD） /dev/nvme0、/dev/nvme1 SD/MMC/eMMC 存储（SD卡） /dev/mmcblk0、/dev/mmcblk1 最新的 virtio-scsi 超虚拟化存储技术对应的命名形式为 /dev/sd*。 磁盘分区和逻辑卷 ​一块磁盘可能会被分为若干个分区以实现不同用途的存储需求，如系统分区、用户主目录分区、交换分区、启动分区等。这些分区的本质也是块设备，其命名形式为：sd*n、nvmempn（n 代表第几个分区）等。 ​整理磁盘和分区的另一种方式是通过逻辑卷管理（LVM）。通过 LVM，一个或多个块设备可以汇集为一个存储池，称为卷组。然后，卷组中的磁盘空间被分配到一个或多个逻辑卷，它们的功能等同于驻留在物理磁盘上的分区。LVM 系统在创建时为卷组和逻辑卷分配名称。LVM 在 /dev 中创建一个名称与组名匹配的目录，然后在该新目录中创建一个与逻辑卷同名的符号链接。之后，可以挂载该逻辑卷文件。例如，如果一个卷组名 myvg，其中有一个名为 mylv 的逻辑卷，那么其逻辑卷设备文件的完整路径名为 /dev/myvg/mylv。 逻辑卷设备的命名形式实际上是建立与实际设备文件的符号链接，以此来访问该文件，其名称在每次启动时可能会有所不同。还有一种逻辑卷设备的命名形式，那就是与常用的 /dev/mapper 中的文件建立链接，也是一种与实际设备文件的符号链接。 检查文件系统 ​使用 df 命令对本地和远程文件系统设备及可用空间大小可以有个简略了解。 12345678910[root@localhost ~]\\# dfFilesystem 1K-blocks Used Available Use% Mounted ondevtmpfs 1880292 0 1880292 0% /devtmpfs 1899208 0 1899208 0% /dev/shmtmpfs 1899208 9884 1889324 1% /runtmpfs 1899208 0 1899208 0% /sys/fs/cgroup/dev/nvme0n1p3 18555904 4878480 13677424 27% //dev/nvme0n1p1 301728 178008 123720 59% /boottmpfs 379840 1168 378672 1% /run/user/42tmpfs 379840 0 379840 0% /run/user/0 ​其中 tmpfs 和 devtmpfs 设备是系统内存中的文件系统，在系统重启后，写入 tmpfs 或 devtmpfs 的文件都会消失。 ​使用选项 -h【单位为 KiB（2^10）、MiB（2^20）或GiB（2^30）】或选项 -H【单位为 KB(10^3)、MB(10^6)或GB(10^9)。 1234567891011[root@localhost ~]\\# df -hFilesystem Size Used Avail Use% Mounted ondevtmpfs 1.8G 0 1.8G 0% /devtmpfs 1.9G 0 1.9G 0% /dev/shmtmpfs 1.9G 9.6M 1.9G 1% /runtmpfs 1.9G 0 1.9G 0% /sys/fs/cgroup/dev/nvme0n1p3 18G 4.7G 14G 27% //dev/nvme0n1p1 295M 174M 121M 59% /boottmpfs 371M 1.2M 370M 1% /run/user/42tmpfs 371M 0 371M 0% /run/user/0-i, --inodes # 输出 inodes 数而不是大小 ​使用 du 命令查看某一特定目录树使用的空间的详细信息，同 df，其也有 -h 和 -H 两个选项。 12345678910[root@localhost ~]\\# du /home/student/.config64 /home/student/.config/pulse0 /home/student/.config/gnome-session/saved-session0 /home/student/.config/gnome-session......[root@localhost ~]\\# du -h /home/student/.config64K /home/student/.config/pulse0 /home/student/.config/gnome-session/saved-session0 /home/student/.config/gnome-session...... 挂载和卸载文件系统 手动挂载文件系统 ​要在系统中挂载某个存储设备才能访问其内容，使用 mount 命令来手动挂载某个存储设备。 12mount -a [options] # 挂载 /etc/fstab 配置文件中涉及的所有配置mount [options] &lt;source&gt; &lt;directory&gt; # 将设备文件系统挂载到目录 ​其中，指定设备时既可以使用 /dev 目录中的设备名称也可以使用格式化文件系统时产生的 UUID。 查看系统连接的块设备 ​使用 lsblk 命令来列出指定块设备或所有可用块设备的详细信息： 1234567[root@localhost ~]\\# lsblk # 不会列出临时内存文件系统 tmpfsNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsr0 11:0 1 1024M 0 rom nvme0n1 259:0 0 20G 0 disk ├─nvme0n1p1 259:1 0 300M 0 part /boot├─nvme0n1p2 259:2 0 2G 0 part [SWAP]└─nvme0n1p3 259:3 0 17.7G 0 part / 按块设备名称挂载 ​以下命令将 /dev/sdb1 设备挂载到 /mnt/data 目录中。 1[root@localhost ~]\\# mount /dev/sdb1 /mnt/data ​若要挂载成功，目标目录必须存在，默认情况下，/mnt 目录存在并用作临时挂载点，可以将 /mnt 目录用作临时挂载点（创建 /mnt 的一个子目录会更好）。 若系统调整过存储设备则操作系统检测磁盘的顺序可能会发生变化，将会导致存储设备的名称的改变，最好通过以下方式（按照文件系统 UUID 挂载）进行挂载。 按文件系统 UUID 挂载 ​UUID 即通用唯一识别码，它唯一性的代表某个事物，可用作某个存储设备上的文件系统的唯一性标识。使用 lsblk -fp 命令可以列出设备的完整路径、其 UUID 和挂载点，以及分区中文件系统的类型。如果未挂载文件系统，则挂载点将为空。 1234567[root@localhost ~]\\# lsblk -fpNAME FSTYPE LABEL UUID MOUNTPOINT/dev/sr0 /dev/nvme0n1 ├─/dev/nvme0n1p1 xfs 529dd49b-7b72-4394-8fbb-98eb7f24de1e /boot├─/dev/nvme0n1p2 swap bb97577f-bf23-4a75-8ff1-46b7dce21eb9 [SWAP]└─/dev/nvme0n1p3 xfs 360e2f42-d6de-4209-8487-f36b7cc69cc2 / ​根据文件系统的 UUID 挂载文件系统。 1[root@localhost ~]\\# mount UUID=&quot;360e2f42-d6de-4209-8487-f36b7cc69cc2&quot; / 自动挂载可移动存储设备 ​登陆图形界面插入任何可移动存储时会自动挂载。可移动存储设备将挂载到 /run/media/USERNAME/LABEL，其中 USERNAME 是登陆图形界面环境的用户名，而 LABEL 是一个标识符，通常是创建时给文件系统取的名称（如果存在）。在移除设备之前，应手动将它卸载。 卸载文件系统 ​关机和重新启动过程会自动卸载所有文件系统，在此过程中，缓存在内存中的任何文件系统数据都将会刷新到存储设备中，从而确保文件系统不会遭受数据损坏。 文件系统数据通常缓存在内存中。因此，为了避免损坏磁盘上的数据，务必先卸载可移动驱动器，然后再拔下它们。卸载过程会在释放驱动器之前同步数据，以确保数据完整性。 ​使用 umount 命令来卸载设备，该命令需要挂载点作为参数。 1[root@localhost ~]\\# umount /mnt/data ​正在使用的文件系统将无法成功卸载，若要成功执行上述命令，则所有进程都需要停止访问卸载点下的数据。 ​使用 lsof 命令可以列出所给目录中所有打开的文件以及访问它们的进程。 1234567[root@localhost ~]\\# lsof /rootCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEbash 3082 root cwd DIR 259,3 219 33575041 /rootsftp-serv 3123 root cwd DIR 259,3 219 33575041 /rootsftp-serv 3123 root 8r DIR 259,3 219 33575041 /rootlsof 3794 root cwd DIR 259,3 219 33575041 /rootlsof 3795 root cwd DIR 259,3 219 33575041 /root 常见的无法卸载的原因是当前命令行的工作目录处于挂载点或其子目录中，将工作目录切换到挂载点之外即可解决此问题。 查找系统中的文件 搜索文件 ​使用 locate 和 find 命令进行文件系统层次结构中搜索文件的操作。 locate 命令搜索预生成索引中的文件名或文件路径，并即使返回结果； find 命令通过爬取整个文件系统层次结构来实时搜索文件。 根据名称查找文件 ​使用 locate 命令搜索文件会比较快速，因为它是从 mlocate 数据库中查找的信息，但是该数据库是每日自动更新的而不是实时更新的，root 用户可以通过命令 updatedb 来强制更新数据库。 1[root@localhost ~]\\# updatedb ​普通用户的搜索结果会根据用户的访问权限作出限制。 1234567[root@localhost ~]\\# locate Desktop # 子串匹配/home/student/Desktop/usr/lib/python3.6/site-packages/xdg/DesktopEntry.py/usr/lib/python3.6/site-packages/xdg/__pycache__/DesktopEntry.cpython-36.opt-1.pyc/usr/lib/python3.6/site-packages/xdg/__pycache__/DesktopEntry.cpython-36.pyc/usr/lib64/girepository-1.0/GDesktopEnums-3.0.typelib...... ​使用 -i 选项来忽略大小写限制，-n 选项来限制命令返回的搜索结果数量： 123456[root@localhost ~]\\# locate -i -n 5 messages /usr/lib/locale/C.utf8/LC_MESSAGES/usr/lib/locale/C.utf8/LC_MESSAGES/SYS_LC_MESSAGES/usr/lib/locale/en_AG/LC_MESSAGES/usr/lib/locale/en_AG/LC_MESSAGES/SYS_LC_MESSAGES/usr/lib/locale/en_AU/LC_MESSAGES 实时搜索文件 ​使用 find 命令实时遍历整个文件系统来查找文件。它比 locate 更慢得到搜索结果但是会更准确，它不仅支持搜索文件名，还支持根据文件的权限、类型、大小或修改时间来搜索文件。 ​find 命令查看文件及目录的权限与执行该命令的用户保持一致。 12find [options] [path...] [expression] # find 命令格式# 默认 path 为当前目录，默认 expression 为 -print（即打印搜索结果） 按照文件名搜索文件 123456789101112[root@localhost ~]\\# find / -name ssh_config/etc/ssh/ssh_config[root@localhost ~]\\# find /home/student -name &quot;*.txt&quot; | head -n 5 # 使用通配符/home/student/.mozilla/firefox/uf3n2m6z.default-default/pkcs11.txt/home/student/.mozilla/firefox/uf3n2m6z.default-default/SiteSecurityServiceState.txt/home/student/.mozilla/firefox/uf3n2m6z.default-default/SecurityPreloadState.txt/home/student/.mozilla/firefox/uf3n2m6z.default-default/TRRBlacklist.txt/home/student/.mozilla/firefox/uf3n2m6z.default-default/AlternateServices.txt[root@localhost ~]\\# find /usr/share -iname &quot;*messages&quot; | head -n 3 # iname 忽略用户名大小写/usr/share/locale/af/LC_MESSAGES/usr/share/locale/az/LC_MESSAGES/usr/share/locale/bg/LC_MESSAGES 根据所有权或权限搜索文件 1234567891011[root@localhost ~]\\# find /home/student/.pki -user student # 按用户搜索/home/student/.pki/home/student/.pki/nssdb[root@localhost ~]\\# find / -group cdrom # 按用户组搜索/dev/sr0/dev/sg0......[root@localhost ~]\\# find /etc/ssh/ssh_config -uid 0 # 按用户 id 搜索/etc/ssh/ssh_config[root@localhost ~]\\# find / -user root -gid 12 # 用户和用户组（mail）搭配使用/var/spool/mail ​使用 -perm 按照特定权限进行搜索，使用数字表示法，详细情况可以参考前面有关章节的内容。-perm 选项的参数的前面可以加上 / 或 - 符号。其中 / 代表匹配 u,g,o 中的至少一个存在才匹配，- 代表 u,g,o 需要都存在才匹配。 1234[root@localhost ~]\\# find -perm 764 # 匹配用户具有 rwx 权限，组成员具有 rw 权限以及其他人只有读权限的文件[root@localhost ~]\\# find -perm -324 # 匹配用户至少拥有 wx 权限，组成员至少拥有 w 权限，其他成员至少具有 r 权限的文件[root@localhost ~]\\# find -perm /442 # 匹配用户具有 r 权限或者组成员具有 r 或者其他人具有 w 权限的文件[root@localhost ~]\\# find -perm -004 # 匹配其他人至少拥有 r 权限的文件 根据大小搜索文件 12345678910111213141516# 1. 搜索大小为 10 兆字节（向上取整）的文件[root@localhost ~]\\# find /boot -size 10M/boot/vmlinuz-4.18.0-240.el8.x86_64 # 实际 9.1M/boot/vmlinuz-0-rescue-6651ee1da4824a37975cd5245c8cb076 # 实际 9.1M# 2. 搜索大小超过 10 兆字节的文件[root@localhost ~]\\# find /boot -size +10M/boot/initramfs-4.18.0-240.el8.x86_64.img/boot/initramfs-0-rescue-6651ee1da4824a37975cd5245c8cb076.img/boot/initramfs-4.18.0-240.el8.x86_64kdump.img# 3. 搜索大小不超过 10 兆字节的文件[root@localhost ~]\\# find /boot -size -10M/boot/boot/efi/boot/efi/EFI/boot/efi/EFI/redhat...... 根据修改时间搜索文件 123456# 1. 搜索 120min 前修改的文件（向下舍入）【119min - 120min】[root@localhost ~]\\# find / -mmin 120# 2. 搜索在 200min+ 前修改过的文件[root@localhost ~]\\# find / -mmin +120# 3. 搜索过去 150min 内修改过的文件[root@localhost ~]\\# find / -mmin -150 根据文件类型搜索文件 ​不同文件类型的标志如下： f，普通文件 d，目录 l，软链接 b，块设备 123456[root@localhost ~]\\# find /dev -type b/dev/sr0/dev/nvme0n1p3/dev/nvme0n1p2/dev/nvme0n1p1/dev/nvme0n1","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"软件仓库和软件包模块流管理","slug":"Linux | 软件仓库和软件包模块流管理","date":"2022-08-15T04:05:29.539Z","updated":"2022-08-15T04:08:34.227Z","comments":true,"path":"2022-08-15-Linux | 软件仓库和软件包模块流管理.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E8%BD%AF%E4%BB%B6%E4%BB%93%E5%BA%93%E5%92%8C%E8%BD%AF%E4%BB%B6%E5%8C%85%E6%A8%A1%E5%9D%97%E6%B5%81%E7%AE%A1%E7%90%86.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 管理 DNF 软件仓库 ​将系统注册到订阅管理服务可根据所附加的订阅自动配置软件存储库的访问。 ​使用 dnf repolist all 查看可用的存储库： 12345678910111213141516171819202122[skinyi@skinyi ~]\\$ dnf repolist all # 不加选项 all 仅列出已启用的仓库仓库 id 仓库名称 状态fedora Fedora 33 - x86_64 启用fedora-cisco-openh264 Fedora 33 openh264 (From Cisco) - x86_64 启用fedora-cisco-openh264-debuginfo Fedora 33 openh264 (From Cisco) - x86_64 禁用fedora-debuginfo Fedora 33 - x86_64 - Debug 禁用fedora-modular Fedora Modular 33 - x86_64 启用fedora-modular-debuginfo Fedora Modular 33 - x86_64 - Debug 禁用fedora-modular-source Fedora Modular 33 - Source 禁用fedora-source Fedora 33 - Source 禁用updates Fedora 33 - x86_64 - Updates 启用updates-debuginfo Fedora 33 - x86_64 - Updates - Debug 禁用updates-modular Fedora Modular 33 - x86_64 - Updates 启用updates-modular-debuginfo Fedora Modular 33 - x86_64 - Updates - De 禁用updates-modular-source Fedora Modular 33 - Updates Source 禁用updates-source Fedora 33 - Updates Source 禁用updates-testing Fedora 33 - x86_64 - Test Updates 禁用updates-testing-debuginfo Fedora 33 - x86_64 - Test Updates Debug 禁用updates-testing-modular Fedora Modular 33 - x86_64 - Test Updates 禁用updates-testing-modular-debuginfo Fedora Modular 33 - x86_64 - Test Updates 禁用updates-testing-modular-source Fedora Modular 33 - Test Updates Source 禁用updates-testing-source Fedora 33 - Test Updates Source ​使用 dnf config-manager 来启用或禁用存储库。 12345678[root@skinyi ~]\\# dnf config-manager --enable fedora-cisco-openh264-debuginfo[root@skinyi ~]\\# dnf repolist all | grep fedora-ciscofedora-cisco-openh264 Fedora 33 openh264 (From Cisco) - x86_64 启用fedora-cisco-openh264-debuginfo Fedora 33 openh264 (From Cisco) - x86_64 启用[root@skinyi ~]\\# dnf config-manager --disable fedora-cisco-openh264-debuginfo[root@skinyi ~]\\# dnf repolist all | grep fedora-ciscofedora-cisco-openh264 Fedora 33 openh264 (From Cisco) - x86_64 启用fedora-cisco-openh264-debuginfo Fedora 33 openh264 (From Cisco) - x86_64 禁用 添加自定义存储库配置 ​要启用对新的第三方存储库的支持，可在 /etc/yum.repos.d/ 目录中创建一个文件。存储库配置文件必须以 .repo 扩展名结尾。存储库定义包含存储库的 URL 和名称，也定义是否使用 GPG 检查软件包签名，如果是，则还检查 URL 是否指向受信任的 GPG 密钥。 DNF 的软件仓库配置目录仍是 /etc/yum.repos.d。 ​使用 dnf config-manager 来添加一个 dnf 存储库。 1234567891011[root@skinyi dnf]\\# dnf config-manager \\--add-repo=&quot;http://dl.fedoraproject.org/pub/epel/8/x86_64/&quot;添加仓库自：http://dl.fedoraproject.org/pub/epel/8/x86_64/[root@skinyi dnf]\\# ls /etc/yum.repos.d/dl.fedoraproject.org_pub_epel_8_x86_64_.repofedora-cisco-openh264.repo......[root@skinyi dnf]\\# dnf repolist all # 添加后的仓库默认为启用状态仓库 id 仓库名称 状态dl.fedoraproject.org_pub_epel_8_x86_64_ created by dnf config-manager from 启用...... ​按需修改仓库文件，并配置 GPG 密钥以增强安全性。密钥存储在远程存储库站点上的不同位置，如 http://dl.fedoraproject.org/pub/epel/RPM_GPG_KEY_EPEL-8。系统管理员应该将此密钥下载到本地并配置 dnf 从本地检索此密钥。例如： 12345678[root@skinyi dnf]\\# vi /etc/yum.repos.d/dl.fedoraproject.org_pub_epel_8_x86_64_.repo [EPEL-8] # id 不能存在空格name=EPEL8 repositoriesbaseurl=http://dl.fedoraproject.org/pub/epel/8/x86_64/enabled=1gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-8:wq ​要删除某个软件仓库，将其配置文件删除即可： 123[root@skinyi ~]\\# rm -f /etc/yum.repos.d/dl.fedoraproject.org_pub_epel_8_x86_64_.repo [root@skinyi ~]\\# dnf repolist all | grep EPEL[root@skinyi ~]\\# 安装软件仓库及其配置文件 ​一些存储库将一个配置文件和 GPG 公钥作为 RPM 软件包的一部分提供，该软件包也可以使用 dnf install 命令来下载和安装。 ​以下命令将安装 RHEL8 EPEL 软件存储库软件包。 12[root@skinyi ~]\\# rpm --import http://dl.fedoraproject.org/pub/epel/RPM-GPG-KEY-EPEL-8[root@skinyi ~]\\# dnf install http://dl.fedoraproject.org/pub/epel/8/x86_64/e/epel-release-8-2.noarch.rpm 先安装 RPM GPG 密钥再安装签名的软件包，安装软件包时可以通过 --nogpgcheck 选项忽略检查 GPG key，但此操作并不安全。 ​一个软件仓库配置文件可以配置多个存储库的引用，每一存储库的开头为包含在方括号里的存储库的 id。 1234567891011121314151617181920212223242526272829303132333435363738[root@skinyi ~]\\# cat /etc/yum.repos.d/fedora.repo [fedora]name=Fedora $releasever - $basearch#baseurl=http://download.example/pub/fedora/linux/releases/$releasever/Everything/$basearch/os/metalink=https://mirrors.fedoraproject.org/metalink?repo=fedora-$releasever&amp;arch=$basearchenabled=1countme=1metadata_expire=7drepo_gpgcheck=0type=rpmgpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-fedora-$releasever-$basearchskip_if_unavailable=False[fedora-debuginfo]name=Fedora $releasever - $basearch - Debug#baseurl=http://download.example/pub/fedora/linux/releases/$releasever/Everything/$basearch/debug/tree/metalink=https://mirrors.fedoraproject.org/metalink?repo=fedora-debug-$releasever&amp;arch=$basearchenabled=0metadata_expire=7drepo_gpgcheck=0type=rpmgpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-fedora-$releasever-$basearchskip_if_unavailable=False[fedora-source]name=Fedora $releasever - Source#baseurl=http://download.example/pub/fedora/linux/releases/$releasever/Everything/source/tree/metalink=https://mirrors.fedoraproject.org/metalink?repo=fedora-source-$releasever&amp;arch=$basearchenabled=0metadata_expire=7drepo_gpgcheck=0type=rpmgpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-fedora-$releasever-$basearchskip_if_unavailable=False 管理软件包模块流 ​模块化 是构建、组织、分发软件包的一种新型方式，具有透明构建和交付、积极维护和易于安装的特点。 模块化的基本概念 软件包：普通的 rpm 软件包； 模块：将软件包进行分组整合成模块 —— 特定的应用程序、语言运行时或任何逻辑组的表示。这使内容更加精细、更容易找到自己所需； 模块流：模块可以在多个流中可用，通常代表它们包含的软件的主要版本，自动选择所需软件的正确版本。 配置文件：为了简化安装而引入了安装配置文件 —— 模块特定用例的软件包子集。 管理软件包模块流 列出模块 ​使用 dnf module list 命令列出可用的模块的列表： 1234567891011121314151617181920212223242526272829[root@skinyi ~]\\# dnf module list # 列出所有可用的模块流Fedora 33 openh264 (From Cisco) - x86_64 576 B/s | 989 B 00:01 Fedora Modular 33 - x86_64Name Stream Profiles Summary ant 1.10 default Java build tool [d] avocado latest default Framework with tools and libraries [d], min for Automated Testing imal avocado-vt latest common Avocado Virt Test Plugin cobbler 3 default Versatile Linux deployment server cri-o nightly default Kubernetes Container Runtime Inter face for OCI-based containers ......[root@skinyi ~]\\# dnf module list perl # 搜索特定的软件模块上次元数据过期检查：0:34:07 前，执行于 2021年09月07日 星期二 10时56分52秒。Fedora Modular 33 - x86_64Name Stream Profiles Summary perl 5.30 common, default [d], minima Practical Extraction and Report Language l perl 5.32 common [d], minimal Practical Extraction and Report LanguageFedora Modular 33 - x86_64 - UpdatesName Stream Profiles Summary perl 5.30 common, default [d], minima Practical Extraction and Report Language l perl 5.32 common [d], minimal Practical Extraction and Report Language提示：[d]默认，[e]已启用，[x]已禁用，[i]已安装 ​使用 dnf module info [MOD_NAME] 查看软件模块的详细信息： 1234567891011[root@skinyi ~]\\# dnf module info perl | head -n 10上次元数据过期检查：0:36:27 前，执行于 2021年09月07日 星期二 10时56分52秒。Name : perlStream : 5.30Version : 3320200819225620Context : 394aad6bArchitecture : x86_64Profiles : common, default [d], minimalDefault profiles : defaultRepo : fedora-modularSummary : Practical Extraction and Report Language 若不指定模块流，dnf module info 将显示使用默认流的模块的配置文件所安装的软件包列表。使用 module-name:stream 的格式来查看特定的模块流。添加 --profile 选项可显示有关各个模块的配置文件所安装的软件包的信息。如： 1234567891011[root@skinyi ~]\\# dnf module info --profile perl:5.30上次元数据过期检查：0:43:18 前，执行于 2021年09月07日 星期二 10时56分52秒。Name : perl:5.30:3320200819225620:394aad6b:x86_64common : perldefault : perlminimal : perl-interpreterName : perl:5.30:3320210211084215:394aad6b:x86_64common : perldefault : perlminimal : perl-interpreter 启用模块流和安装模块 必须启用模块流才能安装其模块。可以使用 yum module enable MOD_STRM 来手动启用模块流。 123456[root@skinyi ~]\\# dnf module install perl上次元数据过期检查：0:50:52 前，执行于 2021年09月07日 星期二 10时56分52秒。参数 &#x27;perl&#x27; 可以匹配模块 &#x27;perl&#x27; 的 2 个流（&#x27;5.30&#x27;, &#x27;5.32&#x27;），但是这些流都未被启用或非默认无法解析参数 perl错误：请求中出现的问题 :损坏的组或模块： perl 对于给定的模块，仅可启用一个模块流，启用其他模块流将禁用原始的模块流。 ​使用模块流安装模块： 123456789101112131415161718192021222324252627282930313233343536373839404142# 1. 首先启用要安装的模块[root@skinyi ~]\\# dnf module enable perl:5.32上次元数据过期检查：3:46:24 前，执行于 2021年09月07日 星期二 10时56分52秒。依赖关系解决。================================================================================ 软件包 架构 版本 仓库 大小================================================================================启用模块流: perl 5.32 事务概要================================================================================确定吗？[y/N]： y完毕！# 2. 安装需要的模块[root@skinyi ~]\\# dnf module install perl上次元数据过期检查：3:48:26 前，执行于 2021年09月07日 星期二 10时56分52秒。依赖关系解决。================================================================================ 软件包 架构 版本 仓库 大小================================================================================安装组/模块包: perl x86_64 4:5.32.1-471.module_f33+12592+71aff0e2 updates-modular 27 k安装依赖关系: annobin x86_64 9.68-2.fc33 updates 96 k binutils x86_64 2.35-18.fc33 updates 5.4 M binutils-gold x86_64 2.35-18.fc33 updates 774 k cpp x86_64 10.3.1-1.fc33 updates 9.4 M ......安装模块配置档案: perl/common 事务概要================================================================================安装 258 软件包总下载：92 M安装大小：301 M确定吗？[y/N]： y...... 安装模块时可以省略选项 module 而用前缀 @ 符号代表模块名，如：dnf install @perl。 ​验证安装结果（我没有安装）： 1234567891011121314151617[root@skinyi ~]\\# dnf module list perl上次元数据过期检查：3:52:55 前，执行于 2021年09月07日 星期二 10时56分52秒。Fedora Modular 33 - x86_64Name Stream Profiles Summary perl 5.30 [x] common, default [d], minim Practical Extraction and Report Languag al e perl 5.32 [x] common [d], minimal Practical Extraction and Report Languag e Fedora Modular 33 - x86_64 - UpdatesName Stream Profiles Summary perl 5.30 [x] common, default [d], minim Practical Extraction and Report Languag al e perl 5.32 [x] common [d], minimal Practical Extraction and Report Languag e 提示：[d]默认，[e]已启用，[x]已禁用，[i]已安装 删除模块和禁用模块流 ​删除模块会删除当前启用的模块流的配置集所安装的所有软件包，以及依赖于这些软件包的任何其他软件包和模块。 删除模块和切换模块流有些棘手。切换流会重置当前流并启用新流，但本地已安装的软件包并不会被更改。切记删除旧有模块流后再安装新流以保证数据不会丢失或配置错误。 ​使用 dnf module remove MOD_NAME 或 dnf remove @MOD_NAME 删除模块流： 123456[root@skinyi ~]\\# dnf remove @perl:5.30上次元数据过期检查：4:04:46 前，执行于 2021年09月07日 星期二 10时56分52秒。无法匹配参数 perl:5.30 中的配置档案依赖关系解决。无需任何处理。完毕！ ​使用 dnf module disable MOD_NAME 禁用模块流： 12345[root@skinyi ~]\\# dnf module disable perl:5.30上次元数据过期检查：4:06:34 前，执行于 2021年09月07日 星期二 10时56分52秒。依赖关系解决。无需任何处理。完毕！ 切换模块流 ​切换模块流需要先删除就有安装的模块，删除模块内容及配置文件后，使用命令 dnf module reset 重置模块流： 1234567891011121314[root@skinyi ~]\\# dnf module reset perl上次元数据过期检查：4:12:14 前，执行于 2021年09月07日 星期二 10时56分52秒。依赖关系解决。================================================================================ 软件包 架构 版本 仓库 大小================================================================================重置模块: perl 事务概要================================================================================确定吗？[y/N]： y完毕！ ​然后启用并安装要使用的模块流。","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"更新和安装软件包","slug":"Linux | 更新和安装软件包","date":"2022-08-15T03:59:45.671Z","updated":"2022-08-15T04:04:28.813Z","comments":true,"path":"2022-08-15-Linux | 更新和安装软件包.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E6%9B%B4%E6%96%B0%E5%92%8C%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E5%8C%85.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 ​这一章的所有关于软件操作的测试环境为：Fedora33。 有关命令摘要 RPM 命令摘要 命令 任务 rpm -qa 列出当前安装的所有 RPM 软件包 rpm -q NAME 显示系统上安装的 NAME 的版本 rpm -qi NAME 显示有关软件包的详细信息 rpm -ql NAME 列出软件包中含有的所有文件 rpm -qc NAME 列出软件包中含有的配置文件 rpm -qd NAME 列出软件包中含有的文档文件 rpm -q --changelog NAME 显示软件包的简短更新日志摘要 rpm -q --scripts NAME 显示软件包在安装、升级或删除时运行的 shell 脚本 DNF 命令摘要 命令 任务 dnf list [NAME-PATTERN] 按名称列出已安装和可用的软件包 dnf group list 列出已安装和可用的软件组 dnf search KEYWORD 按关键字搜索软件包 dnf info PKGNAME 显示软件包的详细信息 dnf install PKGNAME 安装软件包 dnf group install GRPNAME 安装软件组 dnf update [PKGNAME] 更新所有（或指定的）软件包 dnf remove PKGNAME 卸载软件包 dnf history 查看 DNF 历史事务 注册系统获得红帽支持 使用图形界面工具进行注册 ​通过 Gnome 图形界面打开 Red Hat Subscription Manager（红帽订阅管理器），进行用户身份验证后进入订阅窗口点击 Register 按钮，填写并提交相关信息之后即可订阅成功。关于具体操作不再赘述。 从命令行注册 123456789101112# 1. 注册系统到红帽账户[user@host ~]\\$ subscrption-manager register --username=USERNAME --password=PASSWORD# 2. 查看可用的订阅[user@host ~]\\$ subscription-manager list --available | less# 3. 自动附加订阅[user@host ~]\\$ subscription-manager attach --auto# 或者从可用订阅列表中的特定池中附加订阅[user@host ~]\\$ subscription-manager attach --pool=poolID# 4. 查看已用的订阅[user@host ~]\\$ subscription-manager list --consumed# 5. 取消注册系统[user@host ~]\\$ subscription-manager unregister subscription-manager 也可搭配激活密钥使用而不必使用用户名或密码以为实现自动化安装和部署提供便利。 红帽授权证书 ​注册红帽后，系统的授权证书存储在 /etc/pki 和其子目录中。 /etc/pki/product 中的证书知名系统上安装了哪些红帽产品； /etc/pki/consumer 中的证书指明系统所注册到的红帽账户； /etc/pki/entitlement 中的证书指明该系统附加有哪些订阅。 RPM 软件包 ​RPM 软件包管理器最初是由红帽开发的，该程序提供了一种标准的方式来打包软件进行分发。与使用从存档提取到文件系统的软件相比，采用 RPM 软件包形式管理软件要简单得多。管理员可以通过它跟踪软件包所安裝的文件，需要删除哪些软件（如果卸载）并检查确保显示支持软件包（如果安装）。有关已安裝软件包的信息存储在各个系统的本地RPM数据库中。 ​红帽为红帽企业 Linux 提供的所有软件都以 RPM 软件包的形式提供。 RPM 软件包的文件名约定 ​RPM 软件包的文件名一般的格式为：name-version-release.architecture.rpm，如：coreutils-8.30-4.el8.x86_64.rpm。 name 是描述软件内容的一个或多个词语； version 是原始软件的版本号； release 是基于该版本的软件包的发行版号，由软件打包商设置，后者不一定是原始软件开发商； architecture 是编译的软件包运行的处理器架构。noarch 表示该软件包的内容不限定架构。 ​从软件存储库搜索、下载和安装软件包时只需要软件包的名称。如果存在多个版本，则会安装最高版本。 ​每个 RPM 软件包是包含以下三个组成部分的特殊存档： 软件包安装的文件； 元数据-与软件包有关的信息，如名称、版本、发行版和架构；软件包的摘要和描述；是否要求安装其他软件包；授权许可信息；软件包更改日志以及其他详细信息； 在安装、更新或删除此软件包时可能运行的脚本，或者在安装、更新或删除其他软件包时触发的脚本。 ​通常，软件提供商使用 GPG 密钥对 RPM 软件包进行数字签名，RPM 会通过 GPG 密钥签名来验证软件包的完整性。若 GPG 签名不匹配，则 RPM 会拒绝安装软件包。 ​RPM 更新软件会先删除旧有的软件包（通常会保留配置文件）然后安装新版，除了内核。 2. 使用 RPM 实用程序处理本地软件包 ​rpm 实用程序可获取软件包文件和已安装软件包的内容的相关信息。默认情况下，它从已安装软件包的本地数据库中获取信息。但是可以使用 -p 选项来指定想获取有关已下载软件包文件的信息以实现在安装前的检查。 ​使用 rpm 命令查询本地软件包数据库信息的一般格式为： 1rpm -q [select-options] [query-options] # 查询本地软件包数据库信息 ​关于已安装的软件包的一般信息的查询： 1234567891011[skinyi@skinyi ~]\\$ rpm -qa # 列出已安装的所有软件包libgcc-10.2.1-9.fc33.x86_64linux-firmware-whence-20210208-118.fc33.noarchtzdata-2021a-1.fc33.noarchlibreport-filesystem-2.14.0-15.fc33.noarchhwdata-0.345-1.fc33.noarch......# rpm -qf FILENAME 查询哪个软件包提供安装的文件[skinyi@skinyi ~]\\$ rpm -qf /etc/yum.repos.dfedora-repos-33-3.noarchfedora-repos-33-5.noarch ​关于特定软件包的信息查询： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# 1. rpm -q PKG_NAME 列出当前安装的软件包的版本[skinyi@skinyi ~]\\$ rpm -q dnfdnf-4.8.0-1.fc33.noarch# 2. rpm -qi PKG_NAME 获取有关软件包的详细信息[skinyi@skinyi ~]\\$ rpm -qi kernelName : kernelVersion : 5.10.23Release : 200.fc33Architecture: x86_64Install Date: 2021年03月19日 星期五 10时09分52秒Group : UnspecifiedSize : 0License : GPLv2 and Redistributable, no modification permitted......# 3. rpm -ql PKG_NAME 列出软件包安装的文件[skinyi@skinyi ~]\\$ rpm -ql openssh/etc/ssh/etc/ssh/moduli/usr/bin/ssh-keygen/usr/lib/.build-id/usr/lib/.build-id/4b......# 4. rpm -qc PKG_NAME 仅列出软件包安装的配置文件[skinyi@skinyi ~]\\$ rpm -qc openssh-clients/etc/ssh/ssh_config/etc/ssh/ssh_config.d/50-redhat.conf# 5. rpm -qd PKG_NAME 仅列出软件包安装的文档文件[skinyi@skinyi ~]\\$ rpm -qd net-tools/usr/share/man/de/man5/ethers.5.gz/usr/share/man/de/man8/arp.8.gz/usr/share/man/de/man8/ifconfig.8.gz......# 6. rpm -q --scripts PKG_NAME 列出在安装或删除软件包之前或之后运行的 shell 脚本[skinyi@skinyi ~]$ rpm -q --scripts openssh-serverpreinstall scriptlet (using /bin/sh):getent group sshd &gt;/dev/null || groupadd -g 74 -r sshd || :getent passwd sshd &gt;/dev/null || \\ useradd -c &quot;Privilege-separated SSH&quot; -u 74 -g sshd \\ -s /sbin/nologin -r -d /var/empty/sshd sshd 2&gt; /dev/null || :postinstall scriptlet (using /bin/sh): if [ $1 -eq 1 ] &amp;&amp; [ -x /usr/bin/systemctl ]; then # Initial installation /usr/bin/systemctl --no-reload preset sshd.service sshd.socket || : fi ......# 7. rpm -q --changelog PKG_NAME 列出软件包的更改信息[skinyi@skinyi ~]\\$ rpm -q --changelog audit* 三 8月 11 2021 Steve Grubb &lt;sgrubb@redhat.com&gt; 3.0.5-1- New upstream bugfix release* 日 8月 08 2021 Steve Grubb &lt;sgrubb@redhat.com&gt; 3.0.4-1- New upstream feature release......# 8. rpm -pq[ilcd...] PKG_NAME 查询本地软件包（已下载未安装）的上述信息。 ​安装离线下载的软件包： 12345# rpm -ivh name-version-release.arch.rpm # 安装软件包# 选项意义：-i, --install # 安装软件包-v, --verbose # 显示详细信息-h, --hash # 安装的时候列出哈希标记 安装第三方软件时要确保可信，因为在安装过程中允许以 root 用户执行任意脚本。 提取 rpm 软件包中的文件 ​使用 rpm2cpio 命令可以将 rpm 软件包转成格式为 cpio 的特殊归档文件，使用 cpio 命令则可以提取 cpio 归档文件的内容。因此，要实现一条命令提取一个软件包中的内容，可以通过管道来实现： 1234[user@host ~]\\$ rpm2cpio name-version-release.arch.rpm | cpio -id [PATTERN] # 按照 PATTERN 指定的模式提取 rpm 包中的文件# cpio 的命令选项-i, --extract # 从包中提取文件-d, --make-directories # 需要时自动创建目录 ​提取的文件会存放在当前目录，且会自动创建子目录。 使用 DNF 管理软件包 ​DNF 为 RPM 的前端软件，除了可以安装软件包，它也可以实现从软件仓库搜索、下载、解决安装依赖的比 RPM 更完善的功能。 ​YUM 作为软件包管理器的老前辈将要被 DNF所取代（由于其性能差、内存占用过多、依赖解析速度变慢等长期存在的问题），故将原教科书中的关于 YUM 介绍的一章换成对 DNF 的介绍。DNF 使用 c、c++、python 语言编写，将依赖管理模块抽象为 libsolv 库来管理软件包的依赖，相比 YUM 提高了性能。DNF 和 YUM 的用法大体上是相同的。 使用 DNF 查找软件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263# 1. dnf help 显示用法信息[skinyi@skinyi ~]\\$ dnf helpusage: dnf [options] COMMAND主要命令列表：alias 列出或创建命令别名autoremove 删除所有原先因为依赖关系安装的不需要的软件包check 在包数据库中寻找问题check-update 检查是否有软件包升级clean 删除已缓存的数据deplist [已弃用，请使用 repoquery --deplist] 列出软件包的依赖关系和提供这些软件包的源distro-sync 同步已经安装的软件包到最新可用版本downgrade 降级包......# 2. dnf list [KEYWORD] 显示已安装和可用的软件包[root@skinyi ~]\\# dnf list kernel上次元数据过期检查：2:07:19 前，执行于 2021年09月01日 星期三 14时52分31秒。已安装的软件包kernel.x86_64 5.10.23-200.fc33 @updateskernel.x86_64 5.13.12-100.fc33 @updates# 3. dnf search KEYWORD 使用关键字搜索软件包[skinyi@skinyi ~]\\$ dnf search remote上次元数据过期检查：0:02:41 前，执行于 2021年09月01日 星期三 16时43分32秒。============================ 名称 和 概况 匹配：remote ==============================R-remotes.noarch : R Package Installation from Remote RepositoriesRemoteBox.noarch : Open Source VirtualBox Client with Remote Managementanyremote.x86_64 : Remote control through Wi-Fi or bluetooth connectionanyremote-data.x86_64 : Configuration files for anyRemoteanyremote-doc.x86_64 : Documentation for anyRemotechrome-remote-desktop.x86_64 : Remote desktop support for google-chrome &amp; chromium......# 4. dnf info PKG_NAME 查看软件包的详细信息，包括安装所需磁盘空间[skinyi@skinyi ~]\\$ dnf info httpd上次元数据过期检查：0:05:28 前，执行于 2021年09月01日 星期三 16时43分32秒。可安装的软件包名称 : httpd版本 : 2.4.48发布 : 1.fc33架构 : x86_64大小 : 1.4 M源 : httpd-2.4.48-1.fc33.src.rpm仓库 : updates概况 : Apache HTTP ServerURL : https://httpd.apache.org/协议 : ASL 2.0描述 : The Apache HTTP Server is a powerful, efficient, : and extensible web server.# 5. dnf provides PATHNAME 显示提供与指定路径名文件或目录相匹配的软件包[skinyi@skinyi ~]\\$ dnf provides /var/www/html上次元数据过期检查：0:07:46 前，执行于 2021年09月01日 星期三 16时43分32秒。httpd-filesystem-2.4.46-1.fc33.noarch : The basic directory ...: layout for the Apache HTTP Server仓库 ：fedora匹配来源：文件名 ：/var/www/htmlhttpd-filesystem-2.4.48-1.fc33.noarch : The basic directory ...: layout for the Apache HTTP Server仓库 ：updates匹配来源：文件名 ：/var/www/html 使用 DNF 安装和删除软件 123456789101112131415161718192021222324# 1. dnf install PKG_NAME # 获取并安装软件包，包括所有依赖项[root@skinyi ~]\\# dnf install git上次元数据过期检查：2:04:10 前，执行于 2021年09月01日 星期三 14时52分31秒。依赖关系解决。================================================================ 软件包 架构 版本 仓库 大小================================================================安装: git x86_64 2.31.1-3.fc33 updates 122 k安装依赖关系: git-core x86_64 2.31.1-3.fc33 updates 3.6 M git-core-doc noarch 2.31.1-3.fc33 updates 2.3 M perl-AutoLoader noarch 5.74-471.fc33 updates 31 k perl-B x86_64 1.80-471.fc33 updates 189 k perl-Carp noarch 1.50-457.fc33 fedora 29 k perl-Class-Struct noarch 0.66-471.fc33 updates 32 k perl-Data-Dumper x86_64 2.174-459.fc33 fedora 56 k......# 2. dnf update [PKG_NAME] # 更新指定软件或所有已安装软件[root@skinyi ~]\\# dnf update kernel上次元数据过期检查：2:06:19 前，执行于 2021年09月01日 星期三 14时52分31秒。依赖关系解决。无需任何处理。完毕！ 若需查看当前系统运行中的内核，可以使用 uname 命令。 1234[root@skinyi ~]\\# uname -r5.10.23-200.fc33.x86_64[root@skinyi ~]\\# uname -aLinux skinyi.fedora 5.10.23-200.fc33.x86_64 \\#1 SMP Thu Mar 11 22:18:30 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux 12345678910111213141516# 3. dnf remove PKG_NAME # 删除安装的软件包及其依赖包[root@skinyi ~]\\# dnf remove openssh依赖关系解决。================================================================ 软件包 架构 版本 仓库 大小================================================================移除: openssh x86_64 8.4p1-7.fc33 @updates 1.8 M移除依赖的软件包: openssh-clients x86_64 8.4p1-7.fc33 @updates 1.8 M openssh-server x86_64 8.4p1-7.fc33 @updates 924 k事务概要================================================================移除 3 软件包...... 使用 DNF 安装或删除软件组 DNF 也有软件组的概念，软件组是出于特定目的归类到一起安装的相关软件的集合。 ​在 RHEL8 中，有两种类型的组：常规组和环境组，其中常规组是软件包的集合，环境组是常规组的集合。一个组提供的软件包或组可能为 mandatory（安装该软件组时必须安装）、default（安装该组时通常会安装）或 optional（安装该组时不予以安装，除非特别要求）。 查看已安装和可用的软件组名称 123456789101112131415161718[root@skinyi ~]\\# dnf group list上次元数据过期检查：2:17:43 前，执行于 2021年09月01日 星期三 14时52分31秒。可用环境组： Fedora 定制操作系统 最小化安装 Fedora Workstation Fedora Cloud Server ......已安装的环境组： Fedora Server 版本已安装组： 无头设备（Headless）管理可用组： 3D 打印 管理工具 音频制作 写作和出版 ...... 有些组一般通过环境组安装，默认为隐藏。可以通过 dnf group list hidden 命令列出这些隐藏组。 显示软件组的相关信息 1234567891011121314[root@skinyi ~]\\# dnf group info &quot;RPM Development Tools&quot;上次元数据过期检查：2:31:05 前，执行于 2021年09月01日 星期三 14时52分31秒。组：RPM 开发工具 描述：这些工具中包括了核心开发工具，如 rpmbuild。 必要的软件包： redhat-rpm-config rpm-build 默认的软件包： koji mock rpmdevtools 可选的软件包： pungi rpmlint 安装一个软件组 123456789101112131415161718[root@skinyi ~]\\# dnf group install &quot;Deepin Desktop Environment&quot; --with-optional上次元数据过期检查：2:35:01 前，执行于 2021年09月01日 星期三 14时52分31秒。依赖关系解决。================================================================ 软件包 架构 版本 仓库 大小================================================================安装组/模块包: chromium x86_64 91.0.4472.164-1.fc33 updates 99 M deepin-calculator x86_64 5.0.1-3.fc33 fedora 286 k deepin-calendar x86_64 5.0.1-4.fc33 fedora 111 k deepin-desktop x86_64 5.0.0-9.fc33.2 updates 1.9 M deepin-editor x86_64 1.2.9.1-8.fc33.1 updates 1.3 M deepin-icon-theme noarch 15.12.71-5.fc33 fedora 11 M deepin-image-viewer x86_64 5.0.0-5.fc33 fedora 3.7 M deepin-picker x86_64 5.0.1-3.fc33 fedora 83 k deepin-screenshot x86_64 5.0.0-4.fc33 fedora 347 k ...... --with-optional 选项指定安装可选的软件包。 查看软件包管理的历史事务 ​所有安装和删除软件包的事务日志记录在 /var/log/dnf.rpm.log 中。 123456[root@skinyi ~]\\# tail -n 5 /var/log/dnf.rpm.log2021-09-01T17:22:45+0800 INFO --- logging initialized ---2021-09-01T17:23:00+0800 INFO --- logging initialized ---2021-09-01T17:23:36+0800 INFO --- logging initialized ---2021-09-01T17:25:56+0800 INFO --- logging initialized ---2021-09-01T17:27:31+0800 INFO --- logging initialized --- ​使用 dnf history 显示安装和删除事务的摘要： 123456[root@skinyi ~]\\# dnf historyID | 命令行 | 日期和时间 | 操作 | 更改 -------------------------------------------------------------------------------- 3 | update | 2021-09-01 14:54 | I, U | 283 EE 2 | install nodejs | 2021-03-19 11:05 | Install | 6 1 | | 2021-03-19 10:07 | Install | 658 EE ​使用 dnf history undo ID 选项可以撤销指定 ID 的事务。","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"归档和传输文件","slug":"Linux | 归档和传输文件","date":"2022-08-15T03:55:33.835Z","updated":"2022-08-15T03:58:55.061Z","comments":true,"path":"2022-08-15-Linux | 归档和传输文件.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E5%BD%92%E6%A1%A3%E5%92%8C%E4%BC%A0%E8%BE%93%E6%96%87%E4%BB%B6.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 进行文件的归档管理 ​使用 tar 命令来将文件和目录归档到压缩文件中，还能提取现有的 tar 存档内容。tar 存档是一个结构化的文件数据序列，其中包含有关每个文件和索引的元数据，以便可以提取单个文件。该存档可以使用 gzip、bzip2 或 xz 压缩方式进行压缩。tar命令也可仅列出归档文件的内容而不用进行提取。 123456789101112131415tar [OPTION...] [FILE...] # 使用 tar 进行文件归档和存档# 常见选项## 一般操作选项（必选）：-c, --create # 创建一个新存档-A, --catenate, --concatenate # 追加文件到 tar 文件-x, --extract # 从现有存档文件进行提取-t, --list # 列出存档的目录## 一般通用选项：-v, --verbose # 详细信息。显示存档或提取的文件有哪些-f, --file= # 文件名。此选项必须后接要使用或创建的存档的文件名-p, --preserve-permissions # 在提取存档时保留文件和目录的权限，而不去除 umask## 压缩选项：-z, --gzip # 使用 gzip 压缩方式（.tar.gz）-j, --bzip2 # 使用 bzip2 压缩方式（.tar.bz2），bzip2 的压缩率通常比 gzip 高-J, --xz # 使用 xz 压缩方式（.tar.xz），xz 的压缩率通常比 bzip2 更高 一般使用时的常用用法：tar [c|x|t][z|j|J]vf 目标文件 [要归档的文件...] 归档文件和目录 ​以下命令创建名为 archive.tar 的存档，其内容为用户主目录中的 file1、file2 和 file3： 12345[root@vmrhelskinyi ~]\\# tar -cf archive.tar file1 file2 file3 [root@vmrhelskinyi ~]\\# tar -tf archive.tarfile1file2file3 列出存档的内容 1234[root@vmrhelskinyi ~]\\# tar -tvf archive.tar # 查看归档文件的详细信息 -rw-r--r-- root/root 0 2021-09-01 09:18 file1-rw-r--r-- root/root 0 2021-09-01 09:18 file2-rw-r--r-- root/root 0 2021-09-01 09:18 file3 从存档中提取文件 ​ tar 存档通常应当提取到空目录中，以确保它不会覆盖任何现有文件。使用 root 用户提取存档时，tar 命令会保留文件的原始用户和组所有权。如果普通用户使用 tar 提取文件，文件所有权将属于从存档中提取文件的用户。 ​以下命令将把 archive.tar 归档中的文件提取到 /root/filebackup 目录中： 123456[root@vmrhelskinyi ~]\\# mkdir /root/filebackup[root@vmrhelskinyi ~]\\# cd /root/filebackup/[root@vmrhelskinyi filebackup]\\# tar -xvf /root/archive.tar file1file2file3 ​默认情况下，从文档中提取文件时，将从存档内容的权限中去除 umask。要保留存档文件的权限，可在提取存档时使用 -p 选项。 创建压缩了的归档文件 ​最好是使用单个顶级目录，其中可包含其他的目录和文件，以通过有序的方式来简化文件的提取。 ​以下命令创建了 /var/log 目录下的文件的归档，并使用 xz 的方式进行压缩： 123456[root@vmrhelskinyi ~]\\# tar cJvf log_backup.tar.xz /var/log # tar 命令选项中的短线可省略tar: Removing leading `/&#x27; from member names/var/log//var/log/lastlog/var/log/private/...... ​查看压缩了的归档包的内容（不强制使用压缩选项）： 12345[root@vmrhelskinyi ~]\\# tar tvf /root/log_backup.tar.xzdrwxr-xr-x root/root 0 2021-09-01 09:13 var/log/-rw-rw-r-- root/utmp 292292 2021-09-01 09:18 var/log/lastlogdrwx------ root/root 0 2021-06-03 07:05 var/log/private/...... 解压压缩了的归档文件 ​以下命令将创建 /root/logbackup 目录并将 log_back.tar.xz 中的内容解压到该目录下： 123456789101112131415[root@vmrhelskinyi ~]\\# mkdir logbackup &amp;&amp; cd logbackup[root@vmrhelskinyi logbackup]\\# tar xvf ../log_backup.tar.xz var/log/var/log/lastlogvar/log/private/......var/log/vmware-network.3.log[root@vmrhelskinyi logbackup]\\# tree -L 3.└── var └── log ├── anaconda ├── audit ├── boot.log ...... gzip、bzip2 和 xz 也可单独用于压缩单个文件，它们对应的解压缩命令分别为 gunzip、bunzip2、unxz。 在系统之间安全的传输文件 使用 SECURE COPY 传输文件 ​scp 命令是 OpenSSH 套件的一部分，它可将文件从远程系统复制到本地系统或从本地系统复制到远程系统。此过程需要进行身份验证，并在数据传输之前对其进行加密。 ​远程主机的目标文件位置的一般格式为：[user@]host:/path。其中 user 为可选项，若不指定则默认使用当前的本地用户名。 ​以下命令将 host 上的本地文件 /etc/yum.conf 和 /etc/hosts 文件复制到了远程主机 remotehost 上 remoteuser 用户的主目录： 1234[user@host ~]\\$ scp /etc/yum.conf /etc/hosts remoteuser@remotehost:/home/remoteuserremoteuser@remotehost\\`s password: yum.conf 100% 813 0.8KB/s 00:00hosts 100% 227 0.2KB/s 00:00 ​以下命令将 remotehost 上的远程目录 /var/log 复制到了本地主机 host 上的 user 用户的主目录下的 tmp 文件夹中： 123[user@host ~]\\$ scp -r root@remotehost:/var/log /home/user/tmp # -r 选项代表递归复制目录root@remotehost\\`s password: ...... 使用安全文件传输程序传输文件 ​要以交互式方式从 SSH 服务器上上传或下载文件，可以使用安全文件传输程序 sftp。sftp 命令的会话使用安全身份验证机制，并将数据加密后再与 SSH 服务器来回传输。 ​以下命令以 remoteuser 的身份连接到远程主机： 1234[user@host ~]\\$ sftp remoteuser@remotehostremoteuser@remotehost\\`s password: connected to remotehost.sftp&gt; ​ sftp 交互会话接受通用的与 Shell 命令相同的命令如：ls、cd、mkdir、pwd。使用 put 命令将文件上传到远程主机，使用 get 命令从远程主机上下载文件。使用 exit 命令可退出 sftp 会话。 ​ sftp 会话连接成功后会自动进入远程用户的主目录，且默认假设使用 put 命令后跟的是本地文件系统上的文件。 ​以下命令将本地系统的 /etc/hosts 文件上传到 remotehost 新建的目录 /home/remoteuser/hostbackup中： 123456sftp&gt; mkdir hostbackupsftp&gt; cd hostbackupsftp&gt; put /etc/hostsUploading /etc/hosts to /home/remoteuser/hostbackup/hosts/etc/hosts 100% 227 0.2KB/s 00:00sftp&gt; ​以下命令将 remotehost 上的 /etc/yum.conf 下载到本地系统上的当前目录并退出： 12345sftp &gt; get /etc/yum.confFetching /etc/yum.conf to yum.conf/etc/yum.conf 100% 813 0.8KB/s 00:00sftp &gt; exit[user@host ~]\\$ 使用 LRZSZ 进行文件传输 ​这个传输工具需要支持 XMODEM、YMODEM 或 ZMODEM 协议的远程连接客户端如 XShell 才能使用，更详细的介绍可见其官网：https://ohse.de/uwe/software/lrzsz.html。 ​远程连接到远程主机后，使用 rz 命令接收从本地主机发送的文件，使用 sz FILE 将文件发送到本地主机。 在系统间安全地同步文件 ​ rsync 是一个实现本地和远程文件或目录同步更新的程序，其通过比较两个文件或目录的差异进行最小化更改、传输。它也可以支持两个本地文件或目录的同步。 123456789101112131415161718192021# rsync 命令的常见形式：rsync [OPTION...] SRC DEST # 用于本地同步rsync [OPTION...] SRC [USER@]HOST:DEST # 用于将本地数据备份到远程主机（ssh 协议认证）rsync [OPTION...] SRC [USER@]HOST::DST # 用于将本地数据备份到远程主机（rsync 协议认证）rsync [OPTION...] [USER@]HOST:SRC DEST # 用于将远程机器上的数据备份到本地主机（ssh 协议认证）rsync [OPTION...] [USER@]HOST::SRC DEST # 用于将远程机器上的数据备份到本地主机（rsync协议认证）# 常见选项：-v, --verbose # 显示详细信息-r, --recursive # 递归复制目录，同步目录时必须使用-n, --dry-run # 空运行，显示正常运行时的更改但不实际运行-a, --archive # 使用存档模式，相当于 -rlptgoD（保留软链接接但不保留硬链接）-l, --links # 同步软连接-p, --perms # 保留权限-t, --times # 保留时间戳-g, --group # 保留组所有权-o, --owner # 保留文件所有者-D, --devices # 同步设备文件-H, --hard-links # 保留硬链接-z, --compress # 传输过程中进行压缩 --delete # 删除目标路径中源路径没有的文件 --exclude=PATTERN # 排除匹配 PATTERN 的文件 本地数据的同步 ​以下命令保持了 /var/log 目录的内容与 /tmp 目录的同步： 1234567891011[root@host ~]\\# rsync -av /var/log /tmprecieving incremental file listlog/log/README......log/tuned/tuned.logsent 11,592,423 bytes received 779 bytes 23,186,404.00 bytes/sectotal size is 11,586,755 speedup is 1.00[root@host ~]\\# ls /tmplog ssh-RLjDdarkKiw1 ​源目录的路径后面加上 / 即可实现同步源目录的内容而不在目标路径下创建同名子目录。 与远程数据的同步 ​要保留文件的所有权，需使用目标系统上的 root 用户。 ​以下命令将本地的 /var/log 目录同步到 remotehost 系统上的 /tmp 目录中： 12345678910[root@host ~]\\# rsync -av /var/log remotehost:/tmp # 省略用户默认为 rootroot@remotehost\\`s password: receiving incremental file listlog/log/README......log/tuned/tuned.logsent 9783 bytes received 290,576 bytes 85,816.86 bytes/sectotal size is 11,585,690 speedup is 38.57 ​同样，remotehost 上的 /var/log 远程目录也可同步到 host 上的 /tmp 本地目录： 12345678910[root@host ~]\\# rsync -av remotehost:/var/log /tmproot@remotehost\\`s password: receiving incremental file listlog/boot.loglog/dnf.librepo.log......log/dnf.logsent 9783 bytes received 290,576 bytes 85816.86 bytes/sectotal size is 11,585,690 speedup is 38.57","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"Linux 配置网络设置","slug":"Linux | Linux 配置网络设置","date":"2022-08-15T03:49:54.974Z","updated":"2022-08-15T03:52:53.487Z","comments":true,"path":"2022-08-15-Linux | Linux 配置网络设置.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20Linux%20%E9%85%8D%E7%BD%AE%E7%BD%91%E7%BB%9C%E8%AE%BE%E7%BD%AE.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 NMCLI 命令摘要 命令 用途 nmcli dev status 显示所有网络接口的 NetworkManager 状态。 nmcli con show 列出所有连接。 nmcli con show con-name 列出 con-name 连接的当前设置。 nmcli con add con-name name 添加一个名为 name 的新连接。 nmcli con mod con-name 修改 con-name 连接。 nmcli con reload 重新加载配置文件（再手动配置编辑文件之后使用）。 nmcli con up con-name 激活 con-name 连接。 nmcli dev dis device 在网络接口上停用并断开当前连接。 nmcli con del con-name 删除 con-name 连接及其配置文件。 nmcli gen permissions 查看当前用户的网络修改权限。 从命令行配置网络 了解 NETWORKMANAGER 守护进程 ​NetworkManager 是监控和管理网络设置的守护进程。除了该守护进程外，还有一个提供网络状态信息的 GNOME 通知区域小程序。命令行和图形工具与 NetworkManager 通信，并将配置文件保存在 /etc/sysconfig/network-scripts 目录中。NetworkManger 的基本概念： 设备是网络接口； 连接是可以为设备配置的设置的集合； 对于任何一个设备，在同一时间只能有一个连接处于活动状态。可能存在多个连接，以供不同设备使用或者以便为同一设备更改配置。如果需要临时更改网络设置，而不是更改连接的配置，可以通过更改设备的哪个连接处于活动状态； 每个连接具有一个用于标识自身的名称或 ID； nmcli 使用程序可用于从命令行创建和编辑连接文件。 查看联网信息 ​使用nmcli dev[ice] status 命令可查看所有网络设备的状态： 123456[root@localhost ~]\\# nmcli dev statusDEVICE TYPE STATE CONNECTION ens160 ethernet connected ens160 virbr0 bridge connected (externally) virbr0 lo loopback unmanaged -- virbr0-nic tun unmanaged -- ​使用 nmcli con[nect] show 命令可显示所有连接的列表。要仅列出活动的连接，可使用 --active 选项。 1234[root@localhost ~]\\# nmcli con show --activeNAME UUID TYPE DEVICE ens160 8fc2fbfe-e119-43be-87dd-c45071c07bf7 ethernet ens160 virbr0 139c458e-0cff-4615-974c-aa119ddf87c2 bridge virbr0 添加网络连接 ​使用 nmcli con[nect] add 命令添加新的网络连接。 ​以下命令将为接口 eno2 添加一个新链接 eno2，此连接将使用 DHCP 获取 IPv4 联网信息并在系统启动后自动连接。此命令还将通过侦听本地链路上的路由器播发来获取 IPv6 联网设置。配置文件的名称基于的 con-name 选项的值 eno2，并保存到 /etc/sysconfig/network-scripts/ifcfg-eno2 文件中。 12# nmcli connection add COMMON_OPTIONS TYPE_SPECIFIC_OPTIONS SLAVE_OPTIONS IP_OPTIONS [-- ([+|-]&lt;setting&gt;.&lt;property&gt; &lt;value&gt;)+][root@localhost ~]\\# nmcli con add con-name eno2 type ethernet ifname eno2 ​以下命令使用静态 IPv4 地址为 eno2 设备来创建 eno2 连接，且使用 IPv4 地址和网络前缀 192.168.0.5/24 及默认网关 192.168.0.254，但是仍在启动时自动连接并将其配置保存到相同文件中。 12[root@localhost ~]\\# nmcli con add con-name eno2 type ethernet ifname eno2 \\ipv4.address 192.168.0.5/24 ipv4.gateway 192.168.0.254 以下命令使用静态 IPv6 和 IPv4 地址为 eno2 设备创建 eno2 连接，且使用 IPv6 地址和网络前缀 2001:db8:0:1::c000:207/64 及默认 IPv6 网关 2001:db8:0:1::1，以及 IPv4 地址和网络前缀 192.0.2.7/24 及默认 IPv4 网关 192.0.2.1，但是仍在启动时自动连接，并将其配置保存到 /etc/sysconfig/network-scripts/ifcfg-eno2。 123[root@localhost ~]\\# nmcli con add con-name eno2 type ethernet ifname eno2 \\ipv6.address 2001:db8:0:1::c000:207/64 ipv6.gateway 2001:db8:0:1::1 \\ipv4.address 192.0.2.7/24 ipv4.gateway 192.0.2.1 控制网络连接 ​使用 nmcli con[nect] up con-name 命令将其绑定到的网络接口上的连接 con-name 激活。使用 nmcli con show 命令显示所有可用连接的名称。 123456[root@localhost ~]\\# nmcli con showNAME UUID TYPE DEVICE ens160 8fc2fbfe-e119-43be-87dd-c45071c07bf7 ethernet ens160 virbr0 139c458e-0cff-4615-974c-aa119ddf87c2 bridge virbr0 [root@localhost ~]\\# nmcli con up ens160Connection successfully activated (D-Bus active path: /org/freedesktop/NetworkManager/ActiveConnection/4) ​使用 nmcli dev dis[connect] device 命令将断开与网络接口 device 的连接并将其关闭。 12[root@localhost ~]\\# nmcli dev dis virbr0Device &#x27;virbr0&#x27; successfully disconnected. 使用 nmcli con[nection] down con-name 虽然可以停用网络接口，但是大部分有线连接在默认情况下配置了 autoconnect，使用该命令停用网络接口后 NetworkManager 会立即将其重新开启。使用 nmcli dev dis[connect] device 命令将连接与接口完全断开会避免这个问题。 修改网络连接设置 ​ NetworkManager 连接具有两种类型的设置。有静态连接属性，它们是由管理员配置并存储在 */etc/sysconfig/network-scripts/ifcfg-**中的配置文件中。还可能有活动连接数据，这些数据是连接从 DHCP 服务器获取的，不会持久存储。 ​使用 nmcli con[nect] show con-name 命令来查看某个连接的当前设置，其中 con-name 是连接的名称。小写的设置是静态属性，管理员可以更改全大写的设置是活动设置，临时用于此连接实例。 1234567891011121314[root@localhost ~]\\# nmcli con show ens160connection.id: ens160connection.uuid: 8fc2fbfe-e119-43be-87dd-c45071c07bf7connection.stable-id: --connection.type: 802-3-ethernetconnection.interface-name: ens160connection.autoconnect: yesconnection.autoconnect-priority: 0connection.autoconnect-retries: -1 (default)connection.multi-connect: 0 (default)connection.auth-retries: -1connection.timestamp: 1630289327connection.read-only: no...... ​使用 nmcli con[nect] mod con-name 命令更改连接的设置。这些更改将保存在连接的 /etc/sysconfig/netwrok-scripts/ifcfg-* 文件中。 ​以下命令针对 static-ens3 连接将 IPv4 地址设置为 192.0.2.154 并将默认网关设置为 192.0.2.254： 12[root@localhost ~]\\# nmcli con mod static-ens3 ipv4.address 192.0.2.154 \\ipv4.gateway 192.0.2.254 ​以下命令针对 static-ens3 连接将 IPv6 地址设置为 2001:db8:0:1::a00:1/64 并将默认网关设置为 2001:db8:0:1::1。 12[root@localhost ~]\\# nmcli con mod static-ens3 ipv6.address 2001:db8:0:1::a00:1/64 \\ipv6.gateway 2001:db8:0:1::1 之前采用 DHCPv4 服务获取 IPv4 信息的连接改为通过静态文件来获取的话需要将 ipv4.method 字段从 auto 更改为 manual。 之前采用 SLAAC 或 DHCPv6 服务获取 IPv6 信息的连接改为通过静态文件来获取的话需要将 ipv6.method 字段从 auto 或 dhcp 更改为 manual。 删除网络连接 ​使用 nmcli con[nect] del con-name 删除名为 con-name 的连接，同时断开它与设备的连接并删除文件 /etc/sysconfig/network-scripts/ifcfg-con-name。 1[root@localhost ~]\\# nmcli con del static-ens3 网络设置修改权限说明 ​root 用户可以使用 nmcli 对网络配置进行任何必要的更改。除此之外，普通用户： 在本地控制台上登陆的普通用户也可以对系统进行多项网络配置更改（必需本地登录）； 使用 ssh 登陆无权更改网络权限（除非登陆 root）。 使用 nmcli gen[eral] permissions 命令来查看自己的当前权限。 12345678910111213141516171819[student@localhost ~]\\$ nmcli gen permissions # 普通用户 ssh 登陆PERMISSION VALUE org.freedesktop.NetworkManager.checkpoint-rollback auth org.freedesktop.NetworkManager.enable-disable-connectivity-check no org.freedesktop.NetworkManager.enable-disable-network no org.freedesktop.NetworkManager.enable-disable-statistics no org.freedesktop.NetworkManager.enable-disable-wifi no org.freedesktop.NetworkManager.enable-disable-wimax no org.freedesktop.NetworkManager.enable-disable-wwan no org.freedesktop.NetworkManager.network-control auth org.freedesktop.NetworkManager.reload auth org.freedesktop.NetworkManager.settings.modify.global-dns auth org.freedesktop.NetworkManager.settings.modify.hostname auth org.freedesktop.NetworkManager.settings.modify.own auth org.freedesktop.NetworkManager.settings.modify.system auth org.freedesktop.NetworkManager.sleep-wake no org.freedesktop.NetworkManager.wifi.scan auth org.freedesktop.NetworkManager.wifi.share.open no org.freedesktop.NetworkManager.wifi.share.protected no 编辑网络配置文件 ​除了通过 nmcli con mod con-name 命令更改网络配置 /etc/sysconfig/network-scripts/ifcfg-con-name来实现对网络配置的修改，我们还可以使用文本编辑器来手动编辑此文件。手动更改该文件后，执行 nmcli con reload 命令来使 NetworkManager 进程重新读取该配置文件。 ​nmcli 设置和 ifcfg 文件中的名称和语法不同，下表整理了部分常见配置的区别。 NMCLI CON MOD IFCFG-* 文件 作用 ipv4.method manual BOOTPROTO=none IPv4 静态配置 ipv4.method auto BOOTPROTO=dhcp IPv4 动态获取地址，若配置了静态设置，则 DHCPv4 获取成功之前不会激活这些静态设置。 ipv4.address &quot;192.168.2.1/24 192.0.2.254&quot; IPADDR0=192.0.2.1 PREFIX0=24 GATEWAY=192.0.2.254 设置静态 IPv4 地址、网络前缀和默认网关。如果为连接设置了多个，则 ifcog-* 指令将以 1、2、3 等结尾，而不是以 0 结尾。 ipv4.dns 8.8.8.8 DNS0=8.8.8.8 修改 /etc/resolve.conf 以使用此域名服务器。 ipv4.dns-search example.com DOMAIN=example.com 修改 /etc/resolv.conf，以在 search 指令中使用这个域。 ipv4.ignore-auto-dns true PEERDNS=no 忽略来自 DHCP 服务器的 DNS 服务器信息。 ipv6.method manual IPV6_AUTOCONF=no IPv6 静态配置。 ipv6.method auto IPV6_AUTOCONF=yes 使用路由器播发中的 SLAAC 来配置网络设置。 ipv6.method dhcp IPV6_AUTOCONF=no DHCPV6C=yes 使用 DHCPv6 （而不使用 SLAAC）来配置网络设置。 ipv6.addresses &quot;2001:db8::a/64 2001:db8::1&quot; IPV6ADDR=2001:db8::a/64 IPV6_DEFAULTGW=2001:db8::1 设置静态 IPv6 地址、网络前缀默认网关。如果为连接设置了多个地址，IPV6_SECONDARIES 将采用空格分割的地址/前缀定义的双引号列表。 ipv6.dns 2400:3200::1 DNS0=2400:3200::1 修改 /etc/resolv.conf 以使用此域名服务器。与 IPv4 完全相同。 ipv6.dns-search example.com DOMAIN=example.com 修改 /etc/resolv.conf，以在 search 指令中使用这个域。与 IPv4 完全相同。 ipv6.ignore-auto-dns true IPV6_PEERDNS=no 忽略来自 DHCP 服务器的 DNS 服务器消息。 connection.autoconnection yes ONBOOT=yes 在系统引导时自动激活此连接。 connection.id ens3 NAME=ens3 此连接的名称。 connection.interface-name ens3 DEVICE=ens3 连接与具有此名称的网络接口绑定。 802-3-ethernet.mac-address ... HWADDR=... 连接与具有此 MAC 地址的网络接口绑定。 ​以下是我的虚拟机的网络配置文件内容： 123456789101112131415TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=dhcpDEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyNAME=ens160UUID=8fc2fbfe-e119-43be-87dd-c45071c07bf7DEVICE=ens160ONBOOT=yes ​修改了配置文件后，使用以下命令来使配置生效。 123[root@localhost ~]\\# nmcli con reload[root@localhost ~]\\# nmcli con down &quot;con-name&quot;[root@localhost ~]\\# nmcli con up &quot;con-name&quot; 配置主机名和域名解析 更改系统主机名 ​使用 hostname 命令显示或临时修改系统的完全限定主机名。 12345[root@localhost ~]\\# hostname # 不跟选项或参数为显示主机名localhost.localdomain[root@localhost ~]\\# hostname skinyi.mydomain # 后跟内容则临时修改主机名[root@localhost ~]\\# hostname skinyi.mydomain ​使用 hostnamectl 命令修改配置文件 /etc/hostname 来实现永久更改主机名，该命令也可用于查看系统的完全限定主机名的状态。 123456789101112131415[root@localhost ~]\\# hostnamectl set-hostname vmrhel@skinyi.me[root@localhost ~]\\# hostnamectl status Static hostname: vmrhelskinyi.me Pretty hostname: vmrhel@skinyi.me Icon name: computer-vm Chassis: vm Machine ID: 6651ee1da4824a37975cd5245c8cb076 Boot ID: 95270889df844cc2911c26503ef2b0df Virtualization: vmware Operating System: Red Hat Enterprise Linux 8.3 (Ootpa) CPE OS Name: cpe:/o:redhat:enterprise_linux:8.3:GA Kernel: Linux 4.18.0-240.el8.x86_64 Architecture: x86-64[root@localhost ~]\\# cat /etc/hostnamevmrhelskinyi.me 配置域名解析 ​根解析器用于将域名转换为 IP 地址，反之亦可。他将根据 /etc/nsswitch.conf 文件的配置来确定查找位置。默认情况下，先检查 /etc/hosts 文件的内容。 ​使用 getent hosts hostname 命令可以模拟在 /etc/hosts 文件中查找域名记录的过程（关于 getent 命令的详细介绍见 09. 管理本地用户和组 一章）： 12[root@localhost ~]\\# getent hosts localhost # DNS 反查::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 ​若在本地 hosts 文件中找不到相关记录，默认情况下，根解析器会尝试使用 DNS 服务来查询主机名。/etc/resolv.conf 配置文件控制如何进行查询： search：对于较短的主机名尝试搜索的域名列表。不应该在同一文件中设置此参数和 domain，如果在同一文件中设置它们，最后一项设置将覆盖另外一项； nameserver：要查询的域名服务器的 IP 地址。可以指定最多三个域名服务器指令，以在其中一个域名服务器停机时提供备用域名服务器。 123456[root@vmrhelskinyi ~]\\# cat /etc/resolv.conf# Generated by NetworkManagersearch menameserver 192.168.251.86nameserver 240e:41d:8010:c75::6fnameserver 240e:41d:8010:c75::b8 ​向连接添加 DNS 服务器地址配置： 1[root@vmrhelskinyi ~]\\# nmcli con mod CON-NAME +ipv4.dns IP # 向 CON-NAME 连接增加一条 DNS 配置记录 ​NetworkManager 会根据连接配置文件更新 /etc/resolv.conf 文件。 ​使用 host 命令测试域名解析： 12345[root@vmrhelskinyi ~]\\# host kernel.org # 测试域名解析kernel.org has address 198.145.29.83kernel.org mail is handled by 10 mail.kernel.org.[root@vmrhelskinyi ~]\\# host 198.145.29.83 # 测试域名反查83.29.145.198.in-addr.arpa domain name pointer kernel.org. DHCP 设置会在接口启动时自动根据获取的信息重写 /etc/resolv.conf 文件，如果不想使用 DHCP 更新 DNS 服务器设置，可以在接口配置文件中配置：PEERDNS=no。使用 nmcli 命令设置如下： 1[root@vmrhelskinyi ~]\\# nmcli con mod CON_NAME ipv4.ignore-auto-dns yes","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"Linux 收集网络信息","slug":"Linux | Linux 收集网络信息","date":"2022-08-15T03:46:45.330Z","updated":"2022-08-15T03:48:54.392Z","comments":true,"path":"2022-08-15-Linux | Linux 收集网络信息.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20Linux%20%E6%94%B6%E9%9B%86%E7%BD%91%E7%BB%9C%E4%BF%A1%E6%81%AF.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 收集网络接口信息 ​ip 命令的各种形式后面指定具体对象则查询具体对象的信息，不指定则查询所有对象的信息。 识别网络接口 ​使用 ip link 命令查看系统上所有可用的网络接口： 123456789[root@localhost ~]\\# ip link show # 该命令亦可简写为 `ip l`1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: ens160: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether 00:0c:29:02:75:df brd ff:ff:ff:ff:ff:ff3: virbr0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN mode DEFAULT group default qlen 1000 link/ether 52:54:00:53:ea:42 brd ff:ff:ff:ff:ff:ff4: virbr0-nic: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc fq_codel master virbr0 state DOWN mode DEFAULT group default qlen 1000 link/ether 52:54:00:53:ea:42 brd ff:ff:ff:ff:ff:ff ​以上示例中，服务器包含两个物理网络接口和一个虚拟网络接口（该接口拥有相同的 MAC 地址但有两个不同的名字），其中 lo 接口为回环设备，ens160 为虚拟机模拟的物理网卡，virbr0 和 virbr0-nic 为安装了 libvirt 服务自动创建的供虚拟机连接的虚拟网卡，virbr0 绑定一个固定的 ip 地址：192.168.122.1/24。由每个接口的 MAC 地址和绑定的 ip 地址我们就知道了每个接口连接网络的状态。 查询 IP 地址 ​使用 ip addr 命令来查看网络接口的 IPv4 或 IPv6 地址。 123456789[root@localhost ~]\\# ip addr show ens160 # 可简写为 ip a s ens1602: ens160: &lt;BROADCAST,MULTICAST,①UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000 ②link/ether 00:0c:29:02:75:df brd ff:ff:ff:ff:ff:ff ③inet 192.168.224.139/24 brd 192.168.224.255 scope global dynamic noprefixroute ens160 valid_lft 1962sec preferred_lft 1962sec ④inet6 240e:41d:8010:c75:683c:cc7:17fe:4c47/64 scope global dynamic noprefixroute valid_lft 3282sec preferred_lft 3282sec ⑤inet6 fe80::8af6:d265:9b34:f1d6/64 scope link noprefixroute valid_lft forever preferred_lft forever ​其中，标注各项的意义如下： ① UP 代表这是一个活动接口，即已启用。 ② link/ether 行指定设备的硬件（MAC）地址。 ③ inet 行显示 IPv4 地址、其网络前缀长度和作用域。 ④ inet6 行显示 IPv6 地址、其网络前缀长度和作用域。此地址属于全局作用域，通常使用此地址。 ⑤ 该 inet6 行显示接口具有链路作用域的 IPv6 地址，并且只能用于本地以太网链路上的通信。 显示性能统计信息 ​使用 ip -s link 命令统计接口的性能参数。每个网络接口的计数器【包括收到（RX）和传出（TX）的数据包数、数据包错误数、丢弃的数据包数】可用于检测网络问题的存在。 1234567[root@localhost ~]\\# ip -s link show ens160 # 无法简写2: ens160: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether 00:0c:29:02:75:df brd ff:ff:ff:ff:ff:ff RX: bytes packets errors dropped overrun mcast 2159684 2512 0 0 0 146 TX: bytes packets errors dropped carrier collsns 157533 1630 0 0 0 0 检查网络连通性 ​ping（IPv4）或 ping6（IPv6）命令可用于测试当前主机到网络上的任意主机的连通性（前提是被测试的主机开启 ICMP 回显功能）。不同于 windows，linux 环境下该命令将持续运行，直到按下 ctrl + c 组合键结束该命令的进程（除非指定了限制发送软件包数的选项）。 12345678910111213141516[root@localhost ~]\\# ping -c 2 baidu.com # 被测试主机可以使用其域名、IP 地址PING baidu.com (220.181.38.148) 56(84) bytes of data.64 bytes from 220.181.38.148 (220.181.38.148): icmp_seq=1 ttl=51 time=66.2 ms64 bytes from 220.181.38.148 (220.181.38.148): icmp_seq=2 ttl=51 time=56.4 ms--- baidu.com ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 2msrtt min/avg/max/mdev = 56.371/61.274/66.177/4.903 ms[root@localhost ~]\\# ping6 ff02::1 # ping 命令其实也可以兼容 IPv6 地址PING ff02::1(ff02::1) 56 data bytes64 bytes from fe80::8af6:d265:9b34:f1d6%ens160: icmp_seq=1 ttl=64 time=0.423 ms64 bytes from fe80::f4ac:5eff:fe0b:c1d2%ens160: icmp_seq=1 ttl=64 time=2.91 ms (DUP!)^C--- ff02::1 ping statistics ---1 packets transmitted, 1 received, +1 duplicates, 0% packet loss, time 0msrtt min/avg/max/mdev = 0.423/1.668/2.913/1.245 ms ​当网络中存在不止一块网卡且连接不止一个网络时，使用 ping 命令测试本地链路地址和本地链路全节点多播组（ff02::1）时，必须使用作用域标识符来显示指定要使用的网络接口。若遗漏，则将显示错误 connect: Invalid argument。 ​对 ff02::1 执行 ping 可能有助于找到本地网络上的其他 IPv6 节点。如上例中找打了具有 IPv6 本地链路地址 fe80::f4ac:5eff:fe0b:c1d2 的其他主机。 123456789[root@localhost ~]\\# ping fe80::f4ac:5eff:fe0b:c1d2%ens160PING fe80::f4ac:5eff:fe0b:c1d2%ens160(fe80::f4ac:5eff:fe0b:c1d2%ens160) 56 data bytes64 bytes from fe80::f4ac:5eff:fe0b:c1d2%ens160: icmp_seq=1 ttl=64 time=3.19 ms64 bytes from fe80::f4ac:5eff:fe0b:c1d2%ens160: icmp_seq=2 ttl=64 time=4.11 ms^C--- fe80::f4ac:5eff:fe0b:c1d2%ens160 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 3msrtt min/avg/max/mdev = 3.186/3.645/4.105/0.463 ms ​IPv6 本地链路地址可以由同一链路上的其他主机使用。可以尝试使用 IPv6 本地链路地址 ssh 连接到你的虚拟机或同一网络下的其他主机。 路由故障排查 显示路由表 ​使用 ip route 命令选项来显示路由信息。 1234[root@localhost ~]\\# ip routedefault via 192.168.224.44 dev ens160 proto dhcp metric 100 192.168.122.0/24 dev virbr0 proto kernel scope link src 192.168.122.1 linkdown 192.168.224.0/24 dev ens160 proto kernel scope link src 192.168.224.139 metric 100 ​以上命令仅显示了 IPv4 路由表。使用 ip -6 route 命令即可显示 IPv6 路由表。 12345[root@localhost ~]\\# ip -6 route::1 dev lo proto kernel metric 256 pref medium240e:41d:8010:c75::/64 dev ens160 proto ra metric 100 pref mediumfe80::/64 dev ens160 proto kernel metric 100 pref mediumdefault via fe80::f4ac:5eff:fe0b:c1d2 dev ens160 proto ra metric 100 pref high ​一个网络接口同时具有两个 IPv6 地址，即一个对外网络全局地址和一个本地链路地址。 追踪流量采用的路由 ​使用 traceroute 或 tracepath 命令来追踪网络流量通过多少个路由器来到达远程主机以及其采用的路径。可以通过这两个命令检查网络中的路由器配置是否存在问题。 ​默认情况下，两个命令都使用 UDP 数据包来追踪数据路径，但是许多网络阻止 UDP 和 ICMP 流量。traceroute 命令拥有可以追踪 UDP（默认）、ICMP（-I）或 TCP（-T）数据包路径的选项。不过，默认情况下通常不安装 traceroute 命令。 12345678910[root@localhost ~]\\# tracepath bilibili.com 1?: [LOCALHOST] pmtu 1500 1: _gateway 2.647ms 1: _gateway 2.826ms 2: _gateway 3.126ms pmtu 1410 2: no reply 3: 183.29.251.1 67.107ms 4: no reply 5: 183.29.0.5 51.596ms ...... ​traceroute 输出中的每一行表示数据包在来源和最终目标之间所经过的路由器或跃点，也提供了其他信息，如往返用时（RTT）和最大传输单元（MTU）大小中的任何变化等。asymm 表示流量使用了不同的（非对称）路由到达该路由器的流量和从该路由器返回。显示的路由器是用于出站流量的路由器，而不是返回流量。 ​tracepath6 和 tracepath -6 命令等效于 IPv6 版本的 tracepath 和 traceroute 命令。 12345[root@localhost ~]\\# tracepath6 fe80::70b8:51ff:fe39:4e7f # tracepath 命令也兼容 IPv6 1?: [LOCALHOST] 0.027ms pmtu 1410 1: fe80::%ens160 2.619ms rea 1: fe80::%ens160 5.508ms rea Resume: pmtu 1410 hops 1 back 1 端口和服务故障排除 ​TCP 服务使用套接字作为通信的端点，其由 IP 地址、协议和端口号组成。服务通常侦听标准端口，而客户端则使用随机的可用端口。/etc/services 文件中列出了标准端口的常用名称。 ​ss 命令可用于显示套接字统计信息。ss 命令旨在替换 net-tools 软件包中所包含的较旧工具 netstat。 12345678910111213[root@localhost ~]\\# ss -ta # -t 只显示 TCP 连接，-a 显示所有（监听中和已建立的）套接字 State Recv-Q Send-Q Local Address:Port Peer Address:PortLISTEN 0 128 0.0.0.0:sunrpc 0.0.0.0:* LISTEN 0 32 192.168.122.1:domain 0.0.0.0:* LISTEN 0 128 0.0.0.0:ssh 0.0.0.0:*LISTEN 0 5 127.0.0.1:ipp 0.0.0.0:*LISTEN 0 128 127.0.0.1:x11-ssh-offset 0.0.0.0:* LISTEN 0 128 [::]:sunrpc [::]:*LISTEN 0 128 [::]:ssh [::]:* LISTEN 0 5 [::1]:ipp [::]:*LISTEN 0 128 [::1]:x11-ssh-offset [::]:* ESTAB 0 0 [fe80::8af6:d265:9b34:f1d6]%ens160:ssh [fe80::cdbe:da6f:b9b7:a07d]:4499 ESTAB 0 52 [fe80::8af6:d265:9b34:f1d6]%ens160:ssh [fe80::cdbe:da6f:b9b7:a07d]:14318 ​ss 命令和 netstat 命令的常用选项： 选项 描述 -n 显示接口和端口的编号，而不显示名称。 -t 显示 TCP 套接字。 -u 显示 UDP 套接字。 -l 仅显示侦听中的套接字。 -a 显示所有（侦听中和已建立的）套接字。 -p 显示使用套接字的进程。 -A inet 对于 inet 地址，显示活动的连接（但不显示侦听套接字），也就是说，忽略本地 UNIX 域套接字。对于 ss，同时显示 IPv4 和 IPv6连接。对于 netstat，仅显示 IPv4 连接（netstat -A inet6 显示IPv6，netstat -46 则同时显示 IPv4 和 IPv6）。","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"Linux 网路管理基础","slug":"Linux | Linux 网络管理基础","date":"2022-08-15T03:43:49.155Z","updated":"2022-08-15T03:45:32.159Z","comments":true,"path":"2022-08-15-Linux | Linux 网络管理基础.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20Linux%20%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%9F%BA%E7%A1%80.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 网络接口 可以使用网络端口的名称来识别和配置其连接网络的方式。旧版的 RHEL 以 eth0、eth1、eth2...等名称命名各个网络接口，这种方式存在一定缺陷故已被淘汰。新版 RHEL 采用另一种命名体系。系统将基于固件信息、PCI总线拓扑及网络设备的类型来分配网络接口名称，不再基于检测顺序： ​网络接口的名称以接口类型开头： 以太网接口以 en 开头； WLAN 接口以 wl 开头； WWAN 接口以 ww 开头。 在类型之后，接口名称的其余部分将基于服务器固件所提供的信息，或由 PCI 拓扑中设备的位置确定。 oN 代表这是一个板载设备，且服务器的固件提供设备的索引编号 N。如：eno1 代表板载以太网设备 1。许多服务器不提供此信息； sN 表示该设备位于 PCI 热插拔插槽 N 中； pMsN 表示这是一个位于插槽 N 中总线 M 上的 PCI 设备。如：wlp4s0 代表位于插槽 0 中 PCI 总线 4 上的 WLAN 卡。若该卡是一个多功能设备，设备名称中还会添加 fP,如 enp0s1f1。 此种命名方法命名的设备的名称之后不会自动发生变化。 IPV6 地址 IPv6 地址的简写 ​IPv6 地址是一个 128 位数字，通常表示为八组以分号分隔的四个十六进制半字节。每个半字节均表示 4 位的 IPv6 地址，因此每个组表示 16 位的 IPv6 地址。如： ​ 2001:0db8:0000:0010:0000:0000:0000:0001 ​其中，冒号分开的每组中的前导零可以省略，若为 0000 仍需保留一个零： ​ 2001:db8:0:10:0:0:0:1 ​其中，一组或多组连续零又可以通过一个 :: 块来合并： ​ 2001:db8:0:10::1 IPv6 地址简写请注意以下原则： 抑制组中的前导零； 使用 :: 来尽可能地缩短； 若地址包含两个连续的零组，且长度相同，则最好将每个组最左边的零组缩短为 :: ，最右边的组缩短为 :0:，长度不同的话使用 :: 缩短最长的零组，短的使用 :0:； 十六进制数字使用小写字母表示； 后面要跟上网络端口时使用方括号将 IPv6 地址括住，如：[2001:db8:0:10::1]:80。 IPv6 子网划分 ​普通 IPv6 单薄地址分为两部分：网络前缀和接口 ID。网络前缀标识子网，接口 ID 标识子网中的任一子网接口；与 IPv4 不同，IPv6 具有一个标准的子网掩码 /64，用于几乎所有普通地址，因此一个 IPv6 地址因此就被分为两半，其中一半是网络前缀、一半是接口 ID。 ​通常，网络提供商将为组织分配一个较短的子网掩码，如 /48。这会保留其余网络部分以用于通过这一分配的前缀来指定子网（长度始终为 /64）。对于 /48 分配，将保留16位以用于子网（最多65536）个子网。 ​以下列举部分常用 IPv6 地址和网络： IPv6地址或网络 用途 描述 ::1/128 本地主机 等效于 IPv4 127.0.0.1/8，在回环接口上设置。 :: 未指定的地址 等效于 IPv4 0.0.0.0。对于网络服务，这可能标识其正在侦听所有已配置的 IP 地址。 ::/0 默认路由（IPv6互联网） 等效于 IPv4 0.0.0.0/0。路由表中的默认路由与此网络匹配；此网络的路由器是在没有更好路由的情况下发送所有流量的位置。 2000::/3 全局单播地址 ”普通“的 IPv6 地址，目前由 IANA 从该空间进行分配。这等同于范围从 2000::/16 到 3fff::/16 的所有网络。 fd00::/8 唯一本地地址（RFC 4193） 指在一个组织内部可达的ipv6地址，这类地址不能出现在internet上。具有全球唯一的前缀，可以进行网络之间的私有连接，而不必担心地址冲突等问题。如果出现路由泄漏，不会造成Internet路由冲突。在应用中，上层应用程序将这些地址看作全球单播地址。 fe80::/10 本地链路地址 用于邻居发现协议和无状态自动配置进程中链路本地上节点之间的通信。使用链路本地地址作为源或目的地址的数据包不会被转发到其他链路上。 ff00::/8 多播 等效于 IPv4 224.0.0.0/4。多播用于同时传输到多个主机，并且在 IPv6 中特别重要，因为 IPv6 没有广播地址。 ​IPv6 中的本地链路地址是一个无法路由的地址。仅用于与特定网络链路上的主机进行通信。系统上的每个网络接口都通过 fe80::/64 网络上的本地链路地址来自动配置。为确保其唯一性，本地链路地址的接口 ID 是通过网络接口的以太网硬件地址来构建的。 ​将 48 位 MAC 地址转换为 64 位接口 ID 的一般方法是反转 7 位的 MAC 地址，然后在其两个中间字节之间插入 ff:fe。如： 网络前缀：fe80::/64； MAC 地址：00:11:22:aa:bb:cc； 本地链路地址：fe80::211:22ff:feaa:bbcc/64。 ​其他计算机的本地链路地址可以由相同链路上的其他主机像普通地址那样使用。由于每个链路具有 fe80::/64 网络，不能使用路由表来正确地选择出站接口。在地址的结尾必须使用作用域标识符来指定与本地链路地址进行通信时使用的链路。作用域标识符由 % 以及后跟的网络接口名称组成。例如，要使用 ping6 对本地链路地址 fe80::211:22ff:feaa:bbcc 进行 ping 操作（使用连接到 ens160 网络接口的链路），正确的命令语法如下： 1[root@localhost ~]\\# ping6 fe80::211:22ff:feaa:bbcc%ens160 ​IPv6 中的一个重要多播地址是 ff02::1（全节点本地链路地址），对此地址进行 ping 操作会将流量都发送到链路上的所有节点。 1234[root@localhost ~]\\# ping6 ff02::1%ens160PING ff02::1%ens160(ff02::1%ens160) 56 data bytes64 bytes from fe80::8af6:d265:9b34:f1d6%ens160: icmp_seq=1 ttl=64 time=0.888 ms...... IPv6 地址配置 ​IPv6 也支持手动配置以及两种动态配置 IPv6 地址的方法，动态分配方式其中的一种是使用 DHCPv6 协议。 ​在 IPv6 中，以下接口 ID 是保留的，无法用于主机上的普通网络地址： 由链路上的所有路由器使用的全零标识符 0000:0000:0000:0000（子网路由器任意广播）。 标识符 fdff:ffff:ffff:ff80 到 fdff:ffff:ffff:ffff。 ​由于没有广播地址，DHCPv6 的工作原理与适用于 IPv4 的 DHCP 有所不同。一般来说，主机将 DHCPv6请求从其本地链路地址发送到 ff02::1:2 上的端口 547/UDP，即全 dhcp 服务器本地链路多播组。然后 DHCPv6 服务器通常向客户端的本地链路地址上的端口 546/UDP 发送一个包含相应信息的回复。涉及软件包：dhcp。 ​除了 DHCPv6 之外，IPv6 也支持另外一个动态配置方法：SLAAC（无状态地址自动配置）。使用 SLAAC 时，主机通常使用本地链路 fe80::/64 地址来调出其接口。主机随后向 ff02::2（即，全路由器本地链路多播组）发送一个”路由器请求“。本地链路上的 IPv6 路由器以网络前缀以及其他可能的信息来响应主机的本地链路地址。主机随后将该网络前缀与其通常构建的接口 ID（构建方式与本地链路地址相同）配合使用。路由器定期发送多播更新（路由器播发）以确认或更新其提供的信息。涉及软件包：radvd。 域名解析 ​使用 ip 地址连接服务器会很不便，使用具有一定代表意义的名称来标识某个主机会更加方便。Linux 有多种机制可以将主机名映射到 ip 地址，称为 域名解析。 ​一种方法是在各个系统上的 /etc/hosts 文件中为每个名称设置一个静态条目。多台服务器的话需要手动更行每台服务器的文件副本，比较繁琐。 ​对于大多数主机，可以使用域名解析网络服务，从主机名查找其地址（或进行反查）。DNS（域名服务器）是提供主机名到 ip 地址映射的分布式服务器。域名服务器无需与主机位于同一子网，仅仅可供主机访问即可。Linux 中通常通过 /etc/resolv.conf 文件中的静态设置来配置如何提供域名解析服务。","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"系统时间维护","slug":"Linux | 系统时间维护","date":"2022-08-15T03:38:56.736Z","updated":"2022-08-15T03:42:21.132Z","comments":true,"path":"2022-08-15-Linux | 系统时间维护.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E7%B3%BB%E7%BB%9F%E6%97%B6%E9%97%B4%E7%BB%B4%E6%8A%A4.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 ​为了确保系统日志和日志记录的事件有正确的时间戳以及计算机的正常使用，我们需要通过 NTP 服务确保系统时间与互联网时间同步。 设置本地时钟和时区 ​通过网络时间协议（NTP）从互联网上的公共 NTP 服务器上获取正确的时间信息是确保本地系统时间正确的一种标准方法。 ​使用 timedatectl 命令可以简要的显示出当前的时间相关的系统设置，如系统的当前时间、时区和 NTP 同步设置。 12345678[root@localhost ~]\\# timedatectl Local time: Tue 2021-08-24 18:30:15 PDT Universal time: Wed 2021-08-25 01:30:15 UTC RTC time: Wed 2021-08-25 01:30:15 Time zone: America/Los_Angeles (PDT, -0700)System clock synchronized: yes NTP service: active RTC in local TZ: no ​查看系统时区数据库的内容： 12345[root@localhost ~]\\# timedatectl list-timezonesAfrica/AbidjanAfrica/AccraAfrica/Addis_Ababa...... ​若不知道自己该使用的时区配置信息，则可以通过 tzselect 命令来交互式的推断出适合自己的时区配置信息。该命令并不会对系统的时区设置进行任何更改。 ​更改当前时区需要 root 权限，可以使用 timedatectl set-timezone 命令更改系统设置更新当前时区。 123456789[root@localhost ~]\\# timedatectl set-timezone Asia/Shanghai[root@localhost ~]\\# timedatectl Local time: Wed 2021-08-25 09:47:26 CST Universal time: Wed 2021-08-25 01:47:26 UTC RTC time: Wed 2021-08-25 01:47:25 Time zone: Asia/Shanghai (CST, +0800)System clock synchronized: yes NTP service: active RTC in local TZ: no 🟢 若要使用 UTC 可以使用 timedatectl set-timezone UTC 命令将系统当前时区设置为 UTC。 ​开启或禁用 NTP 服务： 1[root@localhost ~]\\# timedatectl set-ntp false # 关闭 NTP，true 为开启 配置和监控 CHRONYD 本地 linux 系统通过 chronyd 服务与配置的 NTP 服务器同步来保证不准确的本地硬件时钟（RTC）保持正确运行。若没有可用的网络连接，chronyd 将计算 RTC 时钟漂移，记录在 /etc/chrony.conf 配置文件指定的 driftfile 变量中。 ​默认情况下不需要配置 chronyd 服务使用的授时服务器配置，但当本地系统处于孤立网络中时，就可能需要更改 NTP 服务器。 ​NTP 时间源的 stratum 决定其质量。stratum 确定计算机与高性能参考时钟偏离的跃点数。参考时钟是 stratum 0 的时间源。与之直接关联的 NTP 服务器是 stratum 1，而与该 NTP 服务器同步时间的计算机则是 stratum 2 时间源。 ​在 /etc/chrony.conf 配置文件中我们可以配置从两种时间源类别进行同步，它们分别是 server 和 peer。Server 比本地 NTP 服务器高一个级别，而 peer 则属于同一级别。可以指定多个 server 和多个 peer，每行指定一个。 ​添加一个授时服务器的具体格式如下： 1234# Use public servers from the pool.ntp.org project.# Please consider joining the pool (http://www.pool.ntp.org/join.html).# ......server ip或者域名 选项[常用 iburst] 🟢 修改 chronyd 配置文件后应该重新启动该服务，该服务不支持 reload。 ​chronyc 命令充当 chronyd 服务的客户端。设置好 NTP 同步后，应该使用 chronyc sources 命令来验证本地系统是否使用 NTP 服务器无缝同步系统时钟，使用 -v 选项可以获得更加详细的输出。 [root@localhost ~]\\# chronyc sources -v 210 Number of sources = 4 .-- Source mode '^' = server, '=' = peer, '#' = local clock. / .- Source state '*' = current synced, '+' = combined , '-' = not combined, | / '?' = unreachable, 'x' = time may be in error, '~' = time too variable. || .- xxxx [ yyyy ] +/- zzzz || Reachability register (octal) -. | xxxx = adjusted offset, || Log2(Polling interval) --. | | yyyy = measured offset, || \\ | | zzzz = estimated error. || | | \\ MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^+ time.cloudflare.com 3 6 377 35 -8470us[ -12ms] +/- 139ms ^- time.cloudflare.com 3 6 37 34 -6035us[-9624us] +/- 128ms ^* 139.199.215.251 2 6 173 32 -16ms[ -20ms] +/- 78ms ^- ntp7.flashdance.cx 2 6 162 162 -7138us[ -13ms] +/- 163ms ``","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"分析和存储系统日志","slug":"Linux | 分析和存储系统日志","date":"2022-08-15T03:29:18.977Z","updated":"2022-08-15T03:38:21.121Z","comments":true,"path":"2022-08-15-Linux | 分析和存储系统日志.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E5%88%86%E6%9E%90%E5%92%8C%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%E6%97%A5%E5%BF%97.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 系统日志概述 ​进程和操作系统内核会以发生的具体事件记录日志，这些日志可用于系统审核和问题的故障排除。 ​许多系统以文本文件的形式存储日志，它们一般都被保存在 /var/log 目录下。RHEL 内建了一个基于 Syslog 协议的标准日志记录系统。systemd-journald 和 rsyslog 服务处理红帽企业 linux 8 中的 syslog 消息。 Systemd-journald 服务是操作系统事件日志架构的核心。它收集许多来源的事件消息，包括内核、引导过程早期阶段的输出、守护进程启动和运行时的标准输出及标准错误，以及 syslog 事件。然后，他会将它们重构为一种标准格式，并写进带有索引的结构化系统日中。默认情况下，该日志存储在系统重启后不保留的文件系统上。 Rsyslog 服务对 syslog 消息进行排序，并将它们写入到在系统重启后不保留的日志文件中(/var/log)。rsyslog 服务会根据发送每条消息的程序类型或设备以及每条 syslog 消息的优先级，将日志消息排序到特定的日志文件。 以下是一些重要的日志文件： 日志文件 描述 /var/log/messages 包含全局系统消息，包括系统启动期间记录的消息。该文件存储邮件、作业调度、任务计划、守护程序、内核、授权、调试等模块的信息。 /var/log/boot.log 包含与系统启动相关的非 syslog 控制台消息。 /var/log/lastlog 显示最近所有用户的登录信息。只能通过 lastlog 命令来查看这个文件的内容。 /var/log/maillog 包含系统中运行的邮件服务器的日志信息。如 sendmail 日志包含所有已发送的邮件的信息。 /var/log/btmp 包含失败的尝试登陆的信息。使用 last 命令来预览这个文件。如：`last -f /var/log/btmp /var/log/cups 所有和打印或打印相关的日志消息。 /var/log/dnf.rpm.log 记录和软件包安装的相关日志。 /var/log/secure 包含认证与授权相关的信息。sshd 在此记录所有信息，包含失败的登陆。 /var/log/wtmp 所有登陆记录。使用 wtmp 可以指出谁登陆了系统，以及谁看了这个信息。 /var/log/audit 包含 Linux 授权守护进程（auditd）存储的信息。 /var/log/samba 包含 samba 服务的信息。 /var/log/sssd 系统安全服务守护程序用于管理远程目录和身份验证机制的访问。 /var/log/cron 与调度作业执行相关的消息。 🟢 有些应用不使用 syslog 管理他们的日志消息，但它们仍将其日志文件放在 /var/log 的某一子目录中。 查看系统日志文件 ​Syslog，其进程名为 rsyslog，根据设备日志消息的严重程度将日志分了八个优先级。 代码 优先级 严重性 0 emerg 系统不可用 1 alert 必须立即采取措施 2 crit 临界情况 3 err 非严重错误状况 4 warning 警告情况 5 notice 正常但重要的事件 6 info 信息性事件 7 debug 调试级别消息 ​Rsyslog 服务使用日志消息的设备和优先级来确定如何进行处理。其配置规则位于 /etc/rsyslog.conf 文件和 /etc/rsyslog.d 目录中拓展名为 .conf 的任何文件。通过在 /etc/rsyslog.d 目录中添加适当的文件，某应用的软件包可以轻松的添加属于自己的日志输出规则。 ​每个控制着 syslog 消息排序方式的规则都对应了其中一个配置文件中的一行。如： 123# Log anything (except mail) of level info or higher.# Don&#x27;t log private authentication messages!*.info;mail.none;authpriv.none;cron.none /var/log/messages ​其中，每行左侧表示与规则匹配的 syslog 消息的设备和严重性。每行右侧表示要将日志消息保存到的文件（或消息所要发送到的其他位置）。星号(*)是一个匹配所有值的通配符。 🟢 使用 logger 命令可以手动往系统日志中添加信息，使用方法详见 man page: logger(1)。 123[root@localhost ~]\\# logger -p user.info &quot;Test User Log&quot; # -p 选项指定优先级[root@localhost ~]\\# tail -n 1 -f /var/log/messagesAug 23 21:22:22 localhost root[3276]: Test User Log 查看系统日志条目 ​Systemd-journal 服务将日志数据存储在带有索引的结构化二进制文件中，该文件称为日志。此数据包含与日志事件相关的额外信息。例如，对于 syslog 事件，这可包含原始消息的设备和优先级。 🟢 系统运行日志默认存储在 /run/log 目录下，该目录下的内容会在系统重启后清除。 ​若要从系统运行日志中检索日志消息，可使用 journalctl 命令。可以使用此命令来查看日志中的所有消息，或根据各种选项和标准来搜索特定事件。如果以 root 身份运行该命令，则对日志具有完全访问权限。普通用户也可以使用此命令，但可能会被限制查看某些消息。 12345678journalctl [OPTIONS...] [MATCHES] # 查询 systemd 日志# 例子root@localhost ~]\\# journalctl # 不带参数默认输出 system.journal 的所有内容-- Logs begin at Mon 2021-08-23 21:08:56 PDT, end at Mon 2021-08-23 21:38:22 PDT. --Aug 23 21:08:56 localhost.localdomain kernel: Linux version 4.18.0-240.el8.x86_64 (mockbuild@x86-vm-09.build.eng.bos.redhat.com) (gcc version 8.3.1 20191121&gt;Aug 23 21:08:56 localhost.localdomain kernel: Command line: BOOT_IMAGE=(hd0,msdos1)/vmlinuz-4.18.0-240.el8.x86_64 root=UUID=360e2f42-d6de-4209-8487-f36b7cc6&gt;Aug 23 21:08:56 localhost.localdomain kernel: Disabled fast string operations...... ​journalctl 命令突出显示重要的日志消息：优先级为 notice 或 warning 的消息显示为粗体文本，而优先级为 error 或以上的消息则显示为红色文本。 ​成功利用日志进行故障排除和审核的关键在于，将日志搜索限制为仅显示相关的输出。 ​默认情况下，journalctl -n 显示最后 10 个条目，可在参数后面指定具体显示的条数。 12345[root@localhost ~]\\# journalctl -n 3-- Logs begin at Mon 2021-08-23 21:08:56 PDT, end at Mon 2021-08-23 21:40:06 PDT. --Aug 23 21:38:22 localhost.localdomain systemd-logind[1137]: New session 8 of user root.Aug 23 21:38:22 localhost.localdomain sshd[3450]: pam_unix(sshd:session): session opened for user root by (uid=0)Aug 23 21:40:06 localhost.localdomain chronyd[1070]: Source 2602:fcad:1::10 replaced with 124.108.20.1 ​类似 tail -f，journalctl -f 也可以实现日志内容的实时更新： 123456789101112[root@localhost ~]\\# journalctl -f-- Logs begin at Mon 2021-08-23 21:08:56 PDT. --Aug 23 21:38:22 localhost.localdomain sshd[3441]: Accepted password for root from 172.16.1.195 port 6922 ssh2Aug 23 21:38:22 localhost.localdomain systemd-logind[1137]: New session 7 of user root.Aug 23 21:38:22 localhost.localdomain systemd[1]: Started Session 7 of user root.Aug 23 21:38:22 localhost.localdomain sshd[3441]: pam_unix(sshd:session): session opened for user root by (uid=0)Aug 23 21:38:22 localhost.localdomain sshd[3450]: Accepted password for root from 172.16.1.195 port 6925 ssh2Aug 23 21:38:22 localhost.localdomain systemd[1]: Started Session 8 of user root.Aug 23 21:38:22 localhost.localdomain systemd-logind[1137]: New session 8 of user root.Aug 23 21:38:22 localhost.localdomain sshd[3450]: pam_unix(sshd:session): session opened for user root by (uid=0)Aug 23 21:40:06 localhost.localdomain chronyd[1070]: Source 2602:fcad:1::10 replaced with 124.108.20.1Aug 23 21:48:56 localhost.localdomain PackageKit[2105]: search-file transaction /131_bcadadca from uid 0 finished with success after 27ms ​使用 -p 选项可以根据日志的优先级过滤日志输出，其中参数可指定优先级的名称或编号，journalctl -p 命令会显示该优先级及以上的日志输出。 123[root@localhost ~]\\# journalctl -p err-- Logs begin at Mon 2021-08-23 21:08:56 PDT, end at Mon 2021-08-23 21:48:56 PDT. --Aug 23 21:09:14 localhost.localdomain kernel: piix4_smbus 0000:00:07.3: SMBus Host Controller not enabled! ​在查找具体事件时，可以将输出限制为某一特定的时间段。--since 和 --until 选项，它们可以将输出限制为特定的时间范围。其参数的具体格式限制为 YYYY-MM-DDhh:mm:ss，除了这两个选项，其还接受 yesterday、today 和 tomorrow 作为有效参数。 1234567[root@localhost ~]\\# journalctl --since &quot;2021-08-23 22:00:00&quot; --until &quot;2021-08-23 22:05:00&quot;-- Logs begin at Mon 2021-08-23 21:08:56 PDT, end at Tue 2021-08-24 01:22:49 PDT. --Aug 23 22:01:01 localhost.localdomain CROND[3760]: (root) CMD (run-parts /etc/cron.hourly)Aug 23 22:01:01 localhost.localdomain run-parts[3763]: (/etc/cron.hourly) starting 0anacronAug 23 22:01:01 localhost.localdomain anacron[3769]: Anacron started on 2021-08-23Aug 23 22:01:01 localhost.localdomain run-parts[3771]: (/etc/cron.hourly) finished 0anacronAug 23 22:01:01 localhost.localdomain anacron[3769]: Normal exit (0 jobs run) ​也可以指定相对于当前的某个时间以后的所有条目。 1234567[root@localhost ~]# journalctl --since &quot;-1.1 hour&quot;-- Logs begin at Mon 2021-08-23 21:08:56 PDT, end at Tue 2021-08-24 01:22:49 PDT. --Aug 24 01:01:01 localhost.localdomain CROND[5331]: (root) CMD (run-parts /etc/cron.hourly)Aug 24 01:01:01 localhost.localdomain run-parts[5334]: (/etc/cron.hourly) starting 0anacronAug 24 01:01:01 localhost.localdomain run-parts[5342]: (/etc/cron.hourly) finished 0anacronAug 24 01:01:01 localhost.localdomain anacron[5340]: Anacron started on 2021-08-24Aug 24 01:01:01 localhost.localdomain anacron[5340]: Normal exit (0 jobs run) 🟢 --since 和 --until 支持的更复杂的时间格式可参见 systemd.time(7) man page。 ​可以使用 journalctl -o 命令以特定的模式（verbose/export/json 等）输出。 123456[root@localhost ~]\\# journalctl -o verbose-- Logs begin at Mon 2021-08-23 21:08:56 PDT, end at Tue 2021-08-24 &gt;Mon 2021-08-23 21:08:56.476108 PDT [s=ac8c7a315ec04e1c98b39f3eba4fe1&gt; _SOURCE_MONOTONIC_TIMESTAMP=0 _TRANSPORT=kernel PRIORITY=5 ​一些特定的系统日志筛选常用字段，可用于搜索与特定进程或事件相关的行。 筛选选项 作用 _COMM 指定命令的名称 _EXE 指定进程的可执行文件路径 _PID 指定进程的 PID _UID 指定运行该进程的用户的 UID _SYSTEMD_UNIT 指定启动该进程的 systemd 单元 ​也可以组合多个系统日志字段以实现更加精细的搜索查询，例如： 12345678910[root@localhost ~]\\# journalctl -n 3 _SYSTEMD_UNIT=sshd.service _UID=0 # 与操作-- Logs begin at Mon 2021-08-23 21:08:56 PDT, end at Tue 2021-08-24 02:03:19 PDT. --Aug 23 21:38:22 localhost.localdomain sshd[3441]: pam_unix(sshd:session): session opened for user root by (uid=0)Aug 23 21:38:22 localhost.localdomain sshd[3450]: Accepted password for root from 172.16.1.195 port 6925 ssh2Aug 23 21:38:22 localhost.localdomain sshd[3450]: pam_unix(sshd:session): session opened for user root by (uid=0)[root@localhost ~]\\# journalctl _COMM=sshd + _PID=1247 # 或操作-- Logs begin at Mon 2021-08-23 21:08:56 PDT, end at Tue 2021-08-24 02:03:19 PDT. --Aug 23 21:09:31 localhost.localdomain sshd[1251]: Server listening on 0.0.0.0 port 22.Aug 23 21:09:31 localhost.localdomain sshd[1251]: Server listening on :: port 22.Aug 23 21:11:38 localhost.localdomain cupsd[1247]: REQUEST localhost - - &quot;POST / HTTP/1.1&quot; 200 363 Create-Printer-Subscriptions successful-ok 保留系统日志 ​默认情况下，系统日志保存在 /run/log/journal 目录中，这意味着系统重启时这些日志会被清除。可以在 /etc/systemd/journald.conf 文件中更改 systemd-journald 服务的配置设置，使日志在系统重启后保留下来。 ​/etc/systemd/journald.conf 文件中的 Storage 参数决定系统日志以易失性方式存储，还是在系统重启后持久保留，该参数的可选值有以下几种： 值 日志存储位置 说明 persistent /var/log/journal 持久保留，若该目录不存在，systemd-journald 服务会自动创建。 volatile /run/log/journal 存放在内存文件系统，/run 目录下的内容重启后丢失。 auto（默认） 以上两者任一 默认 /run/log/journal，但若 /var/log/journal 目录存在，则存放在该目录下。 持久系统日志的优点是系统启动后就可立即利用历史数据。 即便是持久日志，并非所有数据都将永久保留，此日志项具有一个内置的日志轮转机制会每月触发。 修改日志存储配置文件需要重新载入该服务，相关内容可参见 13. 控制服务和守护进程 章节。 ​默认情况下，日志的大小不能超过所处文件系统的 10%，也不能造成文件系统的可用空间低于 15%，可以在 /etc/systemd/journald.conf 中为运行时和持久日志调整这些值。当 systemd-journald 进程启动时，会记录当前的日志大小限额。 ​以下命令输出显示了反映当前大小限额的日志条目： 123456[root@localhost ~]\\# journalctl | grep -E &#x27;Runtime|System journal&#x27;Aug 24 17:47:16 localhost.localdomain systemd-journald[304]: Runtime journal (/run/log/journal/6651ee1da4824a37975cd5245c8cb076) is 8.0M, max 185.4M, 177.4M free.Aug 24 17:47:29 localhost.localdomain systemd-journald[694]: Runtime journal (/run/log/journal/6651ee1da4824a37975cd5245c8cb076) is 8.0M, max 185.4M, 177.4M free.Aug 24 17:47:29 localhost.localdomain systemd-journald[694]: Runtime journal (/run/log/journal/6651ee1da4824a37975cd5245c8cb076) is 8.0M, max 185.4M, 177.4M free.Aug 24 17:47:36 localhost.localdomain systemd[1]: Starting Tell Plymouth To Write Out Runtime Data...Aug 24 17:47:36 localhost.localdomain systemd[1]: Started Tell Plymouth To Write Out Runtime Data. ​使用持久存储的 systemd-journald 服务会存储系统一次或多次启动后的日志，若要根据系统的每次启动筛选日志则可以使用选项 -b： 123[root@localhost ~]\\# journalctl -b 1 # 检索日志存储的第一次启动的条目[root@localhost ~]\\# journalctl -b # 检索当前系统启动启动后的条目[root@localhost ~]\\# journalctl -b -1 # 过去一次的系统启动时的tiao","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"配置和保护 SSH","slug":"Linux | 配置和保护 SSH","date":"2022-08-15T03:23:44.407Z","updated":"2022-08-15T03:27:26.903Z","comments":true,"path":"2022-08-15-Linux | 配置和保护 SSH.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BF%9D%E6%8A%A4%20SSH.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 识别远程用户 ​通过 w 命令查看当前登陆的用户 12345[root@localhost ~]\\# w 20:39:40 up 30 min, 2 users, load average: 0.03, 0.02, 0.04USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATstudent tty2 tty2 20:10 30:20 27.28s 0.29s /usr/liroot pts/1 172.16.1.195 20:37 0.00s 0.09s 0.02s w 使用免密登陆（公私钥对） ​SSH 可通过公钥加密的方式保持通信安全。当某一 SSH 客户端连接到 SSH 服务器时，在该客户端登陆之前，服务器会向其发送公钥副本。这颗用于设置通信渠道的安全加密，并可验证客户端的服务器。 🟢 设置位于 ~/.ssh/config 文件或 /etc/ssh/ssh_config 中的 StrictHostKeyChecking 参数为 yes 可使 ssh 命令在公钥不匹配时始终中断 SSH 连接。 配置步骤 本地主机执行 ssh-keygen -t rsa 命令生成公私钥对； 1234567891011121314151617181920212223242526[root@localhost ~]\\# ssh-keygen -t rsaGenerating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): # 保存 key 的文件绝对路径Created directory &#x27;/root/.ssh&#x27;.Enter passphrase (empty for no passphrase): # 口令Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa. # 私钥文件绝对路径Your public key has been saved in /root/.ssh/id_rsa.pub. # 公钥文件绝对路径The key fingerprint is:SHA256:+wQfHxm3T7+yJSobz6QXWeh2JU3WqQgfpYuxjWzlX90 root@localhost.localdomainThe key\\&#x27;s randomart image is:+---[RSA 3072]----+| .. o|| . .. +.|| .oo= * || . O+.B +o|| S*o+= +.E|| .+ B.o.o.|| ..+.+o .o|| +*...o .|| o=+ .o. |+----[SHA256]-----+[root@localhost ~]\\# ll /root/.sshtotal 8-rw-------. 1 root root 2610 Aug 19 22:42 id_rsa # 密钥文件-rw-r--r--. 1 root root 580 Aug 19 22:42 id_rsa.pub # 公钥文件 本地主机执行 ssh-copy-id -i ~/.ssh/id_rsa.pub user@host_name_or_ip 命令将公钥文件发送到需要免密登陆的服务器； 123456789101112[root@localhost ~]\\# ssh-copy-id -i ~/.ssh/id_rsa.pub skinyi@127.0.0.1/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: &quot;/root/.ssh/id_rsa.pub&quot;The authenticity of host &#x27;127.0.0.1 (127.0.0.1)&#x27; can\\&#x27;t be established.ECDSA key fingerprint is SHA256:CYiNIK6WgrScHzOuI/rnxIdZN68Fm0LVvFKbCzx721w.Are you sure you want to continue connecting (yes/no/[fingerprint])? yes/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keysskinyi@127.0.0.1\\&#x27;s password: Number of key(s) added: 1Now try logging into the machine, with: &quot;ssh &#x27;skinyi@127.0.0.1&#x27;&quot; and check to make sure that only the key(s) you wanted were added. （与第二步二选一）在远程机器上手动导入公钥：将 id_rsa.pub 文件中的内容复制追加到远程主机的 ~/.ssh/authorized_keys 文件中去； 12[root@localhost .ssh]\\# cat ~/.ssh/authorized_keysssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAzIU/3G5LbJEs763JRhvfTzdWAUdfmbRBTzVUo3r0IPnGDUIF135wR7FoI6KVc6jFesgJKfkGos06GdphPgF04z5tFG5VaJS+xQZepveGza2QH6eMssBNwzpZ517FQkRs1l3pLbHweI47gByhRx1xMKWjWX5dhkI0aiNaf2GAZlevb4YNRznx6MEj39LdNEqFKHdfU0iybFDm1p0ql+jPGV7T7N/Xz4GRvnuZQGUrBK39tzAdLHDlf8lU5Muhs8zJ0pMzv7tRdJCMNZ6gW+4dK6GTaOGAR6tc4HwGgIYTOPLGbYpdyJpdNd8hvBp5b17jAs5xLZHib4PVlZJJ6gw== rsa2048-082021 验证。 🔴 注意：远程机器的 .ssh 目录需要 700 权限，authorized_keys 文件需要 600 权限。否则将会被拒绝连接。 已知主机密钥管理 ​若远程主机公钥被替换，则需要在本地主机上编辑已知主机文件以确保将旧公钥条目替换为新公钥条目。 ​远程主机共享的公钥会在本地 /etc/ssh/ssh_known_hosts 或 ~/.ssh/known_hosts 文件中记录。例如： 12[root@localhost .ssh]\\# cat known_hosts127.0.0.1 ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBBnrDFHMD5vaRSn1P9CN5FTpHTGEnAR9n0PN15bMdmD/dNcUQUYGsrKva+StL4y1CXGK4FurJ9gDLliRvjere+U= ​其中，每个公钥各占一行。每条记录的第一个字段是共享该公钥的主机名和 IP 地址的列表；第二个字段是公钥的加密算法；最后一个字段是公钥本身。 ​远程主机将公钥文件存放在 /etc/ssh/ 目录下，其拓展名为 .pub。 SSH 配置优化 ​OpenSSH 服务端由一个名为 sshd 的守护进程提供。它的主配置文件为 /etc/ssh/sshd_config。 禁止远程使用 root 账户登陆 ​完全禁止可以将 /etc/ssh/sshd_config 配置文件中的 PermitRootLogin 配置设置为 no，仅允许通过密钥登陆可以将其值设置为 without-password。 仅允许使用公私钥对的方式进行登陆 ​此场景下可以将 /etc/ssh/sshd_config 配置文件中的 PasswordAuthentication 配置为 no。 🟢 修改 sshd 服务的配置文件后，请使用 systemctl reload sshd 命令确保更改立即生效。","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"控制服务和守护进程","slug":"Linux | 控制服务和守护进程","date":"2022-08-15T02:37:40.706Z","updated":"2022-08-15T02:45:47.715Z","comments":true,"path":"2022-08-15-Linux | 控制服务和守护进程.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E6%8E%A7%E5%88%B6%E6%9C%8D%E5%8A%A1%E5%92%8C%E5%AE%88%E6%8A%A4%E8%BF%9B%E7%A8%8B.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 SYSTEMCTL命令摘要 任务 命令 查看有关单元状态的详细信息 systemctl status UNIT 在运行中的系统上停止一项服务 systemctl stop UNIT 在运行中的系统上启动一项服务 systemctl start UNIT 在运行中的系统上重新启动一项服务 systemctl restart UNIT 重新加载运行中服务的配置文件 systemctl reload UNIT 彻底禁用服务，使其无法手动启动或在系统引导时启动 systemctl mask UNIT 使屏蔽的服务变为可用 systemctl unmask UNIT 将服务配置为在系统引导时启动 systemctl enable UNIT 禁止服务在系统引导时启动 systemctl disable UNIT 列出指定单元依赖的单元 systemctl list-dependencies UNIT 认识 SYSTEMD 服务 ​Systemd 服务可以管理系统守护进程和网络服务，包括 Linux 的启动，一般包括服务启动和服务管理。它可在系统引导时以及运行中的系统上激活系统资源、服务器守护进程和其他进程。 ​守护进程是在执行各种任务的后台等待或运行的进程。一般情况下，守护进程在系统引导时自动启动并持续运行至关机或手动停止。按照惯例，许多守护进程的名称以字母 d 结尾。 ​systemd 意义上的服务通常指的是一个或多个守护进程，但启动或停止一项服务可能会对系统的状态进行一次性更改，不会留下守护进程之后继续运行（称为 oneshot）。 ​在 RHEL 中，第一个启动的进程（PID 1）是 systemd。 如下是 systemd 提供的几项功能： 并行化功能（同时启动多个服务），它可提高系统的启动速度。 按需启动守护进程，而不需要单独的服务。 自动服务依赖关系管理，可以防止长时间超时。例如，只有在网络可用时，依赖网络的服务才会尝试启动。 利用 Linux 控制组一起追踪相关进程的方式。 SYSTEMD 服务单元 ​Systemd 使用单元来管理不同类型的对象。 单元类型 拓展名 描述 系统服务 .service 用于启动、停止、重启和重载经常访问的守护进程，如 web 服务器。 进程间通信（IPC）套接字 .socket 由 Systemd 应监控的进程间通信（IPC）套接字。如果客户端连接套接字，systemd 将启动一个守护进程并将连接传递给它。套接字单元用于延迟系统启动时的服务启动，或者按需启动不常使用的服务。 路径单元 .path 用于将服务的激活推迟到特定文件系统更改发生之后。这通常用于使用假脱机目录的服务，如打印系统。 Target .target 定义 target 信息(类似之前的 run-level)及依赖关系，一般仅包含 Unit 段 设备单元 .device 对于 /dev 目录下的硬件设备，主要用于定义设备之间的依赖关系 挂载单元 .mount 定义文件系统的挂载点，可以替代过去的 /etc/fstab 配置文件 自动挂载单元 .automount 用于控制自动挂载文件系统，相当于 SysV-init 的 autofs 服务 Scope .scope 非用户创建，由 Systemd 运行时产生的，描述一些系统服务的分组信息 Slice .slice 用于表示一个 CGroup 的树 Snapshot .snapshot 用于表示一个由 systemctl snapshot 命令创建的 Systemd Units 运行状态快照，可以切回某个快照 交换分区单元 .swap 定义一个用户做虚拟内存的交换分区 定时器单元 .timer 用于配置在特定时间出发的任务，替代了 Crontab 的功能 若要修改某单元文件请勿在 /usr/lib/systemd/system 目录里直接修改，而应在 /etc/systemd/system 目录下创建该单元文件的一个副本，然后修改该副本文件。Systemd 会优先使用 /etc/systemd/system 目录下的单元文件。 查看所有已加载的服务单元 ​可以使用以下命令来列出 systemd 加载的所有服务单元： 12345[root@localhost ~]\\# systemctl list-units --type=service # 指定不同的 type 可以列出不同的单元类型UNIT LOAD ACTIVE SUB DESCRIPTION abrt-journal-core.service loaded active running Creates ABRT problems from coredumpctl messagesabrt-oops.service loaded active running ABRT kernel log watcher...... ​其中，该命令输出的各列的意义是： 列名 含义 UNIT 单元名称 LOAD systemd 是否正确解析了单元的配置并将该单元加载到内存中 ACTIVE 单元的高级别激活状态。此信息表明单元是否已成功启动 SUB 单元的低级别激活状态。此信息指示有关该单元的更多详细信息。信息视单元类型、状态以及单元的执行方式而异 DESCRIPTION 单元的简短描述 ​默认情况下，``systemctl list-units --type=service` 命令仅列出激活状态为 active 的服务单元。指定 --all 选项可列出所有服务单元，不论激活状态如何： 1234[root@localhost ~]\\# systemctl list-units --type=service --all UNIT LOAD ACTIVE SUB DESCRIPTION abrt-ccpp.service loaded inactive dead Install ABRT coredump hook abrt-journal-core.service loaded active running Creates ABRT problems from coredumpctl messages ​使用 --state= 选项可按照 LOAD、ACTIVE 或 SUB 字段中的值进行筛选。 1234[root@localhost ~]\\# systemctl list-units --type=service --state=dead | head -n 3 UNIT LOAD ACTIVE SUB DESCRIPTION abrt-ccpp.service loaded inactive dead Install ABRT coredump hook abrt-vmcore.service loaded inactive dead Harvest vmcores for ABRT ​不带任何参数运行 systemctl 命令可以列出已加载和活动的单元。 12345678910111213141516[root@localhost ~]\\# systemctlUNIT LOAD ACTIVE SUB DESCRIPTION proc-sys-fs-binfmt_misc.automount loaded active waiting Arbitrary Executable File Formats File System Automount Po&gt;sys-devices-pci0000:00-0000:00:11.0-0000:02:00.0-usb2-2\\x2d2-2\\x2d2.1-2\\x2d2.1:1.0-bluetooth-hci0.device loaded active plugged /sys/devices/pci0000:00/0000:00:11.0/0000:02:00.0/usb2/2-2&gt;......-.mount loaded active mounted Root Mount boot.mount loaded active mounted /boot......cups.path loaded active running CUPS Scheduler systemd-ask-password-plymouth.path loaded active waiting Forward Password Requests to Plymouth Directory Watch ......init.scope loaded active running System and Service Manager session-2.scope loaded active running Session 2 of user student ......... 查看所有已安装的单元文件的状态 ​systemctl list-units 命令显示 systemd 服务尝试解析并加载到内存中的单元；它不显示已安装但未启用的单元。可以使用以下命令来查看所有已安装的单元文件的状态： 1234[root@localhost ~]\\# systemctl list-unit-filesUNIT FILE STATE proc-sys-fs-binfmt_misc.automount static -.mount generated ​*--type=* 以及 state= 选项同样适用于此命令。其中 STATE 的可选值为 [enabled | disabled | static | masked]。 3. 查看服务状态 ​使用 systemctl status name.type 命令来查看特定单元的状态，如果未提供单元类型，则 systemctl 将显示服务单元的状态（如果存在）。 12345678910111213141516171819202122[root@localhost ~]\\# systemctl status cups● cups.service - CUPS Scheduler Loaded: loaded (/usr/lib/systemd/system/cups.service; enabled; vendor preset: e&gt; Active: active (running) since Mon 2021-08-09 17:08:41 PDT; 1h 11min ago Docs: man:cupsd(8) Main PID: 1213 (cupsd) Status: &quot;Scheduler is running...&quot; Tasks: 1 (limit: 23503) Memory: 3.7M CGroup: /system.slice/cups.service └─1213 /usr/sbin/cupsd -lAug 09 17:08:40 localhost.localdomain systemd[1]: Starting CUPS Scheduler...Aug 09 17:08:41 localhost.localdomain systemd[1]: Started CUPS Scheduler.......[root@localhost ~]\\# systemctl status cups.path● cups.path - CUPS Scheduler Loaded: loaded (/usr/lib/systemd/system/cups.path; enabled; vendor preset: enab&gt; Active: active (running) since Mon 2021-08-09 17:08:29 PDT; 1h 13min agoAug 09 17:08:29 localhost.localdomain systemd[1]: Started CUPS Scheduler....... ​一些重要字段的含义： 字段 描述 Loaded 服务单元是否已加载到内存中。 Active 服务单元是否正在运行，若是，他已经运行了多久。 Main PID 服务的主进程 ID, 包括命令名称。 Status 有关该服务的其他信息。 ​Status 字段的不同值的含义： 值 描述 loaded 单元配置文件已加载处理。 active(running) 正在通过一个或多个持续进程运行。 active(exited) 已成功完成一次性配置。 active(waiting) 运行中，但正在等待事件。 inactive 不在运行。 enabled 在系统引导时启动。 disabled 未设为在系统引导时启动。 static 无法启用，但可以由某一启用的单元自动启动。 验证服务的状态 ​systemctl 命令提供了一些方法来验证服务的具体状态。 123456[root@localhost ~]\\# systemctl is-active sshd # 是否活动active # inactive[root@localhost ~]\\# systemctl is-enabled sshd # 是否自启 enabled # disabled[root@localhost ~]\\# systemctl is-failed sshd # 是否启动失败active # failed，若已被停止，则 unknown 或 inactive ​列出所有启动失败的单元： 123[root@localhost ~]\\# systemctl --failed --type=service0 loaded units listed. Pass --all to see loaded but inactive units, too.To show all installed unit files use &#x27;systemctl list-unit-files&#x27;. 控制系统服务 手动启停服务 ​手动启停服务的原因：1. 更新服务；2. 更改配置文件；3. 卸载服务；4. 启动不常使用的服务。 ​启动服务前，可以先用 systemctl status 命令验证服务是否未在运行。启停服务需要 root 权限进行操作。以 cups 服务为例，以下命令展示了启停服务的命令： 1234567891011121314151617181920212223242526272829303132333435# 验证服务是否已经启动[root@localhost ~]\\# systemctl status cups● cups.service - CUPS Scheduler Loaded: loaded (/usr/lib/systemd/system/cups.service; enabled; vendor preset: e&gt; Active: active (running) since Mon 2021-08-09 17:08:41 PDT; 2h 0min ago Docs: man:cupsd(8) Main PID: 1213 (cupsd) Status: &quot;Scheduler is running...&quot; Tasks: 1 (limit: 23503) Memory: 3.7M CGroup: /system.slice/cups.service └─1213 /usr/sbin/cupsd -lAug 09 17:08:40 localhost.localdomain systemd[1]: Starting CUPS Scheduler...Aug 09 17:08:41 localhost.localdomain systemd[1]: Started CUPS Scheduler.# 停止 cups 守护进程服务并查看状态[root@localhost ~]\\# systemctl stop cups.service # .service 拓展可以省略，下同[root@localhost ~]\\# systemctl is-active cups # 验证 cups 服务是否在活动inactive # 服务已停止# 启动 cups 守护进程服务并查看状态[root@localhost ~]\\# systemctl start cups[root@localhost ~]\\# systemctl status cups● cups.service - CUPS Scheduler Loaded: loaded (/usr/lib/systemd/system/cups.service; enabled; vendor preset: e&gt; Active: active (running) (thawing) since Mon 2021-08-09 19:15:01 PDT; 1min 17s &gt; Docs: man:cupsd(8) Main PID: 4284 (cupsd) Status: &quot;Scheduler is running...&quot; Tasks: 1 (limit: 23503) Memory: 1.9M CGroup: /system.slice/cups.service └─4284 /usr/sbin/cupsd -lAug 09 19:15:01 localhost.localdomain systemd[1]: Starting CUPS Scheduler...Aug 09 19:15:01 localhost.localdomain systemd[1]: Started CUPS Scheduler. 手动重启服务和重新加载服务 ​重启 = 停止 + 启动，因此重启后的服务进程 ID 会改变，并且在启动期间会关联新的进程 ID。若只是因为修改了某项支持重新加载的服务的配置文件，则可以直接重新加载该服务而无需重启该服务。 12345678910111213141516171819202122232425262728293031323334353637[root@localhost ~]\\# systemctl restart cups[root@localhost ~]\\# systemctl status cups● cups.service - CUPS Scheduler Loaded: loaded (/usr/lib/systemd/system/cups.service; enabled; vendor preset: e&gt; Active: active (running) (thawing) since Mon 2021-08-09 19:24:21 PDT; 10s ago Docs: man:cupsd(8) Main PID: 4384 (cupsd) Status: &quot;Scheduler is running...&quot; Tasks: 1 (limit: 23503) Memory: 2.0M CGroup: /system.slice/cups.service └─4384 /usr/sbin/cupsd -lAug 09 19:24:21 localhost.localdomain systemd[1]: cups.service: Succeeded.Aug 09 19:24:21 localhost.localdomain systemd[1]: Stopped CUPS Scheduler.......[root@localhost ~]\\# systemctl reload cups # cups 服务不支持重载Failed to reload cups.service: Job type reload is not applicable for unit cups.service.[root@localhost ~]\\# systemctl reload firewalld # firewalld 服务支持重载[root@localhost ~]\\# systemctl status firewalld # 最底下详情记录了重载的信息● firewalld.service - firewalld - dynamic firewall daemon Loaded: loaded (/usr/lib/systemd/system/firewalld.service; enabled; vendor preset: enabled) Active: active (running) (thawing) since Mon 2021-08-09 17:08:40 PDT; 2h 19min ago Docs: man:firewalld(1) Process: 4443 ExecReload=/bin/kill -HUP $MAINPID (code=exited, status=0/SUCCESS) Main PID: 1116 (firewalld) Tasks: 3 (limit: 23503) Memory: 35.2M CGroup: /system.slice/firewalld.service └─1116 /usr/libexec/platform-python -s /usr/sbin/firewalld --nofork --nopidAug 09 17:08:38 localhost.localdomain systemd[1]: Starting firewalld - dynamic firewall daemon...Aug 09 17:08:40 localhost.localdomain systemd[1]: Started firewalld - dynamic firewall daemon.Aug 09 17:08:41 localhost.localdomain firewalld[1116]: WARNING: AllowZoneDrifting is enabled. This is considered an insecure configuration option. It will be removed in a future release. &gt;Aug 09 19:27:17 localhost.localdomain systemd[1]: Reloading firewalld - dynamic firewall daemon.Aug 09 19:27:17 localhost.localdomain systemd[1]: Reloaded firewalld - dynamic firewall daemon.Aug 09 19:27:17 localhost.localdomain firewalld[1116]: WARNING: AllowZoneDrifting is enabled. This is considered an insecure configuration option. It will be removed in a future release. ​若不确定某服务是否具有重新加载配置文件更改的功能，则可以使用 reload-or-restart 选项来运行 systemctl 命令。如果重新加载功能可用，该命令将重新加载配置更改，否则，该命令将重新启动服务以实施新的配置更改： 123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@localhost ~]\\# systemctl status NetworkManager # 支持重载● NetworkManager.service - Network Manager Loaded: loaded (/usr/lib/systemd/system/NetworkManager.service; enabled; vendor preset: enabled) Active: active (running) (thawing) since Mon 2021-08-09 17:08:40 PDT; 2h 28min ago Docs: man:NetworkManager(8) Process: 4531 ExecReload=/usr/bin/busctl call org.freedesktop.NetworkManager /org/freedesktop/NetworkManager org.freedesktop.NetworkManager Reload u 0 (code=exited, status=0/SUCCESS) Main PID: 1190 (NetworkManager) Tasks: 3 (limit: 23503) Memory: 10.7M CGroup: /system.slice/NetworkManager.service └─1190 /usr/sbin/NetworkManager --no-daemonAug 09 19:20:04 localhost.localdomain NetworkManager[1190]: &lt;info&gt; [1628562004.4206] dhcp4 (ens160): option requested_subnet_mask =&gt; &#x27;1&#x27;Aug 09 19:20:04 localhost.localdomain NetworkManager[1190]: &lt;info&gt; [1628562004.4206] dhcp4 (ens160): option requested_time_offset =&gt; &#x27;1&#x27;Aug 09 19:20:04 localhost.localdomain NetworkManager[1190]: &lt;info&gt; [1628562004.4206] dhcp4 (ens160): option requested_wpad =&gt; &#x27;1&#x27;Aug 09 19:20:04 localhost.localdomain NetworkManager[1190]: &lt;info&gt; [1628562004.4206] dhcp4 (ens160): option routers =&gt; &#x27;192.168.30.2&#x27;Aug 09 19:20:04 localhost.localdomain NetworkManager[1190]: &lt;info&gt; [1628562004.4206] dhcp4 (ens160): option subnet_mask =&gt; &#x27;255.255.255.0&#x27;Aug 09 19:20:04 localhost.localdomain NetworkManager[1190]: &lt;info&gt; [1628562004.4206] dhcp4 (ens160): state changed bound -&gt; extendedAug 09 19:36:30 localhost.localdomain systemd[1]: Reloading Network Manager.Aug 09 19:36:30 localhost.localdomain NetworkManager[1190]: &lt;info&gt; [1628562990.2331] audit: op=&quot;reload&quot; arg=&quot;0&quot; pid=4531 uid=0 result=&quot;success&quot;Aug 09 19:36:30 localhost.localdomain NetworkManager[1190]: &lt;info&gt; [1628562990.2339] config: signal: SIGHUP (no changes from disk)Aug 09 19:36:30 localhost.localdomain systemd[1]: Reloaded Network Manager.[root@localhost ~]\\# systemctl reload-or-restart NetworkManager[root@localhost ~]\\# systemctl status NetworkManager● NetworkManager.service - Network Manager Loaded: loaded (/usr/lib/systemd/system/NetworkManager.service; enabled; vendor preset: enabled) Active: active (running) (thawing) since Mon 2021-08-09 17:08:40 PDT; 2h 28min ago Docs: man:NetworkManager(8) Process: 4547 ExecReload=/usr/bin/busctl call org.freedesktop.NetworkManager /org/freedesktop/NetworkManager org.freedesktop.NetworkManager Reload u 0 (code=exited, status=0/SUCCESS) Main PID: 1190 (NetworkManager) Tasks: 3 (limit: 23503) Memory: 10.8M CGroup: /system.slice/NetworkManager.service └─1190 /usr/sbin/NetworkManager --no-daemonAug 09 19:20:04 localhost.localdomain NetworkManager[1190]: &lt;info&gt; [1628562004.4206] dhcp4 (ens160): option subnet_mask =&gt; &#x27;255.255.255.0&#x27;Aug 09 19:20:04 localhost.localdomain NetworkManager[1190]: &lt;info&gt; [1628562004.4206] dhcp4 (ens160): state changed bound -&gt; extendedAug 09 19:36:30 localhost.localdomain systemd[1]: Reloading Network Manager.Aug 09 19:36:30 localhost.localdomain NetworkManager[1190]: &lt;info&gt; [1628562990.2331] audit: op=&quot;reload&quot; arg=&quot;0&quot; pid=4531 uid=0 result=&quot;success&quot;Aug 09 19:36:30 localhost.localdomain NetworkManager[1190]: &lt;info&gt; [1628562990.2339] config: signal: SIGHUP (no changes from disk)Aug 09 19:36:30 localhost.localdomain systemd[1]: Reloaded Network Manager.Aug 09 19:37:18 localhost.localdomain systemd[1]: Reloading Network Manager.Aug 09 19:37:19 localhost.localdomain NetworkManager[1190]: &lt;info&gt; [1628563039.0110] audit: op=&quot;reload&quot; arg=&quot;0&quot; pid=4547 uid=0 result=&quot;success&quot;Aug 09 19:37:19 localhost.localdomain NetworkManager[1190]: &lt;info&gt; [1628563039.0114] config: signal: SIGHUP (no changes from disk)Aug 09 19:37:19 localhost.localdomain systemd[1]: Reloaded Network Manager. 列出单元依赖项 ​某些服务要求首先运行其他服务，从而创建对其他服务的依赖项。其他服务并不在系统引导时启动，而是仅在需要时启动。在这两种情况下， systemd 和 systemctl 根据需要启动服务，不论是解决依赖项，还是启动不经常使用的服务。 ​使用 systemctl list-dependencies 命令可以列出指定服务的依赖项树，如： 123456789[root@localhost ~]\\# systemctl list-dependencies cups # 列出 cups 服务的依赖项cups.service● ├─cups.path● ├─cups.socket● ├─system.slice● └─sysinit.target● ├─dev-hugepages.mount● ├─dev-mqueue.mount...... 屏蔽未屏蔽的服务 ​目的：屏蔽服务可防止管理员意外启动与其他服务冲突的服务。 ​原理：在配置目录中创建指向 /dev/null 文件的链接，该文件可阻止服务启动。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[root@localhost ~]\\# systemctl mask cups # 使用 mask 选项屏蔽某服务Created symlink /etc/systemd/system/cups.service → /dev/null.[root@localhost ~]\\# systemctl status cups● cups.service Loaded: masked (Reason: Unit cups.service is masked.) Active: active (running) (thawing) since Mon 2021-08-09 19:45:56 PDT; 11min ago Main PID: 4653 (cupsd) Status: &quot;Scheduler is running...&quot; Tasks: 1 (limit: 23503) Memory: 1.9M CGroup: /system.slice/cups.service └─4653 /usr/sbin/cupsd -lAug 09 19:45:56 localhost.localdomain systemd[1]: Starting CUPS Scheduler...Aug 09 19:45:56 localhost.localdomain systemd[1]: Started CUPS Scheduler.Aug 09 19:56:23 localhost.localdomain systemd[1]: cups.service: Current command va&gt;[root@localhost ~]\\# systemctl stop cups[root@localhost ~]\\# systemctl status cups● cups.service Loaded: masked (Reason: Unit cups.service is masked.) Active: inactive (dead) (thawing) since Mon 2021-08-09 19:57:53 PDT; 3s ago Main PID: 4653 (code=exited, status=0/SUCCESS) Status: &quot;Scheduler is running...&quot;Aug 09 19:45:56 localhost.localdomain systemd[1]: Starting CUPS Scheduler...Aug 09 19:45:56 localhost.localdomain systemd[1]: Started CUPS Scheduler.Aug 09 19:56:23 localhost.localdomain systemd[1]: cups.service: Current command va&gt;Aug 09 19:57:53 localhost.localdomain systemd[1]: Stopping cups.service...Aug 09 19:57:53 localhost.localdomain systemd[1]: cups.service: Succeeded.Aug 09 19:57:53 localhost.localdomain systemd[1]: Stopped cups.service.[root@localhost ~]\\# systemctl start cupsFailed to start cups.service: Unit cups.service is masked.[root@localhost ~]\\# systemctl list-unit-files --type=service | grep maskedcups.service masked systemd-timedated.service masked [root@localhost ~]\\# systemctl unmask cups # 使用 unmask 接触对某服务的屏蔽Removed /etc/systemd/system/cups.service.[root@localhost ~]\\# systemctl start cups[root@localhost ~]\\# systemctl status cups● cups.service - CUPS Scheduler Loaded: loaded (/usr/lib/systemd/system/cups.service; enabled; vendor preset: e&gt; Active: active (running) (thawing) since Mon 2021-08-09 19:59:12 PDT; 4s ago Docs: man:cupsd(8) Main PID: 4833 (cupsd) Status: &quot;Scheduler is running...&quot; Tasks: 1 (limit: 23503) Memory: 1.9M CGroup: /system.slice/cups.service └─4833 /usr/sbin/cupsd -lAug 09 19:59:12 localhost.localdomain systemd[1]: Starting CUPS Scheduler...Aug 09 19:59:12 localhost.localdomain systemd[1]: Started CUPS Scheduler. 🟢 mask 选项并不会自动停止已经启动的服务，而且只能屏蔽对服务的启动操作。 设置某服务开启或关闭开机自启 12345678910111213141516[root@localhost ~]\\# systemctl is-enabled cups # 查看 cups 服务是否是开机自启的enabled[root@localhost ~]\\# systemctl disable cups # 关闭 cups 开机自启Removed /etc/systemd/system/multi-user.target.wants/cups.service.Removed /etc/systemd/system/multi-user.target.wants/cups.path.Removed /etc/systemd/system/sockets.target.wants/cups.socket.Removed /etc/systemd/system/printer.target.wants/cups.service.[root@localhost ~]\\# systemctl is-enabled cups # 验证disabled[root@localhost ~]\\# systemctl enable cups # 开启 cups 开机自启Created symlink /etc/systemd/system/printer.target.wants/cups.service → /usr/lib/systemd/system/cups.service.Created symlink /etc/systemd/system/multi-user.target.wants/cups.service → /usr/lib/systemd/system/cups.service.Created symlink /etc/systemd/system/sockets.target.wants/cups.socket → /usr/lib/systemd/system/cups.socket.Created symlink /etc/systemd/system/multi-user.target.wants/cups.path → /usr/lib/systemd/system/cups.path.[root@localhost ~]\\# systemctl is-enabled cups # 验证enabled ​设置开机自启某服务并不会立即启动该服务。","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"监控和管理 Linux 进程（二）","slug":"Linux | 监控和管理 Linux 进程（二）","date":"2022-08-15T02:32:03.345Z","updated":"2022-08-15T02:36:36.744Z","comments":true,"path":"2022-08-15-Linux | 监控和管理 Linux 进程（二）.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E7%9B%91%E6%8E%A7%E5%92%8C%E7%AE%A1%E7%90%86%20Linux%20%E8%BF%9B%E7%A8%8B%EF%BC%88%E4%BA%8C%EF%BC%89.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 监控进程活动 Linux 负载平均值 ​负载平均值是 Linux 内核提供的一种度量方式，它可以简单地表示一段时间内感知的系统负载。这个数值可以用来粗略衡量待处理的系统资源请求数量，并确定系统负载是随时间增加还是减少。 ​根据处于可运行和不可中断状态的进程数，内核会每五秒钟收集一次当前的负载数。通过汇总这些数值，可以得到最近一分钟、五分钟和十五分钟内的指数移动平均值。 负载数基本上是根据准备运行的进程数（进程状态为 R）和等待 I/O 完成的进程数（进程状态为 D）而得到的； 一些 UNIX 系统仅考虑 CPU 使用率或运行队列长度来指示系统负载。Linux 还包含磁盘或网络利用率，因为他们与 CPU 负载一样会对系统性能产生重大影响。遇到负载平均值很高但 CPU 活动很低时，请检查磁盘和网络活动。 ​负载平均值可粗略衡量在可以执行其他任何作业之前，有多少进程当前在等待请求完成。请求可能是用于运行进程的 CPU 时间。或者，请求可能是让关键磁盘 I/O 操作完成；在请求完成之前，即使 CPU 空闲，也不能在 CPU 上运行该进程。无论是哪种方式，都会影响系统负载；系统的运行看起来会变慢，因为有进程正在等待运行。 使用 uptime 命令查看系统当前负载平均值 12345678910uptime # 显示系统运行时长及过去 1，5，15 分钟的平均负载-p, --pretty # 只显示开机运行时长-s, --since # 只显示开机运行的时间点# 例子：[student@localhost ~]$ uptime -s2021-06-02 16:30:42[student@localhost ~]$ uptime -pup 17 minutes[student@localhost ~]$ uptime16:48:01 up 17 min, 1 user, load average: 0.13, 0.14, 0.13 使用 w 命令查看系统当前负载 1234567891011121314151617w # 查看已登录的用户及其当前活动-h, --no-header # 不要打印标题行-s, --short # 简洁模式-f, --from # 打印用户的登陆终端信息-i, --ip-addr # 在 from 列打印 IP 地址而不是主机名-u, --no-current # 当指出当前进程和 cpu 时间时忽略用户名# 例子：[student@localhost ~]$ w 16:58:40 up 27 min, 1 user, load average: 0.04, 0.03, 0.06USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATstudent tty2 tty2 16:31 27:49 49.47s 0.15s /usr/libexec/track[student@localhost ~]$ w -hstudent tty2 tty2 16:31 28:16 50.82s 0.15s /usr/libexec/track[student@localhost ~]$ w -s 16:59:27 up 28 min, 1 user, load average: 0.07, 0.04, 0.06USER TTY FROM IDLE WHATstudent tty2 tty2 28:36 /usr/libexec/tracker-miner-fs 使用 top 命令查看系统当前负载 123456789101112top # 动态列出 linux 进程[student@localhost ~]$ toptop - 17:00:39 up 29 min, 1 user, load average: 0.11, 0.07, 0.07Tasks: 329 total, 1 running, 328 sleeping, 0 stopped, 0 zombie%Cpu(s): 1.8 us, 2.5 sy, 0.0 ni, 94.3 id, 0.0 wa, 1.2 hi, 0.2 si, 0.0 stMiB Mem : 3709.4 total, 1835.5 free, 1239.4 used, 634.4 buff/cacheMiB Swap: 2048.0 total, 2048.0 free, 0.0 used. 2217.5 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 11 root 20 0 0 0 0 I 0.3 0.0 0:01.85 rcu_sched ...# 进程号 所属用户 虚拟内存 常驻内存 进程状态 CPU时间 进程命令名称 ​ top 命令常见按键操作： 按键 用途 ? or h 关于快捷键操作的帮助信息。 l、t、m 切换到负载、线程和内存标题行。 1 标题中切换显示单独 CPU 信息或所有 CPU 的汇总。 s * 更改刷新（屏幕）率，以带小数的秒数表示（如0.5、1、5）。 b 切换反向突出显示 运行中 的进程；默认为仅粗体。 shift + b 在显示中使用粗体，用于标题以及运行中的进程。 shift + h 切换线程；显示进程摘要或单独线程。 u、shift + u 过滤任何用户名称（有效、真实）。 shift + m 按照内存使用率降序排列进程列表。 shift + p 按照处理器使用率降序排列进程列表。 k * 中断进程。若有提示，输入 PID ，再输入 signal。 r * 调整进程的 nice 值。若由提示，输入 PID，再输入 nice_value。 shift + w 写入（保存）当前的显示配置，以便在下一次重新启动 top 时使用。 q 退出。 f 通过启用或禁用字段的方式来管理列。同时还允许您为 top 设置排序字段。 * 注： 如果 top 在安全模式中启动，则不可用。","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"监控和管理 Linux 进程（一）","slug":"Linux | 监控和管理 Linux 进程（一）","date":"2022-08-15T02:20:42.222Z","updated":"2022-08-15T02:29:08.419Z","comments":true,"path":"2022-08-15-Linux | 监控和管理 Linux 进程（一）.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E7%9B%91%E6%8E%A7%E5%92%8C%E7%AE%A1%E7%90%86%20Linux%20%E8%BF%9B%E7%A8%8B%EF%BC%88%E4%B8%80%EF%BC%89.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 了解 Linux 进程 什么是进程 ​进程是已启动的可执行程序的运行中实例，其由以下组成部分组成： 已分配内存的地址空间； 安全属性； 程序代码的一个或多个运行线程； 进程状态； ​进程的环境包括： 本地和全局变量； 当前调度上下文； 分配的系统资源，如文件描述符和网络端口； ​现有的（父）进程复制自己的地址空间（fork）来创建一个新的（子）进程结构。每个新进程分配有一个唯一进程 ID(PID) ，满足跟踪和安全性的需要。PID 和父进程 ID(PPID) 是新进程环境的元素。任何进程都可创建子进程。所有进程都是第一个系统进程的后代，在 RHEL8 系统上，第一个系统进程是 systemd。 ​通过fork例程，子进程继承安全性身份、过去和当前的文件描述符、端口和资源特权、环境变量，以及程序代码。随后，子进程可能 exec 其自己的程序代码。通常，父进程在子进程运行期间处于睡眠状态，设置一个在子进程完成时发出信号的请求 wait ）。在退出时，子进程已经关闭或丢弃了其资源和环境。唯一剩下的资源称为僵停，是进程表中的一个条目。父进程在子进程退出时收到信号而被唤醒，清理子条目的进程表，由此释放子进程的最后一个资源。然后，父进程继续执行自己的程序代码。 进程的状态 ​在多任务处理操作系统中，每个 CPU（或 CPU 核心）在一个时间点上处理一个进程。在进程运行时，它对 CPU 时间和资源分配的直接要求会有变化。进程分配有一个状态，它随着环境的要求而改变。 ​上图展示了 Linux 进程运行过程中的各种状态，下表是对以上状态的说明： 名称 标志 内核定义的状态名称 描述 运行 R TASK_RUNNING 进程正在 CPU 上执行，或者正在等待运行。处于运行中（或可运行）状态时，进程可能正在执行用户例程或内核例程（系统调用），或者已排队并就绪。 睡眠 S TASK_INTERRUPTIBLE 进程正在等待某一条件：硬件请求、系统资源访问或信号。当事件或信号满足该条件时，该进程将返回到运行中。 D TASK_UNINTERRUPTIBLE 此进程也在睡眠，但与 S 状态不同，不会响应信号。仅在进程中断可能会导致意外设备状态的情况下使用。 K TASK_KILLABLE 与不可中断的 D 状态相同吧，但有所修改，允许等待中的任务响应要被中断（彻底退出）的信号。实用程序通常将可中断的进程显示为 K 状态。 I TASK_REPORT_IDLE D 状态的一个子集。在计算负载平均值时，内核不会统计这些进程。用于内核线程。设置了 TASK_UNINTERRUPTABLE 和 TASK_NOLOAD 标志。类似于 TASK_KILLABLE，也是 D 状态的一个子集。它接受致命信号。 已停止 T TASK_STOPPED 进程已被停止（暂停），通常是通过用户或其他进程发出的信号。进程可以通过另一信号返回到运行中状态，继续执行（恢复）。 T TASK_TRACED 正在被调试的进程也会临时停止，并且共享同一个 T 状态标志。 僵停 Z EXIT_ZOMBIE 子进程在退出时向父进程发出信号。除进程身份（PID）之外的所有资源都已释放。 X EXIT_DEAD 当父进程清理（获取）剩余的子进程结构时，进程现在已彻底释放。此状态从不会在进程列出实用程序中看到。 ​在对系统进行故障排除时，了解内核如何与进程通信以及进程如何相互通信非常重要。在创建进程时，系统会为进程分配一个状态。top命令的 S 列或 ps 的 STAT 列显示每个进程的状态。在单 CPU 系统上，一次只能运行一个进程。可以看到多个状态为 R 的进程。然而，并非所有这些进程都在持续运行，其中一些将处于等待状态。 1234567[root@localhost ~]\\# ps auxUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.3 245648 14544 ? Ss Apr25 0:16 /usr/lib/systemd/systemd --switched-root --system --deserialize 18root 2 0.0 0.0 0 0 ? S Apr25 0:00 [kthreadd]root 3 0.0 0.0 0 0 ? I&lt; Apr25 0:00 [rcu_gp]root 4 0.0 0.0 0 0 ? I&lt; Apr25 0:00 [rcu_par_gp]...... ​可以使用信号暂停、停止、恢复、终止和中断进程，信号可以由其他进程、内核本身或登陆系统的用户使用。以下会有详细介绍。 列出进程 ​ps 命令可以用于列出当前的进程，它可以提供详细的进程信息，包括： 用户标识符（UID），它确定进程的特权； 唯一进程识别符（PID）； CPU 和已经花费的实时时间； 进程在各种位置上分配的内存数量； 进程 stdout 的位置，称为控制终端； 当前的进程状态。 🟢 常见选项组合 aux: 显示包括五控制终端的进程在内的所有进程，注意 aux != -aux； USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.3 245648 14544 ? Ss Apr25 0:16 &gt; /usr/lib/systemd/systemd --switched-root --system --deserialize 18 lax: 长列表提供更多技术详细信息，但可以通过避免查询用户名来加快显示。 F UID PID PPID PRI NI VSZ RSS WCHAN STAT TTY TIME COMMAND 4 0 1 0 20 0 245648 14544 do_epo Ss ? 0:16 &gt; /usr/lib/systemd/systemd --switched-root --system --deserialize 18 -ef: UID PID PPID C STIME TTY TIME CMD root 1 0 0 Apr25 ? 00:00:16 /usr/lib/systemd/systemd --&gt; switched-root --system --deserialize 18 没有选项：选择具有与当前用户相同的有效用户 ID(EUID) 并于调用 ps 所处统一终端关联的所有进程。 PID TTY TIME CMD 19667 pts/0 00:00:00 bash 🟢 使用 ps -ef | grep [PROC_NAME] 时注意此命令会将 grep 命令自身的进程也列出一份。 🟢 其他事项 方括号中的进程（通常位于列表顶部）为调度的内核线程； 僵停列为 exiting 或 defunct； ps 的输出仅显示一次。使用 top 来获得动态更新的进程显示； ps 可以采用树形显示格式（f 选项），以便查看父进程和子进程之间的关系，（更直观的可以使用 pstree 命令）； 默认输出按进程 ID 编号排序。 作业控制 进程组、作业、会话 ​Linux 下进程不仅有自己独一无二的 PID，还有其属于哪个进程组的标识 PGID。如果某进程的 PGID 等于其自身的 PID，那么此进程就可以被称为与它具有同一 PGID 的进程组的组长进程。当一个程序创建一个进程组时，其创建进程组的这个进程就为组长进程。程序实例的生命周期只与进程组中的最后一个进程有关。Shell 的作业控制功能控制的对象是作业或者进程组而不是进程。每个终端前台只能运行一个进程组或一个组或一个作业，而每个终端后台可以运行多个进程组和多个作业。会话是一个或多个进程组的集合。 12345[root@localhost ~]\\# ps -ajx | grep 19667 PPID PID PGID SID TTY TPGID STAT UID TIME COMMAND 19658 19667 19667 19667 pts/0 20514 Ss 0 0:00 -bash # 同一 19667 20514 20514 19667 pts/0 20514 R+ 0 0:00 ps -ajx # 同一个 个会 19667 20515 20514 19667 pts/0 20514 S+ 0 0:00 grep --color=auto 19667 # 进程组 话 ​ps 命令在 TTY 列中显示进程的控制终端的设备名称。某些进程（如系统守护进程）由系统启动，并不是从 shell 提示符启动。这些进程没有控制终端，也不是作业的成员，无法转至前台。ps 命令在 TTY 列中针对这些进程显示一个问号。 查看当前会话的作业列表 1234567jobs [-lnprs] [jobspec ...] # 显示当前会话所有（或提供 jobspec 参数指定的）作业的状态# 选项：-l, # 额外列出进程的 PID-n, # 列出最后一次通知后改变运行状态的进程-p, # 只列出进程的 PID-r, # 仅限输出正在运行的作业-s, # 仅限输出已经停止的作业 将作业放在前台执行 对于将要运行的程序：在命令行的结尾处不附加符号 &amp;，这样程序所对应的作业直接在前台下运行。 把后台作业拉到前台运行：执行命令 1fg [%]作业号 # [%] 表示 % 为可选 🟢 当在前台下运行一个作业时，shell 会被拉到后台，因为前台只能运行一个作业或者进程组。 将作业放在后台执行 对于将要运行的程序：在命令行的结尾处附加符号 &amp;。 把一个正在前台运行的程序放到后台运行：先使用 Ctrl + Z 快捷键将前台的作业放到后台，此时该后台作业是处于暂停状态的，使用以下命令将其从停止状态恢复到运行状态： 1bg [%]作业号 # [%] 表示 % 为可选 使作业在关闭终端后也能运行 1nohup COMMAND [ARG]... [&gt; FILE] # 执行命令，忽略挂起信号（一般后面追加个 &amp; 配合使用） 终止当前运行的前台任务 ​使用 Ctrl + C 快捷键。 中断进程 使用信号控制进程 ​信号是传递至进程的软件中断。信号向执行中的程序报告事件。生成信号的事件可以是错误或外部事件（I/O请求或定时器过期），或者来自于显式使用信号发送命令或键盘序列。以下是一些常见的中断信号的介绍（更详细的可参见 manpage signal(7)）： 信号编号 名称 定义 用途 1 SIGHUP 挂起 用于报告终端控制进程的终止。也用于请求进程重新初始化（重新加载配置）而不终止。 2 SIGINT 键盘中断 导致程序终止。可以被拦截或处理。通过按 INTR 键盘序列（CTRL + C）发送。 3 SIGQUIT 键盘退出 与 SIGINT 相似；在终止时添加进程转储。通过按 QUIT 键序列（CTRL + \\）发送。 9 SIGKILL 中断，无法拦截 导致立即终止程序。无法被拦截、忽略或处理；总是致命的。 15默认 SIGTERM 终止 导致程序终止。和 SIGKILL 不同，可以被拦截、忽略或处理。要求程序终止的“友好”方式；允许自我清理。 18 SIGCONT 继续 发送至进程使其恢复（若已停止）。无法被拦截。即使被处理，也始终恢复进程。 19 SIGSTOP 停止，无法拦截 暂停进程。无法被拦截或处理。 20 SIGTSTP 键盘停止 和SIGSTOP不同，可以被拦截、忽略或处理。通过按 SUSP 键序列（CTRL + Z）发送。 🟢 信号编号跟硬件平台有关，上表中的编号以 x86_64 系统为例。作为命令使用时建议使用信号名称作为参数。 向作业发送信号 12345kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... # 向作业发送信号，未指定信号的话则默认发送 SIGTERM 信号kill -l [sigspec] # 列出所有可用的中断名称或指定 sigspec 的中断号# 常见选项：-s SIG # SIG 是信号名称-n SIGNUM # SIGN 是信号编码 12killall [-s sigspec | -sigspec] NAME... # 向多个作业发送信号，未指定信号的话则默认发送 SIGTERM 信号# 该命令还有一些筛选选项，具体用到时可参见其 --help 选项的说明 12pkill [-&lt;SIG&gt; | --signal &lt;SIG&gt;] [OTHER_OPTIONS] PATTERN # 向多个作业发送信号，未指定信号的话则默认发送 SIGTERM 信号# 此命令的筛选条件更详细，且进程名都是可以使用模式匹配的 以管理员的身份注销其他用户的登陆 ​要注销某个用户，首先确定要终止的登录会话。使用 w 命令列出用户登陆和当前运行的进程。记录 TTY 和 FROM 列，以确定要关闭的会话。 12345[root@localhost ~]\\# w 11:06:17 up 1 day, 2:29, 2 users, load average: 0.00, 0.00, 0.00USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATstudent tty2 tty2 15Apr21 10days 5:04 1.20s /usr/libexec/trackroot pts/0 192.168.30.1 07:35 1.00s 0.25s 0.01s w 🟢 TTY 列：pts/N 代表图形界面终端窗口或远程登录会话相关联的伪终端；ttyN 代表用户位于一个系统控制台、替代控制台或其他直接连接的终端设备上。 ​使用 pgrep 确定要中断的 PID 编号： 12345678[root@localhost ~]\\# pgrep -l -u student # pgrep 与 pkill 命令的用法类似，作用不同2238 systemd2248 (sd-pam)2257 pulseaudio2263 gnome-keyring-d......[root@localhost ~]\\# pkill -SIGKILL -u student # 杀死 student 用户的所有进程[root@localhost ~]\\# pgrep -l -u student 🟢 通常建议不要直接使用 SIGKILL 杀死进程，而是在尝试 SIGTERM 和 SIGINT 不起作用之后使用。","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"Linux 文件系统权限","slug":"Linux | Linux 文件系统权限","date":"2022-08-15T02:17:38.330Z","updated":"2022-08-15T02:19:32.512Z","comments":true,"path":"2022-08-15-Linux | Linux 文件系统权限.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20Linux%20%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%9D%83%E9%99%90.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 Linux 文件权限类别 ​对于一个 linux 系统上的一般文件，其访问权限的具体内容如下： 例子 用户类别 具体权限 sample.sh u: 该文件的属主，通常是创建者 r: 读取权限，可以读取文件内容 w: 修改权限，可以更改文件内容 x: 执行权限，可以做为可执行文件执行 g: 该文件属主所处的主要组 r: 读取权限，可以读取文件内容 w: 修改权限，可以更改文件内容 x: 执行权限，可以做为可执行文件执行 o: 其他用户以及他们的用户组 r: 读取权限，可以读取文件内容 w: 修改权限，可以更改文件内容 x: 执行权限，可以做为可执行文件执行 ​对于目录文件，其权限标识的具体内容如下： 权限 作用 r: 读取权限 可以列出目录的内容 w: 写入权限 可以创建或删除目录中的任一文件 x: 执行权限 该目录可以成为当前工作目录（可以 ch 到），但要读取权限才能查看该目录下的文件 修改 Linux 文件权限 使用 chmod 命令修改文件权限 12345678chmod [OPTION]... MODE[,MODE]... FILE... # 以符号形式修改权限chmod [OPTION]... OCTAL-MODE FILE... # 以数字形式修改权限chmod [OPTION]... --reference=RFILE FILE... # 将文件的权限修改的和 RFILE 一样# 常见选项：-R, --recursive # 递归修改目录和文件-v, --verbose # 为每个处理的文件输出诊断信息-c, --changes # 类似 -v 选项，但是仅在文件更改成功时报告-f, --silent, --quiet # 忽略大多数错误信息 符号法 ​可以使用 u、g、o、a 字母分别代表文件属主、属主所在组、其他用户及组、所有用户及组，对应的动作 +、-、= 分别代表添加、删除、精确设置，r、w、x 代表所要设置的权限，设置多个用户类别时用逗号隔开，即如下面的例子所示： 1chmod u+wx,o-rx executable.sh # 属主增加写入和执行权限，其他用户删除读和执行权限 数字法 ​让 r、w、x 权限分别对应数字 4、2、1，由这三个数字任意组合相加得到一个 0-7 的结果，将这个结果从左到右三位分别代表 u、g、o 对应的权限再组合为一个三位数（最高位可以为零），此方法适用于精确设置文件的权限，即如下面的例子所示： 1chmod 777 executable.sh # 将此文件设置为所有用户可读写、执行。 ​第三种形式较易理解，不再赘述。 使用 chown 修改文件所属用户或组 ​只有 root 用户可以更改文件的所属用户，文件所有者和 root 可以更改文件的所属用户（前者只能改到自己在的组里，后者任意）。 1234567chown [OPTION]... [OWNER][:[GROUP] FILE... # 修改文件所属用户和组chown [OPTION]... --reference=RFILE FILE... # 参照 RFILE 修改文件所属用户和组# 常见选项：-R, --recursive # 递归修改目录和文件-v, --verbose # 为每个处理的文件输出诊断信息-c, --changes # 类似 -v 选项，但是仅在文件更改成功时报告-f, --silent, --quiet # 忽略大多数错误信息 123chown -R student:student /opt/dir/ # 将 /opt/dir 目录的所有者和组改为 student 和 student 组chown :wheel /opt/file # 作用等同于下条命令chgrp wheel /opt/file # 将 /opt/file 文件的所有组改为 wheel 组 特殊权限 特殊权限 对文件的影响 对目录的影响 u+s(suid) 以拥有文件的用户身份，而不是以运行文件的身份执行文件 无影响 g+s(sgid) 以拥有该文件的组身份执行文件 在目录中最新创建的文件将其组所有者设置为与目录的组所有者相匹配 o+t(stiky) 无影响 对目录具有写入访问权限的用户仅可以删除其所拥有的文件，而无法删除或强制保存到其他用户所拥有的文件 ​示例： 12345678[root@localhost ~]\\# ll /usr/bin/passwd-rwsr-xr-x. 1 root root 33544 Dec 14 2019 /usr/bin/passwd # u.x-&gt;s[root@localhost ~]\\# ll -d /run/log/journaldrwxr-sr-x. 3 root systemd-journal 60 Apr 15 16:47 /run/log/journal # g.x-&gt;s[root@localhost ~]\\# ll /usr/bin/locate-rwx--s--x. 1 root slocate 47128 Aug 12 2018 /usr/bin/locate # g.x-&gt;s[root@localhost ~]\\# ll -d /tmp drwxrwxrwt. 22 root root 4096 Apr 23 20:10 /tmp # o.x-&gt;t 设置特殊权限的方法 符号法：u+s、g+s、o+t； 数值法：在原来三位的基础上在左边增加一位：setuid=4、setgid=2、sticky=1； 创建的新文件的默认权限 ​两个因素影响创建的新文件（含目录）的初始权限：一是文件的类型（常规文件还是目录），二是当前的 umask。对于因素一，若是创建的新目录，操作系统默认首先为其分配八进制权限 0777（drwxrwxrwx）；如果是常规文件，操作系统默认首先为其分配八进制权限 0666（-rw-rw-rw-），因此可执行文件创建后需手动赋予执行权限才能够被执行。对于因素二，shell 内置了 umask 机制来进一步限制创建的新文件的权限，使用不带参数的 umask 可以查看当前 shell 设置的 umask 值，其内容为一个八进制位掩码，每位的数字代表从当前用户的默认设置中删掉某种权限： 12[root@localhost ~]\\# umask0022 # 代表 go-w，即在默认的基础上去掉同组用户和其它用户的写入权限 1234umask [-p] [-S] [MODE] # 显示或设置文件模式掩码# 常见选项：-p, # 输出的具体掩码前面加上 umask，即可以作为命令输入复用-S, # 使用符号模式 ​使用 umask 可以临时更改当前 shell 创建文件时的掩码，想永久更改需在 bashrc 和 profile 文件中覆盖。","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"管理本地用户和组（二）","slug":"Linux | 管理本地用户和组（二）","date":"2022-08-15T02:07:41.170Z","updated":"2022-08-15T02:16:26.482Z","comments":true,"path":"2022-08-15-Linux | 管理本地用户和组（二）.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E7%AE%A1%E7%90%86%E6%9C%AC%E5%9C%B0%E7%94%A8%E6%88%B7%E5%92%8C%E7%BB%84%EF%BC%88%E4%BA%8C%EF%BC%89.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 管理本地用户账户 使用 useradd 命令创建新用户 ​添加用户所使用的默认配置保存在 /etc/default/useradd 中，同时还有一些默认配置从 /etc/login.defs 文件中读取。这两个文件只会影响新创建的用户，更改这两个文件不会影响现有用户。没有设置密码的用户是无法登陆系统的。 1234567891011121314151617useradd [OPTION]... LOGIN_NAME # 新建登陆用户useradd -D [-befgs] # 查看或修改创建用户使用的默认设置，# 常见选项-b, --base-dir BASE_DIR # 指定创建用户家目录的基目录（一般为 /home ）-u, --uid UID # 为新账户指定 UID-c, --comment COMMENT # 指定新用户描述信息或真实姓名-d, --home-dir HOME_DIR # 指定新用户的家目录，默认 $BASE_DIR/LOGIN_NAME-D, --difaults # 打印或改变默认的 useradd 配置-g, --gid GROUP # 指定新账户的主要组的 ID 或名字-G, --groups GROUPS # 指定新账户的补充组-m, --create-home # 创建用户的家目录（指定该字段或 CREATE_HOME 配置项为 yes 才会创建）-M, --no-create-home # 不创建用户的家目录，即使 /etc/login.defs 中的 CREATE_HOME 字段的值为 yes-U, --user-group # 为用户创建与用户同名的用户组-N, --no-user-group # 不创建与用户同名的用户组-p, --password PASSWORD # 为该新账户设置加密的密码（不推荐）-r, --system # 创建系统账户-s, --shell SHELL # 为新账户指定登陆 shell 12345678910[root@localhost ~]\\# useradd -D # 添加用户所使用的默认配置GROUP=100HOME=/homeINACTIVE=-1EXPIRE=SHELL=/bin/bashSKEL=/etc/skelCREATE_MAIL_SPOOL=yes[root@localhost ~]\\# getent group 100 # 查询 GID 100 对应的 group 信息users:x:100: # 添加的新用户会默认将其主要组设置为 users 组 ​以上示例中使用了 getent 命令，在本章结尾对这个命令会有更详细的介绍。 使用 usermod 命令修改现有用户 123456789usermod [OPTION]... LOGIN_NAME # 修改用户账户# 以下 useradd 中的选项也适用于 usermod，只不过行为变成了更改而不是创建，将不再赘述：-u, -d, -g, -G, -c, -s, -p# 其余常见选项：-a, --append # 与 -G 搭配，追加加入补充组模式（-G 默认是替换）-l, --login NEW_LOGIN # 修改用户名-L, --lock # 锁定账户-U, --unlock # 解锁账户-m, --move-home # 与 -d 搭配，立即移动到新的家目录 使用 userdel 命令删除现有用户 1234userdel [OPTION]... LOGIN_NAME # 删除用户账户（默认不删除此用户的文件，创建的新用户如果使用了之前被删的用户的 uid 则新用户会默认获得旧用户文件的所属权）# 常见选项：-f, --force # 强制删除普通删除会失败的账户（如：删除有人登陆的账户）-r, --remove # 同时删除该用户家目录和邮箱目录（推荐） 使用 passwd 命令设置用户初始密码或更改现有的密码 12345678910passwd [-k] [-l] [-u] [-e] [-d] [-S] [--stdin] [username]# 常见选项：-k, --keep-tokens # 继续使用旧密码，重新计算过期时间-l, --lock # 仅 root 可用，锁定指定账户的密码（但账户没有被锁，其他方式仍能登陆）-u, --unlock # 仅 root 可用，解锁指定账户的密码-d, --delete # 仅 root 可用，删除某个账户的密码-e, --expire # 仅 root 可用，强制某个用户下次登陆时修改密码-S, --status # 输出账户的账户密码状态信息--stdin, # 从标准输入中读取密码（常与管道配合）# 不使用任何选项时可省略 username, 默认修改当前登陆账户的用户密码 管理本地组账户 使用 groupadd 命令添加用户组 12345groupadd [OPTIONS] GROUP # 创建新用户组# 常见选项：-g, --gid GID # 指定 GID-K, --key KEY=VALUE # 覆盖 /etc/login.defs 中的默认值，可以指定多个 -K 选项-r, --system # 创建系统组 使用 groupmod 命令修改用户组 1234groupmod [OPTIONS] GROUP # 修改系统中的用户组的定义# 常见选项：-g, --gid GID # 改变组 ID-n, --new-name NEW_GROUP # 修改组名 使用 groupdel 命令删除用户组 1groupdel [OPTIONS] GROUP # 删除用户组 管理用户密码 ​用户密码存放文件 /etc/shadow 的格式： ​ 用户名:加密后的密码[^1]:上次更改密码的日期:从上次更改密码到下一次可以更改所必须经过的最短天数:在密码过期之前不进行密码更改可以经过的最长天数[^2]:警告期[^3]:非活动期[^4]:密码过期日[^5]:预留字段 [^1]: 加密密码字符串的不同部分由美元符号 $ 隔开，第一个 $ 后的数字代表此密码所用的哈希算法，数字 6 代表使用的是 SHA-512 哈希算法（红帽 8 默认算法），1 代表 MD5 哈希算法，5 代表 SHA-256 哈希算法。第二个 $ 后面的是加密密码使用的盐值。第三个 $ 后面的是用户密码的加密哈希值，前面盐值和用户未加密密码进行组合加密生成的密码哈希串。 [^2]: 空字段表示它不会根据上次更改以来的时间失效。 [^3]: 当用户在截止日前之前登陆达到该天数时，会收到有关密码过期的警告。 [^4]: 一旦密码过期，这些天内仍可以接受登陆，过了这一时期之后，账户将被锁定。 [^5]: 其设置值为从 1970 年 1 月 1 日起的天数，并按 UTC 时区计算。空字段表示它不会在特定的日期失效。 ​当用户尝试登陆时，系统会从 /etc/shadow 中查询用户的密码条目，并将用户的盐值和键入的未加密密码组合，再使用指定的哈希算法加密。如果结果与已加密哈希匹配，则用户输入了正确的密码，即会登陆成功，否则表示用户输入了错误的密码，登陆尝试也会失败。 ​下图展示了相关密码期限参数及其周期作用。 使用 chage 命令修改用户密码过期设置 123456789chage [OPTIONS] LOGIN_NAME # 修改用户密码过期信息# 常见选项：-d, --lastday LAST_DAY # 修改最后一次更改密码的时间，可以设置为从 1970 年 1 月 1 日起度过的天数，也可以以 YYYY-MM-DD 的形式进行设置，如果设置为 0 的话，则该用户在下次登陆时会被强制要求更改密码-E, --expiredate EXPIRE_DATE # 修改密码强制过期时间，过期将无法登陆，只能由 root 解锁后才能继续使用，可以设置为 1970 年 1 月 1 日起度过的天数，也可以以 YYYY-MM-DD 的形式进行设置，设置为 -1 密码将永不过期-I, --inactive INACTIVE # 设置宽限期（天数，即密码已过期到用户账户被锁这段时间）,设置为 -1 则没有宽限期-l, --list # 显示账户密码的重要时间段-m, --mindays MIN_DAYS # 设置两次更改密码的最小间隔（天数），设置为 0 代表没有限制-M, --maxdays MAX_DAYS # 设置密码可用的最大天数，超过时间即会过期，设置为 -1 会移除密码过期限制-W, --warndays WARN_DAYS # 设置密码到期前发出改密警告的天数 ​如果没有指定选项，则 chage 会进入交互式操作模式。 GETENT 命令介绍 ​使用 getent 命令来查看系统的数据库中的相关记录。 语法 12345getent database [key ...] # Get entries from administrative database.-s, --service=CONFIG # 要使用的服务配置-?, --help # 给出该系统求助列表 --usage # 给出简要的用法信息-V, --version # 打印程序版本号 支持的系统数据库 ​包含：ahosts、ahostsv4、ahostsv6、alias、ethers、group、gshadow、hosts、netgroup、networks、passwd、protocols、rpc、services、shadow。 示例 1234567891011# 1. 查看前三项系统注册的服务及其占用的端口和协议[root@vmrhelskinyi ~]\\# getent services | head -3tcpmux 1/tcptcpmux 1/udprje 5/tcp# 2. 根据当前登陆信息查找 UID[root@vmrhelskinyi ~]\\# getent passwd `whoami`root:x:0:0:root:/root:/bin/bash# 3. 进行 DNS 反查[root@vmrhelskinyi ~]\\# getent hosts kernel.org198.145.29.83 kernel.org","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"管理本地用户和组（一）","slug":"Linux | 管理本地用户和组（一）","date":"2022-08-15T02:00:28.205Z","updated":"2022-08-15T02:07:01.313Z","comments":true,"path":"2022-08-15-Linux | 管理本地用户和组（一）.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E7%AE%A1%E7%90%86%E6%9C%AC%E5%9C%B0%E7%94%A8%E6%88%B7%E5%92%8C%E7%BB%84%EF%BC%88%E4%B8%80%EF%BC%89.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 用户和组的概念 什么是用户 用户账户用于在可以运行命令的不同人员和程序之间提供安全界限。 ​用户使用用户名向人类用户标识自己并增加操作的便利性。在内部，系统通过分配的唯一标识号用户ID或UID）来区分不同的用户帐户。人类使用用户帐户时，通常会为其分配一个密码，供用户用于在登录时证明他们是实际的授权用户。 用户帐户构成了系统安全的基础。系统中的每个进程（运行程序）都作为一个特定用户运行。每个文件都有一个特定用户作为其所有者。文件所有权有助于系统对文件用户实施访问控制。与运行进程相关联的用户可确定该进程可访问的文件和目录。 ​用户帐户有三种主要类型：超级用户、系统用户和普通用户。 超级用户帐户用于管理系统。超级用户的名称为 root，其帐户 UID 为 0。超级用户对系统具有完全访问权限。 系统用户帐户供提供支持服务进程使用。这些进程（或守护进程）通常不需要以超级用户身份运行。系统会为它们分配非特权帐户，允许它们确保其文件和其他资源不受彼此以及系统上普通用户的影响。用户无法使用系统用户帐户以交互方式登录。 普通用户是大多数用户都有用于处理日常工作的帐户。与系统用户一样，普通用户对系统具有有限的访问权限。。 ​可以使用 id 命令显示有关当前已登陆用户的信息。 123456789id [OPTION]... [USER] # 打印真实有效的用户和其组 ID，忽略 USER 时打印当前用户的用户和其组信息# 常见选项（下面四个只能四选一）：-g, --group # 只打印有效的组 ID-G, --groups # 打印所有的组 ID-u, --user # 只打印有效的用户 ID-Z, --context # 只打印进程安全上下文## 用于 -g、-G、-u 之后的：-n, --name # 打印名字而不是用户 ID-r, --real # 打印真实 ID 而不是有效 ID 1234[root@localhost ~]\\# iduid=0(root) gid=0(root) groups=0(root) context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 # 安全上下文[root@localhost ~]\\# id -ur student1000 # 只打印 student 用户的用户ID ​存储用户信息的配置文件为 /etc/passwd 文件，它的格式为： ​ ​用户名:加密的用户密码[^1]:用户UID:用户主要组的GID:用户真实姓名:用户主目录:用户的默认登陆shell[^2] [^1]: 已弃用，现在该字段始终应为 x，密码配置已经移到了 /etc/shadow 配置文件。 [^2]: 对于普通用户一般来说是 /bin/bash，某些服务的系统用户一般不允许进行交互式登陆，其可能会使用：/sbin/nologin。 ​例子： 12[root@localhost ~]\\# head -n 1 /etc/passwdroot:x:0:0:root:/root:/bin/bash 红帽 UID 范围划分 UID 范围 账户范围 0 root 1-200 系统用户，红帽静态分配给一些系统进程 201-999 系统用户，供文件系统中没有自己的文件的系统进程使用。一般是一些后续安装的系统服务，由红帽动态分配，用来限制这些服务仅访问它们正常运行所需的资源。 1000+ 普通用户 什么是组 ​组是需要共享文件和其他系统资源访问权限的用户的集合。组可用于向一组用户授予文件访问权限，而非仅仅向一个用户授予访问权限。 ​与用户相似，组也有组名称以增加操作的便利性。在內部，系统通过分配的唯一标识号（组ID或GID）来区分不同的组。 ​存储用户组信息的配置文件为 /etc/group 文件，它的格式为： ​ 组名称:组密码[^3]:该组的GID号:组成员列表（以逗号作为分界符） [^3]: 已弃用，该字段始终应为 x。组密码配置文件已移至 /etc/gshadow。 主要组和补充组 ​每个用户有且只有一个主要组。对于本地用户而言，这是按 /etc/passwd 文件中的 GID 号列出的组。默认情况下，这是拥有用户创建的新文件的组。 ​通常，在创建新的普通用户时，会创建一个与该用户同名的新组。该组将用作新用户的主要组，而该用户是这一用户专用组的唯一成员。事实证明，这有助于简化文件权限的管理。 ​用户也可以有补充组。补充组的成员资格由 /etc/group 文件确定。根据所在的组是否具有访问权限，将授予用户对文件的访问权限。具有访问权限的组是用户的主要组还是补充组无关紧要。 ​例如，如果用户 user 有一个主要组 user 以及两个补充组 wheel 和 webadmin，那么该用户就可以读取其中任何一个组可读的文件。 ​查询用户主要组及其组 GID 也可以使用 id 命令，具体用法详见上面对 id 命令的介绍。 使用超级用户权限 超级用户 ​大多数操作系统具有某种类型的超级用户，即具有系统全部权限的用户。在 RHEL 中，此为 root 用户。该用户的特权高于文件系统上的一般特权，用于管理系统。要执行诸如安装或删除软件以及管理系统文件和目录等任务，必须将特权升级到root用户。 ​普通用户能控制大部分的设备，但也有一些例外，只有此时才需要 root 用户。例如，普通用户可以控制可移动设备，如 USB 设备。因此，虽然普通用户可以添加和删除文件并可管理可移动的设备，但默认情况下，只有 root 用户才能管理“固定的”硬盘。 ​root 用户这种无限制的特权也带来了职责问题。root 用户拥有足以破坏系统的无限制权限：删除文件和目录、删除用户帐户，以及添加后门等。如果 root 帐户泄露，则其他人就有可能拥有系统的管理控制权限。在一般的系统使用场景下，建议管理员以普通用户身份登录，仅在需要时升级到 root 用户特权。 ​Linux 上的 root 帐户大致相当于 Microsoft Windows 上的本地 Administrator 帐户。在 Linux 中，多数系统管理员都作为无特权的用户登录，然后使用各种工具临时获得 root 特权。 2. 使用 su 命令进行用户切换 12345su [OPTIONS] [-] [USER [ARG...]] # 使用替换的用户和组运行命令# 常见选项：-c, --command=COMMAND # 切换用户过去执行命令（慎用别名），执行完毕后切回原来的用户-g, --group=GROUP # 指定主要组，仅适用于 root-, -l, --login # 切换用户时，使环境变量(HOME，SHELL，USER，LOGNAME，PATH等）和欲切换的用户相同、不使用则取得用户的临时权限，不加载环境变量 1234[root@localhost ~]\\# su --login student -c &quot;ls -l&quot;total 0[root@localhost ~]\\# su - student[student@localhost ~]\\$ ​使用 exit 或 logout 命令可以从临时切换过去的用户切换回原来的用户。 3. 使用 sudo 命令利用超级用户特权执行命令 ​有时为了安全起见，root 用户的账户可能没有设置有效的密码。在这种情况下无法正常通过密码验证以 root 用户登陆，也不能通过使用 su 获取交互式 shell，而为了使用 root 特权，则可以使用 sudo 命令来临时获得 root 特权执行命令，这个过程也需要进行密码验证，不过是需要输入当前用户自己的密码。 ​普通用户能执行 root 特权命令的前提是该普通为系统管理员用户，即其已经在 /etc/sudoers 中，并且已经被配置了些许可以以 root 权限运行的命令。普通用户如果没被允许执行特权命令，其使用 sudo 执行命令会被拒绝，且会被记录下来向 root 用户报告。 ​使用 visudo 命令可以编辑 /etc/sudoers 配置文件，进行 root 权限下放的配置，RHEL7 之后 wheel 组成员默认被授予了超级用户的一些权限，它们可以使用 sudo 执行一些 root 特权命令。 🟢 建议在 /etc/sudoers.d 目录下补充自己的 sudo 权限访问权限而不是修改 /etc/sudoers。 ​为用户配置权限的一般形式为：用户名或%组名 ALL=(ALL) [NOPASSWD:]ALL，其中 NOPASSWD: 会允许当前用户或组不用输入用户自己的密码直接运行特权命令，比较危险。 ​管理员用户使用 root 特权执行命令的内容会被记录到 /var/log/secure 日志中去： 1234[student@localhost ~]\\$ sudo tail -n 0 -f /var/log/secureApr 17 12:27:16 localhost sudo[9240]: student : TTY=pts/2 ; PWD=/home/student ; USER=root ; COMMAND=/bin/tail -n 0 -f /var/log/secureApr 17 12:27:16 localhost sudo[9240]: pam_systemd(sudo:session): Cannot create session: Already running in a session or user sliceApr 17 12:27:16 localhost sudo[9240]: pam_unix(sudo:session): session opened for user root by root(uid=0) ​特殊地，管理员用户可以通过以下两种方式切换到 root，这两种方式的行为不完全相同： 123456[student@localhost ~]\\$ sudo su - # 推荐[sudo] password for student: [root@localhost ~]\\# [student@localhost ~]\\$ sudo -i # 虽切换到了 root 但使用的环境与上方方法有差异[sudo] password for student: [root@localhost ~]\\#","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"Shell 变量与环境变量","slug":"Linux | Shell 变量与环境变量","date":"2022-08-15T01:53:16.429Z","updated":"2022-08-15T01:57:20.126Z","comments":true,"path":"2022-08-15-Linux | Shell 变量与环境变量.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20Shell%20%E5%8F%98%E9%87%8F%E4%B8%8E%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 Shell 变量 使用 Shell 变量 ​Shell 变量可以帮助运行命令或修改 shell 的行为，shell 变量也可以被导出为环境变量，它会在程序启动时自动复制到从该 shell 运行的程序中。 ​Shell 变量对于特定 shell 会话是唯一的，每个 shell 都有自己的一组 shell 变量值。 使用 echo 命令输出一行文本内容 12345echo [SHORT_OPTION]... string...# 常见参数：-n, # 不要输出跟随的换行符-e, # 解释转义字符-E, # 不解释转义字符（默认） ​Shell 变量名称可以包含大写或小写字母、数字和下划线字符_。用美元符号 $ 可以读取设置的 shell 变量的值。如下例所示： 12345[root@localhost ~]\\# count=250 # 设置变量，注意等号左右别加多余的空格字符[root@localhost ~]\\# echo count # 不加 $ 符号只会将原文当文本输出count[root@localhost ~]\\# echo $count # 加上 $ 符号会将 count 视作变量，且此命令也会输出其值250 使用花括号来保护变量 1234[root@localhost ~]\\# echo something $countx # 找不到变量不会导致错误，而是不返回任何内容something[root@localhost ~]\\# echo something $&#123;count&#125;xsomething 250x 使用 set 命令列出当前设置的所有 Shell 变量 ​set 命令由于打印当前终端设置的所有 shell 变量和 shell 函数。 123456[root@localhost ~]\\# set | moreBASH=/bin/bashBASHOPTS=checkwinsize:cmdhist:complete_fullquote:expand_aliases:extglob:extquote:force_fignore:histappend:interactive_comments:login_shell:progcomp:promptvars:sourcepath# 省略大部分输出 使用 Shell 变量配置 Bash ​一些 shell 变量在 bash 启动时设置，但可以进行修改来调整 shell 的行为。如：$PATH、$PS1、$HISSIZE 等。 环境变量 ​Shell 提供了一个环境包括有关文件系统上当前工作目录的信息、传递给程序的命令行选项，以及环境变量的值。程序可以使用这些环境变量来更改其行为或其默认设置。 ​不是环境变量的 shell 变量只能由 shell 使用，环境变量可以由 shell 以及从该 shell 启动的程序使用。 设置环境变量 123456[root@localhost ~]\\# RHEL_VERSION=8.3 # 创建 shell 变量[root@localhost ~]\\# export RHEL_VERSION # 将其导出为环境变量[root@localhost ~]\\# export RHEL_VERSION= # 在一行中完成上面两步[root@localhost ~]\\# echo $RHEL_VERSION # 输出环境变量的内容[root@localhost ~]\\# 使用 env 命令列出 shell 的所有环境变量 ​env 修改环境变量并运行程序。使用 export -p 也可以打印所有的 shell 变量，不过每条输出前面都会加上：&quot;declare -x &quot;。 123456789101112env [OPTION]... [-] [NAME=VALUE]... [COMMAND [ARG]...] # 修改环境变量并运行程序# 常见选项：-i, --ignore-environment # 使用空的环境运行程序-0, --null # 使用空字符结束输出，而不是换行符-u, --unset=NAME # 从环境中移除环境变量 NAME-c, --chdir=DIR # 修改工作目录到 DIR-S, --split-string=S # 将 S 拆分为多个参数，用来传递多个参数# -S 在脚本中的使用举例，如想执行 1.pl 这个 perl 脚本,其第一行的写法为：#!/user/bin/env -S perl -w -T # 将会执行 perl -w -T 1.pl# 没有 -S 的话则会提示：/usr/bin/env: &#x27;perl -w -T&#x27;：No such file or directory 12345678[root@localhost ~]\\# env # env 不加参数则会列出所有设置的环境变量# 省略部分输出RHEL_VERSION=SSH_TTY=/dev/pts/1MAIL=/var/spool/mail/rootTERM=xtermSHELL=/bin/bash# 省略部分输出 保存环境变量以长期使用 ​如果要修改整个系统的环境变量，则建议在 /etc/profile.d 目录下添加自己的 .sh 结尾的文件（需要 root 权限），如果只是希望修改自己用户的环境变量，则修改自己的 ~/.bashrc 文件。 取消设置变量与取消导出环境变量 ​使用 export -n 命令取消导出的环境变量（但其还是 shell 变量）： 1234567[root@localhost ~]\\# export RHEL_VERSION=8.3[root@localhost ~]\\# env | grep RHELRHEL_VERSION=8.3[root@localhost ~]\\# export -n RHEL_VERSION[root@localhost ~]\\# env | grep RHEL[root@localhost ~]\\# echo $RHEL_VERSION8.3 ​使用 unset 命令取消设置变量以及环境变量： 12345678[root@localhost ~]\\# export RHEL_VERSION[root@localhost ~]\\# env | grep RHELRHEL_VERSION=8.3[root@localhost ~]\\# unset RHEL_VERSION[root@localhost ~]\\# env | grep RHEL[root@localhost ~]\\# echo $RHEL_VERSION[root@localhost ~]\\#","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"查阅 Linux 系统手册与 Vim 的使用","slug":"Linux | 查阅 Linux 系统手册与 vim 的使用","date":"2022-08-15T00:57:36.250Z","updated":"2022-08-15T01:00:44.943Z","comments":true,"path":"2022-08-15-Linux | 查阅 Linux 系统手册与 vim 的使用.html","link":"","permalink":"https://skinyi.github.io/2022-08-15-Linux%20|%20%E6%9F%A5%E9%98%85%20Linux%20%E7%B3%BB%E7%BB%9F%E6%89%8B%E5%86%8C%E4%B8%8E%20vim%20%E7%9A%84%E4%BD%BF%E7%94%A8.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 Linux 操作手册 ​Linux 本地系统提供的一个 linux 操作文档是系统手册，或称为 man page，可以通过 man 命令从命令行进行访问查询。man page 源自过去的 Linux 程序员手册，该手册篇幅很长，足以打印成多个章节，每个章节中都包含了有关特定主题的信息。以下列举了一些常见的章节。 章节 内容类型 1 用户命令（可执行命令和 shell 程序） 2 系统调用（从用户空间调用的内核例程） 3 库函数（由程序库提供） 4 特殊文件（如设备文件） 5 文件格式（用于许多配置文件和结构） 6 游戏（过去的有趣程序章节） 7 惯例、标准和其他（协议、文件系统） 8 系统管理和特权命令（维护任务） 9 Linux 内核 API（内核调用） ​为区分不同章节中的相同主题名称，man page 参考中在主题后附上了章节编号（用括号括起）：如 passwd(1) 介绍使用 passwd 命令更改用户密码，而 passwd(5) 说明用于存储本地用户账户的 /etc/passwd 配置文件格式。 1234man [THEME_NUM] TOPIC # 使用 man 命令查阅 TOPIC 的相关文档，不指定 THEME_NUM 则默认为 1# 例子：man passwd # 查看 passwd 命令的帮助信息man 5 passwd # 查看 passwd 配置文件的介绍信息 阅读文档相关 导航与搜索 ​man page 底层使用 less 作为其查看器，具体的导航与查找的操作信息可参见 04. Linux 文件操作、重定向和管道 中与 less 命令有关的相关章节。 小标题 ​man page 每个主题都划分为几个部分，每个部分都有固定的小标题，大多数主题都共享相同的小标题，且这些小标题出现的循序都是约定俗成的。每个主题下不可能包含所有的小标题，因为有些小标题不适用于当前主题。以下列举了一些常见的小标题： 标题 描述 NAME 主题名称，通常是命令或文件名，后跟非常简短的描述 SYNOPSIS 命令语法的概要 DESCRIPTION 提供对主题的基本理解的深度描述 OPTIONS 对命令执行选项的说明 EXAMPLES 有关如何使用命令、功能或文件的示例 FILES 与 man page 相关的文件和目录的列表 SEE ALSO 相关的信息，通常是其他 man page 的主题 BUGS 软件中的已知错误 AUTHOR 有关参与编写该主题的人员的信息 根据关键字搜索 man page 12345man -k keyword # 在 manpage 中搜索跟 keyword 有关的 man page 主题和章节号# 需更新 whatis 库后才能使用，否则提示：[KEYWORD]: nothting appropriate# 通过 root 使用 makewhatis 指令来手动建立资料库 apropos 与 man -k 相同， whatis 与 man -f 相同。# 好吧，我系统上也没装 makewhatis ，知道就行算了😒 pinfo 操作手册 ​通常而言，man page 文档更加正式，其采用独立文本文件的结构，pinfo 文档更加全面和灵活，采用超文本文档的结构。 1pinfo [TOPIC] # 打开关于 TOPIC 的 info 文档，不指定 TOPIC 则打开顶级目录 如果系统中没有针对该主题的 info 条目，则 pinfo 就会去查找 man page 并显示相应的内容。 ​pinfo 和 man 命令的键盘导航操作的区别如下： 导航操作 pinfo man 向前（下）滚动一个屏幕 PgDn 或 SPACE PgDn 或 SPACE 向后（上）滚动一个屏幕 PgUp 或 b PgUp 或 b 显示主题目录 d 无 向前（下）滚动半个屏幕 无 d 显示主题的父节点 u 无 显示主题的顶部（上部） h g 向后（上）滚动半个屏幕 - u 向前（下）滚动到下一个超链接 ↓ 无 打开光标处的主题 ENTER 无 向前（下）滚动一行 无 ↓ 或 ENTER 向后（上）滚动到上一超链接 ↑ 无 向后（上）滚动一行 无 ↑ 搜索某种模式 /string /sting 和 ?string 显示主题中的下一节点（章节） n 无 重复之前的向前（下）搜索 / + ENTER n 显示主题中的上一节点（章节） p 无 重复之前的向后（上）搜索 无 SHIFT + n 退出程序 q q Vim Cheat Sheet ​中文版 Cheat Sheet 可以参阅这里。","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"Linux 文件与目录管理","slug":"Linux | Linux 文件与目录管理","date":"2022-08-13T00:52:07.799Z","updated":"2022-08-15T01:05:53.722Z","comments":true,"path":"2022-08-13-Linux | Linux 文件与目录管理.html","link":"","permalink":"https://skinyi.github.io/2022-08-13-Linux%20|%20Linux%20%E6%96%87%E4%BB%B6%E4%B8%8E%E7%9B%AE%E5%BD%95%E7%AE%A1%E7%90%86.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 文件目录操作 使用 mkdir 创建目录 12345mkdir [OPTION]... DIRECTORY... # 如果不存在则创建目录# 常见可选选项-m, --mode=MODE # 设置文件读写执行权限（跟 chmod 以数字设置文件权限的方法一样）-v, --verbose # 打印创建的每一个目录的信息-p, --parents # 递归创建每层目录，即如果父目录不存在则创建好父目录后再创建自己 使用 rmdir 删除空的目录 12345rmdir [OPTION]... DIRECTORY... # 要删除的目录必须为空# 常见选项-p, --parents # 递归删除-v, --verbose # 打印程序执行过程--ignore-fail-on-non-empty # 忽略目录非空错误 使用 cd 切换工作目录 123cd [-L|[-P [-e]] [-@]] [DIR] # 切换 shell 工作目录到 DIR（默认未当前用户家目录，可省略）# 常见选项-P，# 符号链接直接转到物理目录结构中，例：cd -L /bin/ &amp;&amp; pwd 输出 /usr/bin ​常见且典型的例子： 123456789[root@localhost cups]\\# cd &amp;&amp; pwd # 不跟参数默认切换到家目录/root[root@localhost home]\\# cd ~ &amp;&amp; pwd # cd ~ 切换到家目录/root[root@localhost home]\\# cd - # cd - 为返回旧的工作目录/root[root@localhost ~]\\# ls /etc/ # 省略输出[root@localhost ~]\\# cd !$ # cd !$ 将上条命令的参数作为 cd 的参数cd /etc/ 🟢 想玩点花的😎：touch 1.txt &amp;&amp; rm -rf !$，如果你不巧是在执行了以某个存在的文件或目录作为参数的命令之后执行的这条语句，那么你刚才操作的那个文件或目录将不幸被删除😢！人生忠告：在删除文件前一定要确保知道你在干什么。一个例子：rm -rf $VAR_NOT_DEFINED/*，这个例子中使用了一个环境变量 VAR_NOT_DEFINED，但该变量未在系统中定义，故原命令就相当于 rm -rf /*，根目录下的所有文件和目录将不保😂。一定切记：删东西需谨慎，验证后再玩花的。献上我差点中招的例子： 1234[root@localhost ~]\\# cd /etc[root@localhost etc]\\# touch 1.txt &amp;&amp; rm -f !$ # 一条语句 != 一条命令，幸好我没指定 -rtouch 1.txt &amp;&amp; rm -f /etcrm: cannot remove &#x27;/etc&#x27;: Is a directory 列出目录里的内容 123456789101112131415161718ls [OPTION]... [FILE]...# 常见可选选项：-a, --all # 列出所有文件（包括 ./、../以及隐藏文件）-A, --almost-all # 列出所有文件（包括隐藏文件）--color[=WHEN] # 用颜色渲染输出：always 总是（默认），auto 自动, never 永不-r, # 将文件以相反次序显示（原来以英文字母次序排序）-t, # 将文件依建立时间之先后次序列出-R, # 递归显示子目录的内容-l, # 一行展示一个文件（包括文件夹），更加详细 ll [OPTION]... [FILE]... # ll 实际上是 ls -l --color=auto 的别名，有些发行版可能不会默认设置# 例子[root@localhost ~]\\# ll /hometotal 0drwx------. 3 student student 99 Apr 11 00:22 student# 可选选项-h, # 人类友好方式显示文件大小-d，# 列出目录或文件自己本身的属性 ​ ls -l 命令执行结果的各个部分的意义如下表所示： 部分 意义 drwx------. 文件类型读写执行权限属性标识，其中第一个字母代表文件类型，- 代表普通文件，d 代表目录，l 符号链接，b 块设备文件，c 字符设备文件，c 套接字文件，接下来每三位分别代表文件所有者、所有者处于的组、其余用户的读取执行权限：- 代表无权限，r 代表有读取权限，w 代表有写入权限，x 代表有执行该文件的权限 3 链接数，表示有多少个文件链接到inode号码，普通文件为 1，目录的话是其包含的文件或目录的个数 student 该文件或目录的拥有者 student 该文件拥有者的分组 99 文件大小，默认用 byte 来表示 Apr 11 00:22 文件最后一次修改的时间，格式：月-日-时间 student 文件名 使用 mv 命令重命名或移动文件或目录 12345678910111213141516mv cp [OPTION]... [-T] SOURCE DEST # 重命名|产生文件的不同名的副本mv cp [OPTION]... SOURCE... DIRECTORY # 将所有 SOURCE 参数代表的文件移动|复制到 DIRECTORY 目录中mv cp [OPTION]... -t DIRECTORY SOURCE... # 传参顺序改变，更容易理解# 常见参数--backup[=CONTROL] # 备份已存在的目标文件，通过选项传参决定：none|off 不备份，numbered|t 产生有编号的备份文件 existing|nil 如果已存在有编号的备份则编号备份，否则不编号，simple|never 普通备份，也可以通过环境变量 $VERSION_CONTROL 决定备份类型-b # 同 --backup，不过不接受参数-S, --suffix=SUFFIX # 指定备份文件后缀名，默认 ~ 。# -i, -n, -f 同时指定则仅最后一个生效-f, --force # 不询问，直接覆盖移动-i, --interactive # 在覆盖前询问-n, --no-clobber # 不覆盖已存在的文件--strip-trailing-slashes # 从源参数中移除尾随斜杠-t, --target-directory=DIRECTORY # 将所有 SOURCE 参数代表的文件移动到 DIRECTORY 目录中-T, --no-target-directory # 将 DESC 视作正常文件-u, --update # 仅当源文件比目标文件新或目标文件丢失的时候移动-v, --verbose # 输出操作的详细信息 使用 cp 命令复制文件或目录 ​ cp 命令格式见 mv。 123# 其它常见选项--attributes-only # 不要复制文件数据，仅复制文件的属性-R, -r, --recursive # 递归复制，即包括目录里的内容也复制 使用 rm 命令删除文件或目录 12345678rm [OPTION]... [FILE]...-f, --force # 忽略不存在的文件或参数报错，不提示-i, # 删除前需确认操作-I, # 删除三个以上目录或文件时，或者在递归删除时，仅提示一次-r, -R, --recursive # 递归删除目录和其中的文件-d, --dir # 删除空目录-v, --verbose # 删除时输出操作信息--, # 删除以 - 为开头的文件时使用 链接文件 了解 linux 文件底层机制 ​Linux 下的文件除了文件数据内容（block 节点）本身之外，还包含对这些纯文件数据内容的管理信息，如：文件名、访问权限、文件的属主以及该文件的数据所对应的磁盘块等，这些管理信息称之为元数据（meta data)，元数据保存在文件的 inode 节点之中。 ​可以通过 stat 命令查看一个文件的 inode 信息。 1234567891011121314151617[root@localhost ~]\\# stat /var/log/messages # linux 下 inode 是该文件系统中的某一文件的唯一标识 File: /var/log/messages Size: 1378414 Blocks: 2696 IO Block: 4096 regular file Device: fd00h/64768d Inode: 34218021 Links: 1 Access: (0600/-rw-------) Uid: ( 0/ root) Gid: ( 0/ root)Context: system_u:object_r:var_log_t:s0 Access: 2021-04-14 18:41:03.906745879 +0800 Modify: 2021-04-14 18:41:03.906745879 +0800 Change: 2021-04-14 18:41:03.906745879 +0800 Birth: -## stat 显示文件或文件系统状态stat [OPTIONS]... FILE...# 常见选项：-L, --dereference # 跟随链接-f, --file-system # 显示文件系统状态而不是文件状态-t, --terse # 以精小的方式打印信息（不常用） ​使用 df -ih 命令查看系统给每个文件系统的 inode 区域划分情况。 12345678910[root@localhost ~]\\# df -ihFilesystem Inodes IUsed IFree IUse% Mounted ondevtmpfs 457K 426 456K 1% /devtmpfs 464K 1 464K 1% /dev/shmtmpfs 464K 987 463K 1% /runtmpfs 464K 17 464K 1% /sys/fs/cgroup/dev/mapper/rhel-root 18M 120K 18M 1% //dev/nvme0n1p1 512K 302 512K 1% /boottmpfs 464K 20 464K 1% /run/user/42tmpfs 464K 32 464K 1% /run/user/0 某个文件系统的 inode 区域被使用完了就无法在该文件系统下创建文件了，即使该文件系统还有磁盘块可以存放文件数据。 ​Linux 下的目录其实是一类特殊的文件，”目录“文件下保存着该目录下所有文件的文件名到 inode 号的对应关系，这里的每个对应关系被称为一个目录项（directory entry，即 dentry）。 硬链接（hard link） ​硬链接的实质是现有文件在文件目录树中的另一个入口，即分居于不同或相同目录下的指向同一个 inode 的 dentry，其文件内容也位于相同的磁盘数据库，具有相同的访问权限、属性等。硬链接可以理解为给已存在的文件取一个别名，只删除一个硬连接并不影响索引节点本身和其它的链接，只有当最后一个链接被删除后，文件的数据块及目录的链接才会被释放。也就是说，文件真正删除的条件是与之相关的所有硬连接文件均被删除。 ​硬链接的优点是几乎不占磁盘空间，因为仅仅是在一个目录文件中增加了一个目录项的对应关系，但这一有点相较软连接并不明显，软链接占用的磁盘空间也很小。硬链接的缺点是：1. 不能跨文件系统创建硬链接；2. 不能对目录创建硬链接原因可以参照网络上的这篇文章。 符号链接（symlink,symbolic link, 也称软链接） ​符号链接其本身也是一个文件，不过这个文件的内容是另一个文件的指针。当要查看某个软链接指向文件的内容时，系统会循着指针找出含有实际数据的目标文件，并读取其内容。 ​软连接可以跨越文件系统指向另一个分区的文件，甚至可以跨越主机指向远程主机的一个文件，也可以指向目录文件。软连接文件的权限是 777，即所有权限都是开放的，且无法更改，但实际文件的权限保护机制仍然起作用。符号链接可以指向一个不存在的文件，即与目标文件处于断裂状态，硬链接不能。 使用链接的好处 保持软件的兼容性 ​在 RHEL8 操作系统中，sh 命令的二进制文件实际上是 bash 文件的一个软连接： 12[root@localhost ~]\\# ll /bin/shlrwxrwxrwx. 1 root root 4 Jun 23 2020 /bin/sh -&gt; bash ​这样做的好处是方便系统向后兼容，因为有些较为早期的脚本文件其默认使用的解释器还默认是 sh ,而 bash 是后来 sh 的最成功的改进版本，为了使这些较为早期的脚本也能在 bash 上正常的执行，故将 sh 作为 bash 的一个链接，实现了不用更改脚本内容就可以使用 bash 来解释执行它们。 方便使用 ​如当我们在 /opt 目录下安装了大型软件后，可在 /usr/bin 目录下为其启动脚本或可执行文件创建链接，这样就可以实现不用修改环境变量，在命令行直接输入软链接的文件名执行就可以打开安装好的软件。 维持旧的操作习惯 ​比如在 SuSE 中，启动脚本的位置是放在 /etc/init.d 目录下，而在 RedHat 的发行版中，是放在 /etc/rc.d/init.d 目录下。为了避免因为从 SuSE 转换到 RedHat 系统而导致管理员找不到位置的情况，我们可以创建一个符号链接 /etc/init.d 使其指向 /etc/rc.d/init.d 即可。 12[root@localhost ~]\\# ll -d /etc/init.dlrwxrwxrwx. 1 root root 11 Apr 17 2020 /etc/init.d -&gt; rc.d/init.d RHEL8 版本中，原先的 service 机制（包括 init.d 控制启动项的机制）已经 systemd 机制取代了。但为了向后兼容，现版本还存在这些文件目录。 使用 ln 命令创建链接 12345678910111213141516ln [OPTION]... [-T] TARGET LINK_NAME # 为 TARGET 创建一个名为 LINK_NAME 的链接ln [OPTION]... TARGET # 在当前工作目录中为 TARGET 创建一个链接ls [OPTION]... TARGET... DIRECTORY # 在 DIRECTORY 中为每一个 TARGET 创建链接（默认硬链接，默认链接文件的文件名不允许在该目录中已存在）ls [OPTION]... -t DIRECTORY TARGET... # 硬链接的目标文件必须存在# 常见选项：--backup=[CONTROL] # 为每个已存在的目标文件创建备份，详见 mv 的 --backup 选项-b, # 类似 --backup 但不接受参数-f, --force # 如果目标文件已经存在则删除它-i, --interactive # 交互询问是否删除已存在的目标文件-L, --logical # 断开符号链接文件和目标文件之间的链接-n, --no-dereference # 将 LINK_NAME 视作正常文件如果它是目录的一个软连接-P, --physical # 使硬链接直接指向符号链接-s, --symbolic # 创建软连接而不是硬链接-t, --target-directory=DIRECTORY # 指定在哪个目录下创建链接-T, --no-target-directory # 将链接名总是视作正常文件-v, --verbose # 打印每个创建好的链接文件名 相关例子如下： 12345678910111213141516171819202122232425262728293031323334353637383940# 创建练习文件 file.txt 并为其创建软链接和硬链接[student@localhost ~]\\$ touch file.txt &amp;&amp; echo &quot;this is an example file of links&quot; &gt; file.txt &amp;&amp; lltotal 4-rw-rw-r--. 1 student student 33 Apr 14 22:13 file.txt[student@localhost ~]\\$ ln -s file.txt symlink_file[student@localhost ~]\\$ ln file.txt hlink_file[student@localhost ~]\\$ lltotal 8-rw-rw-r--. 2 student student 33 Apr 14 22:13 file.txt-rw-rw-r--. 2 student student 33 Apr 14 22:13 hlink_filelrwxrwxrwx. 1 student student 8 Apr 14 22:15 symlink_file -&gt; file.txt# 使用 stat 命令检查这三个文件[student@localhost ~]\\$ stat * File: file.txt Size: 33 Blocks: 8 IO Block: 4096 regular fileDevice: fd00h/64768d Inode: 3252736 Links: 2Access: (0664/-rw-rw-r--) Uid: ( 1000/ student) Gid: ( 1000/ student)Context: unconfined_u:object_r:user_home_t:s0Access: 2021-04-14 22:13:47.856472747 +0800Modify: 2021-04-14 22:13:47.857472747 +0800Change: 2021-04-14 22:16:20.095481417 +0800 Birth: - File: hlink_file Size: 33 Blocks: 8 IO Block: 4096 regular fileDevice: fd00h/64768d Inode: 3252736 Links: 2Access: (0664/-rw-rw-r--) Uid: ( 1000/ student) Gid: ( 1000/ student)Context: unconfined_u:object_r:user_home_t:s0Access: 2021-04-14 22:13:47.856472747 +0800Modify: 2021-04-14 22:13:47.857472747 +0800Change: 2021-04-14 22:16:20.095481417 +0800 Birth: - File: symlink_file -&gt; file.txt Size: 8 Blocks: 0 IO Block: 4096 symbolic linkDevice: fd00h/64768d Inode: 3252737 Links: 1Access: (0777/lrwxrwxrwx) Uid: ( 1000/ student) Gid: ( 1000/ student)Context: unconfined_u:object_r:user_home_t:s0Access: 2021-04-14 22:16:23.155481591 +0800Modify: 2021-04-14 22:15:43.072479308 +0800Change: 2021-04-14 22:15:43.072479308 +0800 Birth: - ​经过对比这三个文件可以发现：源文件和其硬链接文件共同指向了同一个 inode (Inode:3252736) ,硬链接数（Links）字段同为 2，表示有两个目录项指向该 inode，有多少个硬链接其值就为多少（普通文件必存在一个硬链接），它们的文件元数据是一样的；而软链接与源文件相比，其访问权限为 0777，且 inode 号也与源文件不同，其所占的文件数据块大小为0。 12345678# 删除源文件后看看[student@localhost ~]\\$ rm file.txt &amp;&amp; ll -i &amp;&amp; cat hlink_filetotal 43252736 -rw-rw-r--. 1 student student 33 Apr 14 22:13 hlink_file3252737 lrwxrwxrwx. 1 student student 8 Apr 14 22:15 symlink_file -&gt; file.txtthis is an example file of links[student@localhost ~]\\$ cat symlink_file cat: symlink_file: No such file or directory ​删除了源文件后还可以通过硬链接访问文件内容，但该文件的元数据的 Links 字段重新变回了 1（第三列），其 inode（第一列） 没有改变，软链接的记录会不断闪烁表明该软链接已经断裂失效，通过 cat 命令查看其内容也会提示没有该文件。 追随链接 ​自从有了软链接，当要备份、复制或者移动目录或文件的时候，就会出现是否要”追随链接“的问题。如果是，则会操作链接所指的对象，如果不是，则仅仅操作链接本身。一些命令工具会出现是否追随的选项，如 cp： 123# cp 命令关于链接的选项-L, --dereference # 追随链接（复制链接所指向的目标）-P, --no-dereference # 不追随链接（复制链接本身）","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"Linux 文件操作、重定向和管道","slug":"Linux | Linux 文件操作、重定向和管道","date":"2022-08-12T10:35:40.374Z","updated":"2022-08-12T10:54:15.930Z","comments":true,"path":"2022-08-12-Linux | Linux 文件操作、重定向和管道.html","link":"","permalink":"https://skinyi.github.io/2022-08-12-Linux%20|%20Linux%20%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C%E3%80%81%E9%87%8D%E5%AE%9A%E5%90%91%E5%92%8C%E7%AE%A1%E9%81%93.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 文件操作相关 文件名通配符 通配符 作用 举例 * 代表任意多个字符 列出以&quot;.log&quot;结尾的文件：ll *.log ? 代表任意单个字符 列出单个字符构成文件名的文件：ll ? [abc...] 括起的类（位于方括号间的）中的任何一个字符 列出由纯小写字母构成，第二位为i的三位字符构成文件名的文件：ll -d [a-z]i[a-z] [!abc...] 不是括起的类中的任何一个字符 ll -d [^a-b]i[^x-z] {匹配一,匹配二,匹配三...}或{匹配一..匹配三} 将上下文与花括号内的内容结合匹配 ll -d /etc/rc{1,4,5}.d ​ [] 中的其它常见类名：[:alpha:] 任何字母字符，[:lower:] 任何小写字母，[:upper:] 任何大写字母，[:alnum:] 任何字母字符或数字，[:punct:] 除空格和字母数字以外的任何可打印字符，[:digit:] 从 0 到 9 任何单个数字，[:space:] 任何一个空白字符。可能包含制表符、换行符、回车符、换页符或空格。 使用 pwd 命令查看当前工作目录的绝对路径 1234[root@localhost ~]\\# type pwdpwd is a shell builtin[root@localhost ~]\\# pwd/root 使用 touch 命令新建文件 ​ touch 命令的作用是改变文件的时间戳，不过最常用来创建新的空白文件： 12[root@localhost ~]\\# touch file.txt &amp;&amp; ls | grep filefile.txt 使用 file 命令查看文件类型 ​Linux 不需要文件拓展名来区分文件类型，使用 file 命令可以扫描文件的文件头来显示文件或目录类型： 123456[root@localhost ~]\\# file /usr/bin/file/usr/bin/file: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 3.2.0, BuildID[sha1]=2f48178ab3e0f2368f38669dd1d58c49bf0dcf8f, stripped# file 命令常见选项：-b, --brief 不会在输出结果前面加上文件名和冒号（简洁模式）-i, --mime 显示更加详细的 mime 以及字符集信息，效果相当于：--mime-type --mime-encoding-L, --dereference 进一步显示符号链接到的文件的类型 使用 cat 命令查看文件内容（以字符文件形式打开） 🟢 准确的说 cat 命令的作用是将文件以字符的形式输出到标准输出设备中。 123456789[root@localhost ~]\\# cat /proc/cpuinfo # 无文件名参数或提供&quot;-&quot;时会读取标准输入设备,支持同时输出多个文件processor : 0vendor_id : GenuineIntelcpu family : 6model : 142model name : Intel(R) Core(TM) i5-7200U CPU @ 2.50GHz# 常见选项-b, --number-noblank 为非空白行显示行号并输出-n, --number 为所有输出行进行编号 使用 grep 命令搜索文件内容 ​grep - 将匹配模式的文件内容按行输出。如果没有提供 FILE 参数，递归搜索会检查工作目录，非递归搜索会读取标准输入。 123456789101112131415161718grep [OPTIONS] PATTERN [FILE...] # 搜索每个文件中的模式（默认使用基本正则表达式语法），用 - 代表读取标准输入文件grep [OPTIONS] -e PATTERN ... [FILE...]grep [OPTIONS] -f FILE ... [FILE...]# 常见选项：-E, --extended-regexp=PATTERN # 将 PATTERN 解释为拓展正则表达式进行搜索匹配-F, --fixed-strings=PATTERN # 将 PATTERN 解释为固定字符串列表（而不是正则表达式），由 \\ 分隔，其中任何一个字符串都要匹配-e, --regexp=PATTERN # 可以指定多次，也可以和 -f 混用，搜索所有指定的模式，搜索指定的模式-f, --file=FILE # 可以指定多次，也可以和 -e 混用，搜索所有指定的模式，从文件中读取模式，一行一个-i, --ignore-case # 忽略大小写-v, --invert-match # 输出不匹配模式的所有行（反选）-w, --word-regexp # 完整匹配，即搜索结果必须是完整的字-x, --line-regexp # 搜索一整行-c # 忽略输出匹配结果，只输出匹配结果数，-cv 输出不匹配的结果 --color=WHEN # 结果颜色高亮，配色方案可在环境变量 $GREP_COLORS 中配置，值：never,always,auto，默认：grep=grep --color=auto-L, --files-without-matches # 忽略输出匹配结果，只输出没有匹配结果的文件-l, --files-with-matches # 忽略输出匹配结果，只输出含有匹配结果的文件-m, --max-count # 达到指定数量行数的匹配结果后停止搜索-o, --only-matching # 只输出匹配结果中匹配的部分 例子： 123456789101112131415[root@localhost ~]\\# grep -e rm -e mv .bashrcalias rm=&#x27;rm -i&#x27;alias mv=&#x27;mv -i&#x27;[root@localhost ~]\\# grep -c -e rm -e mv .bashrc2[root@localhost ~]\\# grep -w alias .bashrcalias rm=&#x27;rm -i&#x27;alias cp=&#x27;cp -i&#x27;alias mv=&#x27;mv -i&#x27;[root@localhost ~]\\# grep -w alia .bashrc[root@localhost ~]\\# grep -i ALIas .bashrc# User specific aliases and functionsalias rm=&#x27;rm -i&#x27;alias cp=&#x27;cp -i&#x27;alias mv=&#x27;mv -i&#x27; 使用 wc 命令统计文件中行、字和字符的数量 ​可以一次指定多个文件，且未指定文件名参数或指定参数 ”-“ 时默认读取标准输入文件。默认情况下该命令输出的结果按照 行数、 字数、字符数、字节数、最大行的长度 的顺序排序，也可以通过选项来指定要输出的内容： 12345678[root@localhost ~]\\# wc --help | wc # 统计命令 wc --help 执行结果的行数、字数、字符数 24 158 1201# 常见选项-l, --lines 打印行数-w, --words 打印字数-m, --chars 打印字符数-c, --bytes 打印字节数-L, --max-line-length 打印最长行的长度 重定向和管道 ​因为上下文中都有涉及，先来了解重定向和管道的相关知识： 重定向和管道 ​Linux 有三个特殊的文件分别是标准输入流文件（stdin)、标准输出流文件（stdout）、标准错误输出流文件（stderr），它们在你打开的程序开始运行时被默认打开。以终端程序为例，每次键入的内容被送到标准输入流作为程序的输入，程序处理后的文字输出通过标准输出流成为我们看到的命令执行结果，错误信息则会被送到标准错误输出流中处理，它们通常都会显示在对应的终端窗口中。在终端中分别可以用 0、1、2 代指它们，例子： 1234[root@localhost ~]\\# cat file.txt 1&gt;&gt; res.txt &amp;&amp; cat res.txt # 文件描述符 1 可以省略echo hellowordecho helloword# 解释：读取 file.txt 的内容并直接追加输出到 res.txt 并显示 res.txt 文件里的内容 ​有时我们会有需求将某个文件作为命令输入或者命令执行结果的输出，这可以使用重定向来实现，输入输出重定向可简单理解为用其它设备代替键盘和显示器。 ​注意，如果我们想要将某条命令的执行结果作为第二条命令的参数，需要通过管道来实现而不是重定向。 🔴 如果误使用重定向向第二条命令传参的话可能会破环第二条命令的可执行文件的内容！切记：重定向是将本该在标准输入输出（键盘、屏幕）的内容改用其他文件来进行读写的。 命令符号格式 作用 命令 &lt; 文件 将指定文件的内容作为命令的输入设备 命令 &lt;&lt; 分界符 表示从标准输入设备（键盘）中读入，直到遇到分界符才停止（读入的数据不包括分界符），这里的分界符其实是自定义的字符串 命令 &lt; 文件1 &gt; 文件2 将文件1作为命令的输入设备，该命令的执行结果输出到文件2中 命令 &gt; 文件 将命令执行的标准输出结果重定向输出到指定的文件中（清空写入模式） 命令 2&gt; 文件 将命令执行的错误输出结果重定向输出到指定的文件中（清空写入模式） 命令 &gt;&gt; 文件 将命令执行的标准输出结果重定向输出到指定的文件中（追加写入模式） 命令 2&gt;&gt; 文件 将命令执行的错误输出结果重定向输出到指定的文件中（追加写入模式） 命令 &gt;&gt; 文件 2&gt;&amp;1 或者 命令 &amp;&gt;&gt; 文件 将命令执行的标准输出或者错误输出写入到指定文件中（追加写入模式） 命令1 ` ` 命令2 重定向的例子 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091## 例一：[root@localhost ~]\\# cat &lt; /etc/hosts # 跟 cat /etc/hosts 效果一致127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6# 虽然它们的执行结果相同，但本例是以 /etc/hosts 文件作为输入设备的，注释是以键盘作为输入设备的。## 例二：[root@localhost ~]\\# cat &lt;&lt; EOF # 从标准输入设备不断读取内容知道读取到 EOF 才停止，并输出&gt; abcd&gt; cde&gt; eof EOF&gt; EOFabcdcdeeof EOF## 例三：# 做的事：新建 hosts.bak 文件 -&gt; 从 /etc/hosts 读入内容并输出到 hosts.bak -&gt; 显示 hosts.bak 的内容[root@localhost ~]\\# touch hosts.bak &amp;&amp; cat &lt; /etc/hosts &gt; hosts.bak &amp;&amp; cat hosts.bak127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6# 整条命令由三条语句构成，且后面的语句执行与否由前面语句的执行成功与否的结果决定## 例四：# 准备工作：新建两个空白文件 file1.txt 和 file2.txt，其中向 file1.txt 添加内容 ”123321“# 查看两个文件的内容[root@localhost ~]\\# more file1.txt file2.txt::::::::::::::file1.txt # -&gt; 文件1的文件名::::::::::::::123321 # -&gt; 文件1的内容::::::::::::::file2.txt # -&gt; 文件2的文件名 因为没有内容所以显示内容为空::::::::::::::# 读取 file2.txt 的内容并清空写入到 file1.txt 并显示 file1.txt 的内容[root@localhost ~]\\# cat file2.txt &gt; file1.txt &amp;&amp; cat file1.txt[root@localhost ~]\\# █ # file1.txt 的内容被清空写入了空内容# 向文件 file1.txt 和 file2.txt 分别写入 123321[root@localhost ~]\\# echo &#x27;123321&#x27; &gt; file1.txt &amp;&amp; cat file1.txt &gt; file2.txt# 此时再查看这两个文件的内容[root@localhost ~]\\# more file1.txt file2.txt::::::::::::::file1.txt # -&gt; 文件1的文件名::::::::::::::123321 # -&gt; 文件1的内容::::::::::::::file2.txt # -&gt; 文件2的文件名::::::::::::::123321 # -&gt; 文件2的内容# 将 file1.txt 的内容追加到 file2.txt 中并显示 file2.txt 的内容[root@localhost ~]\\# cat file1.txt &gt;&gt; file2.txt &amp;&amp; cat file2.txt123321123321 # &lt;-- 新追加的内容# 将不存在的文件的内容清空写入到 file1.txt 并尝试查看 file1.txt 的内容[root@localhost ~]\\# cat file_not_exist.txt &gt; file1.txt; cat file1.txtcat: file_not_exist.txt: No such file or directory # 前面语句执行出错,标准输出为空，错误输出显示在了屏幕上，file1.txt 的内容被清空写入了空内容# 同上例，不过要求将错误信息输出到 file1.txt，标准输出正常输出到显示器[root@localhost ~]\\# cat file_not_exist.txt 2&gt; file1.txt; cat file1.txtcat: file_not_exist.txt: No such file or directory # 注意这是 file1.txt 的文件内容[root@localhost ~]\\# cat file_not_exist.txt &amp;&gt;&gt; file1.txt # 再次执行，将标准输出或错误输出都追加到 file1.txt [root@localhost ~]\\# cat file1.txtcat: file_not_exist.txt: No such file or directorycat: file_not_exist.txt: No such file or directory## 例五：（要使用上例中的两个文件）# 查看 file1.txt 和不存在的文件的内容并将标准输出和错误输出都重定向追加写入到 file2.txt[root@localhost ~]\\# cat file1.txt file_not_exist.txt &gt;&gt; file2.txt 2&gt;&amp;1[root@localhost ~]\\# cat file2.txt123321 # -&gt; file2.txt 的原有内容123321 # -&gt; file2.txt 的原有内容cat: file_not_exist.txt: No such file or directory # -&gt; file1.txt 定向过来的内容cat: file_not_exist.txt: No such file or directory # -&gt; file1.txt 定向过来的内容cat: file_not_exist.txt: No such file or directory # -&gt; 找不到文件的标准错误输出# 上例也可以如下实现：[root@localhost ~]\\# cat file1.txt file_not_exist.txt &amp;&gt;&gt; file2.txt[root@localhost ~]\\# cat file2.txt123321 # -&gt; file2.txt 的原有内容123321 # -&gt; file2.txt 的原有内容cat: file_not_exist.txt: No such file or directory # -&gt; file2.txt 的原有内容cat: file_not_exist.txt: No such file or directory # -&gt; file2.txt 的原有内容cat: file_not_exist.txt: No such file or directory # -&gt; file2.txt 的原有内容cat: file_not_exist.txt: No such file or directory # -&gt; file1.txt 定向过来的内容cat: file_not_exist.txt: No such file or directory # -&gt; file1.txt 定向过来的内容cat: file_not_exist.txt: No such file or directory # -&gt; 找不到文件的标准错误输出## 例六[root@localhost .config]\\# ps aux | grep bash # 执行 ps aux 命令并在其输出中查找 bash 关键字root 1045 0.0 0.0 26344 2468 ? S Apr11 0:13 /bin/bash /usr/sbin/ksmtunedroot 12458 0.0 0.1 27660 5612 pts/0 Ss 08:25 0:01 -bashroot 20373 0.0 0.0 12112 1092 pts/0 S+ 21:33 0:00 grep --color=auto bash 既想在终端上输出命令执行结果又想将其保存到文件中 ​ tee 命令：从标准输入中获取内容并写入到标准输出和文件中去。 1234tee [OPTIONS]... [FILE]... # 复制标准输入获得的内容到文件和标准输出# 常见选项：-a, --append # 向指定的文件中追加写入，而不是覆盖-i, --ignore-interrupts # 忽略中断信号 例子： 123456789101112131415[root@localhost ~]\\# ll | tee file.txt | grep Videos &amp;&amp; cat file.txtdrwxr-xr-x. 2 root root 6 Apr 9 04:49 Videostotal 8-rw-r--r--. 1 root root 0 Apr 10 21:51 $-rw-------. 1 root root 1327 Apr 9 04:40 anaconda-ks.cfgdrwxr-xr-x. 2 root root 6 Apr 9 04:49 Desktopdrwxr-xr-x. 2 root root 6 Apr 9 04:49 Documentsdrwxr-xr-x. 2 root root 6 Apr 9 04:49 Downloads-rw-r--r--. 1 root root 0 Apr 15 19:46 file.txt-rw-r--r--. 1 root root 1680 Apr 9 04:43 initial-setup-ks.cfgdrwxr-xr-x. 2 root root 6 Apr 9 04:49 Musicdrwxr-xr-x. 2 root root 6 Apr 9 04:49 Picturesdrwxr-xr-x. 2 root root 6 Apr 9 04:49 Publicdrwxr-xr-x. 2 root root 6 Apr 9 04:49 Templatesdrwxr-xr-x. 2 root root 6 Apr 9 04:49 Videos 其他查看文件内容的方法 使用 cat 命令查看大篇幅的文件内容时，显示这些文件时所占用的空间可能要超过终端提供的大小。cat 命令不会对文件的内容进行分页。 使用 more 分页查看文件内容 ​more 和 cat 类似，但是 more 支持分页查看。 123456789[root@localhost ~]\\# more /proc/meminfoMemTotal: 3798432 kBMemFree: 1387992 kB...... # 省略内容KReclaimable: 213284 kB--More--(0%)█ # space 或 ctrl + f 往下翻页，b 或 ctrl + b 往回翻页，enter 向下滚动一行，q 退出# 常见选项 h 显示帮助信息-d, 显示操作提示信息-f, 以实际文件行数计算行数（非自动换行后的行数） 使用 less 分页查看文件内容 ​less 算是 more 的加强版，less 不会读取整个文件，因此其加载时间会很快。 1234567891011121314151617# 使用 less 读取文件[root@localhost ~]\\# less /proc/cpuinfoprocessor : 0vendor_id : GenuineIntel...... # 省略内容a cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon nopl xtopology tsc_reliable nonstop_tsc cp....../proc/cpuinfoc█# 使用 less 读取命令输出的内容（需结合管道）[root@localhost ~]\\# ps aux | lessUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND...... # 省略内容root 13 0.0 0.0 0 0 ? S 11:00 0:00 [watchdog/0]:█# 常见选项-N, 显示行号-X, 退出 less 后在屏幕上保留内容+F, 表现与 tail -f 命令几乎相同 可使用的键盘操作： 按键 作用 备注 space or f 往下翻 N 行 N 默认为一个窗口的行数大小，可以在冒号后面输入数字指定 N 的值再按快捷键 b 或 ctrl + b 或 esc + v 往上翻 N 行 N 默认为一个窗口的行数大小，可以在冒号后面输入数字指定 N 的值再按快捷键 d 或 ctrl + d 往下翻 N 行 N 默认为半个屏幕的行数大小，可以在冒号后面输入数字指定 N 的值再按快捷键 u 或 ctrl + u 往上翻 N 行 N 默认为半个屏幕的行数大小，可以在冒号后面输入数字指定 N 的值再按快捷键 ↓ 或 e 或 j 或 enter 往下翻一行 ↑ 或 y 或 k 往上翻一行 g 或 p 分别对应转到第一行和最后一行 g 前面指定 N 转到第 N 行，p 前面指定 N 转到第 N% 的内容 / 或 ? 跟模式 分别对应向前或向后搜索模式 n 重复上一次搜索，N 反向重复上一次搜索 h 或 q h 显示帮助信息 q 退出 less。 head 或 tail 显示部分文件内容 ​head 和 tail 分别显示文件的开头和结尾部分，默认情况下，这两个命令显示文件的 10 行，但它们都有一个 -n 选项，允许指定不同的行数。未指定文件名参数或指定参数 ”-“ 时默认读取标准输入文件。 123456789[root@localhost ~]\\# head -n 3 /etc/passwdroot:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologin[root@localhost ~]\\# tail -n 2 -fs 2 /var/log/messagesApr 11 22:21:47 localhost systemd[1]: Started Network Manager Script Dispatcher Service.Apr 11 22:21:57 localhost systemd[1]: NetworkManager-dispatcher.service: Succeeded.█ # -f 监视文件，文件内容发生变化时也跟着输出（追加）， -s 指定扫描文件变化间隔的秒数（与 -f 搭配，默认 1s）# 按 ctrl + c 退出监控模式","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"Shell 使用相关与 Linux 文件系统基础","slug":"Linux | Shell 使用相关与 Linux 文件系统基础","date":"2022-08-12T10:27:44.899Z","updated":"2022-08-12T10:55:30.838Z","comments":true,"path":"2022-08-12-Linux | Shell 使用相关与 Linux 文件系统基础.html","link":"","permalink":"https://skinyi.github.io/2022-08-12-Linux%20|%20Shell%20%E4%BD%BF%E7%94%A8%E7%9B%B8%E5%85%B3%E4%B8%8E%20Linux%20%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 Shell 使用相关 在图形界面中打开终端 ​最常用的是找终端的图标单击打开，也可以使用快捷键 &quot;Alt + F2&quot; 打开 ”Enter a command“ 窗口（类似于 windows 上的 ”运行“ 窗口），输入 ”gnome-terminal“ 按回车即可打开图形界面自带的终端。 终端上常用的快捷键操作 a. tab：可以实现命令的自动补全（当所输入的内容可以推断出唯一结果时），连按两次会给出所有可能匹配的结果。（此功能由软件包 bash-completion 提供，最小化安装操作系统时可能不会自动安装）； b. 调整光标位置或内容调整： 快捷键 效果 Ctrl + A 跳到命令行语句的开头 Ctrl + E 跳到命令行语句的末尾 Ctrl + U 将光标处到命令行语句开头的内容清除 Ctrl + K 将光标处到命令行语句末尾的内容清除 Ctrl + ← 跳到命令行语句中前一字的开头 Ctrl + → 跳到命令行语句中下一字的末尾 Ctrl + R 在历史记录列表中搜索某一模式的命令 Esc + . 插入执行的上条命令的参数 Shell 历史命令操作 ​使用 history 命令可以查看历史执行过的命令。 12345678910111213141516[root@localhost ~]\\# type historyhistory is a shell builtin # history 命令是 bash 内建命令[root@localhost ~]\\# history # 使用 history 命令可以查看之前执行过的命令 1 ip addr show 2 clear 3 vim /etc/sysconfig/network-scripts/ifcfg-ens160 4 ls /etc/sysconfig/network-scripts/ 5 ls 6 ls -a /etc/sysconfig/network-scripts/ 7 ll -a /etc/sysconfig/network-scripts/ 8 clear 9 vim /etc/sysconfig/network-scripts/ifcfg-ens160 10 reboot 11 ip addr show 12 type history 13 history ​此时如果还想执行之前执行过的第 7 行命令，则只需执行： 123456[root@localhost ~]\\# !7 # 使用 &quot;!&quot; 后跟历史序号即可执行 history 结果里的第该序号条命令ll -a /etc/sysconfig/network-scripts/ # 执行的历史命令的内容会首先列出total 8 # 然后是执行结果drwxr-xr-x. 2 root root 26 Apr 9 06:01 .drwxr-xr-x. 6 root root 4096 Apr 9 04:39 ..-rw-r--r--. 1 root root 282 Apr 9 06:01 ifcfg-ens160 ​特殊的，如果想再次执行上一次执行的命令，如下例所示： 123456789101112[root@localhost ~]\\# type file # 执行 ”!!“ 前的上一条命令file is /usr/bin/file[root@localhost ~]\\# !! # 使用 ”!!“ 再次执行type file # 同样会先显示执行内容file is /usr/bin/file # 执行结果# sudo !! 的例子[student@localhost root]\\$ dnf update # 该普通用户没有权限，无法升级本地软件包2021-04-10 22:13:38,682 [ERROR] dnf:5314:MainThread @logutil.py:194 - [Errno 13] Permission denied: &#x27;/var/log/rhsm/rhsm.log&#x27; - Further logging output will be written to stderrNot root, Subscription Management repositories not updated[student@localhost root]\\$ sudo !! # 使用 sudo 提升当前用户的权限再次执行上次未成功的操作（前提是当前用户是管理员，即在 sudoers 里）sudo dnf updateUpdating Subscription Management repositories. Shell 配置文件 文件路径 描述 ~/.bashrc 和 /etc/bashrc 分别对应当前用户和全局用户的 bash 的一些个性化设置，如命令别名、函数等，通常不建议直接修改 /etc/bashrc 而应该在 /etc/profile.d/ 目录中添加自己的脚本 ~/.bash_profile 和 /etc/profile 分别对应当前用户和全局用户的 bash 环境变量以及启动程序等，通常不建议直接修改 /etc/bashrc 而应该在 /etc/profile.d/ 目录中添加自己的脚本 ~/.bash_history 存储当前用户终端中执行过的历史命令，环境变量 $HISSIZE 定义其存储大小 ~/.bash_logout 存储当前用户登出终端时要执行的命令 🟢 配置文件读取情景及读取顺序 图形界面登陆时：/etc/profile -&gt; ~/.profile 登陆后，打开终端后：-&gt; /etc/bashrc -&gt; ~/.bashrc 文本模式登陆时：/etc/bashrc -&gt; /etc/profile -&gt; ~/.bash_profile 从其它用户 su 到该用户，则分两种情况： a. 带 -l, -, --login 参数：/etc/bash -&gt; /etc/profile -&gt; ~/.bash_profile b. 没有带 -l 参数：/etc/bashrc -&gt; /bashrc 注销时，或退出 su -l 登陆的用户时会读取：~/.bash_logout 执行自定义的 shell 文件时，若使用 bash -l a.sh 的方式，则 bash 会读取：/etc/profile 和 ~/.bash_profile，若使用其他方式，如：bash a.sh，./a.sh，sh a.sh 则不会读取上面任何文件。 Linux 文件系统基础 ​大多数 linux 发行版采用 FHS（Filesystem Hierarchy Standard,文件系统层次化标准）来组织文件系统结构，这是一种以一个根节点开始的倒置的树形结构，FHS定义了系统中每个区域的用途、所需要的最小构成的文件和目录，同时还给出了例外处理与矛盾处理。 ​FHS 定义了两层规范，一是 linux 文件系统根目录（即 &quot;/&quot; ）下的各个目录该放什么文件数据，二是针对/usr及/var这两个目录的子目录来进行了更深一层的定义。 ​Linux 的文件结构树根据每个人的喜好不同可能会被组织成各式各样的形式，这无疑会导致一种混乱的局势，FHS 一定程度上提供了一种共识，是即使是不同的 linux 发行版不会因为文件结构的混乱产生很大的学习成本。 ​在Linux文件系统中有两个特殊的目录，一个用户所在的工作目录，也叫当前目录，可以使用一个点来表示；另一个是当前目录的上一级目录，也叫父目录，可以使用两个点来表示： . ：代表当前的目录，也可以使用 ./ 来表示； .. ：代表上一层目录，也可以使用 ../ 来代表。 ​如果一个目录或文件名以一个点 &quot;.&quot; 开始，表示这个目录或文件是一个隐藏目录或文件(如：.bashrc)，以默认方式查找时，不显示该目录或文件。 linux 文件系统中的一些重要目录及其作用 根目录 一级目录 二级目录 描述 / boot 系统启动目录，包含可引导的 linux 内核和引导装载配置文件，删除后虚拟机无法启动 root root 用户的家目录 home student /home是所有普通用户家目录存放的路径，普通用户一般再次路径下拥有和自己用户名一样的家目录，用以存放保存的文件、个人配置文件等，此例中有一个 student 用户的家目录：/home/student usr bin 见/bin，/bin下的命令在任何运行级别都可以使用，此路径下的命令在单用户模式下不能执行 sbin 见/sbin local 手工安装的软件保存位置，一般建议源码包软件安装在这个位置 tmp 存放系统运行过程中产生的临时文件，其真实目录在/var/tmp，此目录存放需要长期保存的临时文件，未访问、修改、更改超 30 天的文件会被删除 local 手工安装的软件保存位置，一般建议源码包软件安装在这个位置 share 应用程序的资源文件保存位置，如帮助文档、说明文档和字体目录 include C/C++ 等编程语言头文件的放置目录 bin 二进制文件目录的链接，真实目录为/usr/bin，普通用户和 root 用户均可操作，包含常用的 linux 用户命令 sbin 保存与系统环境设置相关的命令，只有 root 可以使用这些命令进行系统环境设置，真实目录在/usr/sbin tmp 存放系统运行过程中产生的临时文件，存放的文件需要的生命周期较短，有些系统会十分频繁的清理这个目录（RHEL 自动删除未访问、修改、更改超 10 天的目录），为了追求读取和写入迅速有些系统甚至会将这个目录挂载到 RAM 上。在系统启动阶段，许多启动脚本将这个目录作为临时文件存放目录 lib 系统的动态库目录，存放/bin和/sbin目录中二进制文件依赖的运行库文件。几乎所有的应用程序都会用到该目录下的共享库 lib64 存放针对64位系统的特定的一些额外动态库的目录 opt 可选目录。一般用以存放第三方软件和数据文件 etc 配置文件保存位置。系统内所有采用默认安装方式的服务配置文件全部保存在此目录中，如用户信息、服务的启动脚本、常用服务的配置文件等 srv 服务目录，service 的缩写，主要用来存储本机或本服务器提供的服务或数据 sys 于2.6内核引入，存放sysfs在内存中，sysfs文件系统集成了下面3种信息：针对进程信息的proc文件系统、针对设备的devfs文件系统以及针对伪终端的devpts文件系统。该文件系统是内核设备树的一个直观反映。当一个内核对象被创建的时候，对应的文件和目录也在内核对象子系统中 var tmp /var为可变目录，用以存放经常变化的文件，如日志文件；/var/tmp见/usr/tmp lib 程序运行中需要调用或改变的数据保存位置。如 MySQL 的数据库保存在 /var/lib/mysql 目录中 log 登陆文件放置的目录，其中所包含比较重要的文件如 /var/log/messages, /var/log/wtmp 等 run 一些服务和程序运行后，它们的 PID（进程 ID）保存位置 spool 里面主要都是一些临时存放，随时会被用户所调用的数据，例如 /var/spool/mail 存放新收到的邮件，/var/spool/cron/存放系统定时任务 nis和yp NIS 服务机制所使用的目录，/var/nis 主要记录所有网络中每一个 client 的连接信息；/var/yp 是 linux 的 nis 服务的日志文件存放的目录 run 一个临时文件系统，存储系统启动以来的信息（PID和锁文件）。当系统重启时，这个目录下的文件应该被删掉或清除。如果你的系统上有 /var/run 目录，应该让它指向 run proc 虚拟文件系统，数据直接保存在内存中，将内核、进程、外部设备和网络状态归档为文本文件（系统信息都存放在这目录下），例如：uptime、network。在 linux 中，对应 procfs 格式挂载，目录下文件只能看不能改 cpuinfo 保存 CPU 信息 devices 保存设备驱动列表 net 保存网络协议信息 dev 设备文件，任何设备与接口设备都是以文件形式存在于这个目录的，包括终端设备 tty、软盘 fd、硬盘 hd、RAM ram 和 CD-ROM cd等，用户通过设备文件直接访问这些设备 mnt 临时挂载的文件系统，比如移动硬盘, U盘和其他操作系统的分区 media 媒体目录，也是挂载点目录，提供挂载和自动挂载设备的标准位置，如远程访问文件系统和可移动介质 文件系统归类： 系统启动必须：/boot、/etc、/lib、/sys； 二进制指令集合：/bin、/sbin； 外部文件管理：/dev、/media、/mnt； 账户相关：/root、/home、/usr、/usr/bin、/usr/sbin、/usr/src； 运行过程相关：/var、/proc； 扩展用的：/opt、/srv； 其它常用的重要文件位置及作用： 位置 作用 /etc/yum.repos.d/redhat.repo RHEL YUM 仓库的配置文件（安装、更新软件相关） /etc/sysconfig/network-scripts/ifcfg-ens160 网卡配置文件（连接外网） /boot/vmlinuz-4.18.0-240.el8.x86_64 内核文件 /boot/initramfs-4.18.0-240.el8.x86_64.img 是内存中的磁盘结构的实现，其中包含必要的工具和脚本，用于在将控制权交给根文件系统上的 init 应用程序之前挂载所需的文件系统 /boot/grub2/.. 与引导程序有关的文件 /etc/ssh/sshd.conf SSH 配置文件 /etc/services 常用和已注册的网络端口监听列表","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"Linux 基本架构与 Shell 初识","slug":"Linux | Linux 基本架构与 Shell 初识","date":"2022-08-12T09:53:32.669Z","updated":"2022-08-13T00:51:00.651Z","comments":true,"path":"2022-08-12-Linux | Linux 基本架构与 Shell 初识.html","link":"","permalink":"https://skinyi.github.io/2022-08-12-Linux%20|%20Linux%20%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E4%B8%8E%20Shell%20%E5%88%9D%E8%AF%86.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 Linux 架构概览 ​Linux，全称 GNU/Linux，是一种免费使用和自由传播的类 UNIX 操作系统，它基于 POSIX 的多用户、多任务、同时支持多线程和多 CPU,它能运行主要的 unix 工具软件、应用程序和网络协议。GNU/Linux 是宏内核的操作系统，整体贯彻模块化的开发思想，因此支持针对不同应用场景和设备硬件情况进行裁剪定制。下图展示了 linux 内核的基本模块构成。 🟢 严格来说，linux 是指 linux 内核，GNU/Linux 才是一个包含软件和内核的完整操作系统。 Shell 与命令初识 ​Shell 是操作系统内核的外壳，用以保护操作系统内核和提供用户和操作系统内核进行交互的接口。同时 shell 还是一种程序设计语言：作为命令语言，它交互式解释和执行用户输入的命令或者自动地解释和执行预先设定好的一连串的命令；作为程序设计语言，它定义了各种变量和参数，并提供了许多在高级语言中才具有的控制结构，包括循环和分支。 ​Shell 可以分为两大类，即图形界面 shell 和命令行式 shell。图形界面 shell 相较于命令行 shell 比较占用系统资源且灵活性不高，命令行 shell 因为要记忆大量的 linux 基本操作命令而比较难以掌握，不过很多 Linux 命令本身提供了查阅手册和帮助选项用以提示用户相关的交互指令用法。Shell 根据历史阶段的不同有不同的实现，在 RHEL 中支持 sh 和 bash（默认） 命令式交互 shell（但调用 sh 时仍是使用的 bash，bash 是 sh 的一个最成功的改进产品）。 ​以命令行交互方式使用 shell 时，启动终端字符界面后，它在等待用户输入命令时会闪烁一个“█”小光标，在它的前面会有一串shell提示符，如下所示（请忽略&quot;$&quot;或&quot;#&quot;前边的\\转义符号，下同）： 1[user@host ~]\\$ █ 🟢 Shell提示符的构成 user：当前登陆用户，如果使用 root 用户的则显示 root； host：登陆终端的主机名，一般由 ip 或域名构成； ~：当前操作所位于的工作路径，“~”代表当前用户的家目录（默认登陆后的工作目录），如示例则完整路径为：/home/user，其他路径以完整绝对路径显示。 $：以该系统的普通用户登陆时则显示美元符号“$”，表明当前会话以普通用户登陆，若以 root 用户登陆时则显示井号“#”，用以提示用户谨慎操作。 Shell 提示符的内容及形式由 PS1 环境变量确定。 ​Shell 命令主要由三部分组成，命令、选项、参数，如下例子： 12[root@host ~]\\# usermod -L user01 # command-&gt;usermod options-&gt;-L args-&gt;user01# 选项若由字母指定，一般前面加一个 &quot;-&quot;，空格后跟参数，若由单词指定，一般前面加 &quot;--&quot;，= 后跟参数 ​可以在一行中使用分号将不同语句隔离开，shell 会按序执行，但是这样做是有风险的，因为后面的语句不论前面的执行结果成功与否都会执行，因此依赖于前面执行结果的语句可能会得到错误的结果。为了使操作更加安全，可以使用”&amp;&amp;“将它们连接起来，这个符号连接的两条语句只有第一条语句执行成功后第二条才会执行。与此相反，”||“连接的两条语句只有前一条执行失败的时候才会执行第二条。 ​如果你要执行的命令比较冗长，可以使用”\\“将其切割为多行，如下例所示： 123[user@host ~]\\$ command --this_is_a_very_long_option \\ # 保持各个组成部分完整，不要拆分&gt; very_long_parameter_that_you_never_see_before_1 \\&gt; very_long_parameter_that_you_never_see_before_2 使用本地终端登录到本地计算机 ​终端是一个基于文本的界面，用于向计算机系统输入命令以及显示计算机系统的输出。本地终端是指运行在连接了键盘和显示器直接输入输出的设备上的文本界面，这些设备也称为 Linux 计算机的物理控制台。物理控制台支持多个虚拟控制台，它们可以运行单独的终端。每个虚拟控制台均支持独立的登录会话。 🟢 使用 Ctrl + Alt + F1~F6 快捷键进行虚拟控制台一到六的快速终端切换。 在 RHEL8 中，如果图形环境可用，则登陆屏幕默认会在称为 tty1 的第一个虚拟控制台中运行，其余第二到第六虚拟控制台则提供文本 Shell 交互界面。用户在登陆界面登陆成功后则会为该用户在二到六顺延空闲的一个虚拟控制台建立图形会话。要在图形界面中获得 Shell 提示符，需要使用图形界面提供的终端应用程序。 🟢 使用以下命令查看系统默认以什么方式进行登陆： [root@localhost opt]# systemctl get-default # set-default 或 isolate 选项可以设置其它登陆方式（一般为multi-user.target）（前者重启生效永久保存，后者即时生效临时有效） graphical.target # 默认图形界面登陆 ​登陆用户若想退出当前图形界面的交互，需要进行注销操作，注意：切换用户的界面同样是返回 tty1 进行登陆操作但不退出当前操作用户，同样在下一个未使用的虚拟控制台为切换过去的用户提供图形交互界面。用户注销后，物理控制台则自动切回第一虚拟控制台的图形登陆界面，等待选择用户并登录。 ​无外设服务器提供了串行端口用以为管理员提供登陆服务，该串行端口为远程登陆服务器和该应用服务器提供连接，串口登陆为网络配置有误或者尚未配置网络的服务器提供登陆支持以修复，不过大多数下，网络配置无误有效的服务器通过网络来进行登陆。 使用远程服务登陆到网络计算机 ​Linux 用户和管理员通常需要通过网络连接到远程系统来获得对远程系统的 shell 访问。随着现代虚拟化以及云计算技术的不断发展，网络登陆变得更加十分普遍，在 Linux 中，最常见的是使用 Secure Shell Daemon(SSHD) 服务为宿主计算机提供远程登陆获得命令提示符的服务。其它需要登陆到远程服务器的计算机则需要安装 SSH 客户端。最主流的 SSH 实现为 OpenSSH 实现。通常一台 Linux 机器上是同时安装了 SSH 客户端和服务端了的，用以实现登陆登陆其它机器和为其它登陆到自己的机器提供会话。如下例： 123[user@host ~]\\$ ssh remoteuser@remotehost # sshd 服务默认监听 22 端口，登陆时不指定的话客户端默认去连 22remoteuser@remotehost\\`s password: password # 密码不会显示在终端上[remoteuser@remotehost ~]\\$ █ 🟢 本示例展示了通过本地 user 用户远程登陆到了远程 remotehost 上的 remoteuser 用户，且这个过程需要提供身份验证，本示例是使用密码验证，登陆成功后 shell 提示符变为了远程计算机的 shell 提示符。 ​ssh 命令通过加密连接来防止通信被窃听或劫持密码和内容。有些系统不允许用户使用密码登陆到远程主以增强安全性，其使用的用户身份验证方法是公私钥身份验证。这种验证方法的流程是：用户本地存放私钥、远程计算机存放公钥，用户登录时通过为 ssh 命令提供公钥文件路径的参数，ssh 程序通过与远程计算机上安装的授权公钥进行比对，如果两者是匹配的，则不需要密码就可登陆，如下例： 12[user@host ~]\\$ ssh -i mylab.pem remoteuser@remotehost[remoteuser@remotehost ~]\\$ █ 🟢 用户的私钥文件必须只能该用户本身拥有读取权限。用户首次登陆远程计算机时系统会发出警告，表示本地没有存储过远程计算机的密钥，如果你信任该密钥，则本地计算机会保存其密钥登陆且下次不再提醒。 ​使用 exit 命令可以退出在远程计算机上的登陆，且 shell 提示符切换回本地的： 1234[remoteuser@remotehost ~]\\$ exitlogoutConnection to remotehost closed.[user@host ~]\\$ █ Linux 命令执行优先级 ​Shell 中可执行命令分为 shell 内建命令和外部命令。内建命令直接从内存中读取只需提供命令名，而外部命令需要从系统文件中读取可执行文件，一般来说可以直接指定可执行文件的绝对路径或相对路径，但是这样要输入长串的路径，比较麻烦，因此 shell 提供了环境变量 $PATH 来指定命令的搜索路径，这样的话执行命令就可以直接使用命令名来执行了，shell 程序会自动搜索 $PATH 环境变量中的路径，同时为了加快外部命令的执行过程 shell 还提供了缓存表机制。有些常用的命令可能输入起来比较长，因此还有别名机制用以实现快速输入执行。 查看命令类型可以使用 type 命令： 123456[root@localhost ~]\\# type type # type 是内建命令,除此之外 echo、hash、alias、pwd也是type is a shell builtin[root@localhost ~]\\# type top # top 是外部命令top is /usr/bin/top[root@localhost ~]\\# type rm # rm 是 rm -i 的别名，除此之外 ll 是 ls -l 的别名rm is aliased to `rm -i&#x27; 查看 $PATH 环境变量的内容： 1234567891011121314151617[root@localhost ~]\\# echo $PATH/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin# 可执行文件搜索相关[root@localhost opt]\\# type which # which 也是别名which is aliased to `(alias; declare -f) | /usr/bin/which --tty-only --read-alias --read-functions --show-tilde --show-dot`[root@localhost opt]\\# which top # 查看命令可执行文件的绝对路径/usr/bin/top[root@localhost opt]\\# type whereis # 我之前执行过 whereis 此处 whereis 是从缓存表里加载的 whereis is hashed (/usr/bin/whereis)[root@localhost opt]\\# whereis top # 查看命令可执行文件绝对路径及帮助文档绝对路径top: /usr/bin/top /usr/share/man/man1/top.1.gz# 查看命令的缓存表[root@localhost opt]\\# hashhits command 3 /usr/bin/whereis 1 /usr/bin/ls 1 /usr/bin/clear ​Shell 命令的执行优先级为：绝对路径或相对路径执行的命令 &gt; 别名指定的命令 &gt; Shell 内部命令 &gt; hash 表中的命令 &gt; $PATH 环境变量中指示的路径按序查找到的第一个命令。 执行当前工作目录中的可执行文件 ​根据上面的结论可知，一般情况下，shell 是不会在当前工作目录搜索可执行文件的，因此我们可以通过指定当前可执行文件的绝对路径或相对路径来执行该命令，最简单方式自然是指定相对路径，linux 以 “.” 代表当前工作目录，因此执行当前工作目录下的命令 command 则可以通过以下方式（推荐）： 1[user@host ~]\\$ ./command # 其中 command 命令可执行文件的绝对路径为 /home/user/command 🔴 把 ./ 添加到环境变量 $PATH 中也可以实现输入命令名直接查找执行的效果，但是这种方式并不安全。 123[user@host ~]\\$ export $PATH=./:$PATH # 这种方式最不安全，如将公共目录中的病毒程序名字取为 ls ，任何用户在此工作目录中都会优先执行病毒程序[user@host ~]\\$ export $PATH=$PATH:./ # 如果一定要设置的话可以这样设置：如果自己的命令名和系统的一样的话会优先执行系统的，自己的命令并不执行[user@host ~]\\$ command # 配置好环境变量后执行上面的例子","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"二二年四月一日新交规记分","slug":"驾驶 | 二二年四月一日新交规记分","date":"2022-04-18T02:31:41.767Z","updated":"2022-04-18T04:42:00.651Z","comments":true,"path":"2022-04-18-驾驶 | 二二年四月一日新交规记分.html","link":"","permalink":"https://skinyi.github.io/2022-04-18-%E9%A9%BE%E9%A9%B6%20|%20%E4%BA%8C%E4%BA%8C%E5%B9%B4%E5%9B%9B%E6%9C%88%E4%B8%80%E6%97%A5%E6%96%B0%E4%BA%A4%E8%A7%84%E8%AE%B0%E5%88%86.html","excerpt":"","text":"引用来源 以下内容引用总结自从 2022 年 4 月 1 日起施行《道路交通安全违法行为记分管理办法》（公安部令第163号）。 记分规定 记十二分的相关情形 饮酒后驾驶机动车的； 造成致人轻伤以上或者死亡的交通事故后逃逸，尚不构成犯罪的； 使用伪造、变造的机动车号牌、行驶证、驾驶证、校车标牌或者使用其他机动车号牌、行驶证的； 驾驶校车、公路客运汽车、旅游客运汽车载人超过核定人数百分之二十以上，或者驾驶其他载客汽车载人超过核定人数百分之百以上的； 驾驶校车、中型以上载客载货汽车、危险物品运输车辆在高速公路、城市快速路上行驶超过规定时速百分之二十以上，或者驾驶其他机动车在高速公路、城市快速路上行驶超过规定时速百分之五十以上的； 驾驶机动车在高速公路、城市快速路上倒车、逆行、穿越中央分隔带掉头的； 代替实际机动车驾驶人接受交通违法行为处罚和记分牟取经济利益的。 记九分的相关情形 驾驶 7 座以上载客汽车载人超过核定人数百分之五十以上未达到百分之百的； 驾驶校车、中型以上载客载货汽车、危险物品运输车辆在高速公路、城市快速路以外的道路上行驶超过规定时速百分之五十以上的； 驾驶机动车在高速公路或者城市快速路上违法停车的； 驾驶未悬挂机动车号牌或者故意遮挡、污损机动车号牌的机动车上道路行驶的； 驾驶与准驾车型不符的机动车的； 未取得校车驾驶资格驾驶校车的； 连续驾驶中型以上载客汽车、危险物品运输车辆超过 4 小时未停车休息或者停车休息时间少于 20 分钟的。 记六分的相关情形 驾驶校车、公路客运汽车、旅游客运汽车载人超过核定人数未达到百分之二十，或者驾驶 7 座以上载客汽车载人超过核定人数百分之二十以上未达到百分之五十，或者驾驶其他载客汽车载人超过核定人数百分之五十以上未达到百分之百的； 驾驶校车、中型以上载客载货汽车、危险物品运输车辆在高速公路、城市快速路上行驶超过规定时速未达到百分之二十，或者在高速公路、城市快速路以外的道路上行驶超过规定时速百分之二十以上未达到百分之五十的； 驾驶校车、中型以上载客载货汽车、危险物品运输车辆以外的机动车在高速公路、城市快速路上行驶超过规定时速百分之二十以上未达到百分之五十，或者在高速公路、城市快速路以外的道路上行驶超过规定时速百分之五十以上的； 驾驶载货汽车载物超过最大允许总质量百分之五十以上的； 驾驶机动车载运爆炸物品、易燃易爆化学物品以及剧毒、放射性等危险物品，未按指定的时间、路线、速度行驶或者未悬挂警示标志并采取必要的安全措施的； 驾驶机动车运载超限的不可解体的物品，未按指定的时间、路线、速度行驶或者未悬挂警示标志的； 驾驶机动车运输危险化学品，未经批准进入危险化学品运输车辆限制通行的区域的； 驾驶机动车不按交通信号灯指示通行的； 机动车驾驶证被暂扣或者扣留期间驾驶机动车的； 造成致人轻微伤或者财产损失的交通事故后逃逸，尚不构成犯罪的； 驾驶机动车在高速公路或者城市快速路上违法占用应急车道行驶的。 记三分的相关情形 驾驶校车、公路客运汽车、旅游客运汽车、7 座以上载客汽车以外的其他载客汽车载人超过核定人数百分之二十以上未达到百分之五十的； 驾驶校车、中型以上载客载货汽车、危险物品运输车辆以外的机动车在高速公路、城市快速路以外的道路上行驶超过规定时速百分之二十以上未达到百分之五十的； 驾驶机动车在高速公路或者城市快速路上不按规定车道行驶的； 驾驶机动车不按规定超车、让行，或者在高速公路、城市快速路以外的道路上逆行的； 驾驶机动车遇前方机动车停车排队或者缓慢行驶时，借道超车或者占用对面车道、穿插等候车辆的； 驾驶机动车有拨打、接听手持电话等妨碍安全驾驶的行为的； 驾驶机动车行经人行横道不按规定减速、停车、避让行人的； 驾驶机动车不按规定避让校车的； 驾驶载货汽车载物超过最大允许总质量百分之三十以上未达到百分之五十的，或者违反规定载客的； 驾驶不按规定安装机动车号牌的机动车上道路行驶的； 在道路上车辆发生故障、事故停车后，不按规定使用灯光或者设置警告标志的； 驾驶未按规定定期进行安全技术检验的公路客运汽车、旅游客运汽车、危险物品运输车辆上道路行驶； 驾驶校车上道路行驶前，未对校车车况是否符合安全技术要求进行检查，或者驾驶存在安全隐患的校车上道路行驶的； 连续驾驶载货汽车超过 4 小时未停车休息或者停车休息时间少于 20 分钟的； 驾驶机动车在高速公路上行驶低于规定最低时速的。 记一分的相关情形 驾驶校车、中型以上载客载货汽车、危险物品运输车辆在高速公路、城市快速路以外的道路上行驶超过规定时速百分之十以上未达到百分之二十的； 驾驶机动车不按规定会车，或者在高速公路、城市快速路以外的道路上不按规定倒车、掉头的； 驾驶机动车不按规定使用灯光的； 驾驶机动车违反禁令标志、禁止标线指示的； 驾驶机动车载货长度、宽度、高度超过规定的； 驾驶载货汽车载物超过最大允许总质量未达到百分之三十的； 驾驶未按规定定期进行安全技术检验的公路客运汽车、旅游客运汽车、危险物品运输车辆以外的机动车上道路行驶的； 驾驶擅自改变已登记的结构、构造或者特征的载货汽车上道路行驶的； 驾驶机动车在道路上行驶时，机动车驾驶人未按规定系安全带的； 驾驶摩托车，不戴安全头盔的。 记分对照记忆表 超员 以下车型分类统一归类为以下简称： 大车：校车、公路客运汽车、旅游客运汽车； 中车：7 座以上载客汽车； 小车：除了以上类别的其他载客机动车。 车型\\程度 20% 以下 20% 到 50% 50% 到 100% 100% 以上 大车 6 12 12 12 中车 6 9 12 小车 3 6 12 超速 表格中标黑的表示在高速、城市快速路上行驶的情形，未标黑表示在普通公路上行驶的情形。以下车型分类统一归类为以下简称： 大车：校车、中型以上载客载货汽车、危险物品运输车辆； 小车：除了以上类别的其他载客机动车。 车型\\程度 10% 到 20% 20% 到 50% 50% 到 100% 100% 以上 大车 1，6 6，12 9，12 9，12 小车 3，6 6，12 6，12 超重 车型\\程度 30% 以下 30% 到 50% 50% 以上 载货汽车 1 3 6","categories":[{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"生活","slug":"生活","permalink":"https://skinyi.github.io/categories/%E7%94%9F%E6%B4%BB/"},{"name":"驾驶","slug":"生活/驾驶","permalink":"https://skinyi.github.io/categories/%E7%94%9F%E6%B4%BB/%E9%A9%BE%E9%A9%B6/"}],"tags":[{"name":"记分","slug":"记分","permalink":"https://skinyi.github.io/tags/%E8%AE%B0%E5%88%86/"},{"name":"驾照","slug":"驾照","permalink":"https://skinyi.github.io/tags/%E9%A9%BE%E7%85%A7/"},{"name":"开车","slug":"开车","permalink":"https://skinyi.github.io/tags/%E5%BC%80%E8%BD%A6/"},{"name":"法律法规","slug":"法律法规","permalink":"https://skinyi.github.io/tags/%E6%B3%95%E5%BE%8B%E6%B3%95%E8%A7%84/"}]},{"title":"重学 Shell 编程之 Linux 三剑客","slug":"Shell | 重学 Shell 编程之 Linux 三剑客","date":"2022-04-07T06:08:05.796Z","updated":"2022-06-09T01:35:34.635Z","comments":true,"path":"2022-04-07-Shell | 重学 Shell 编程之 Linux 三剑客.html","link":"","permalink":"https://skinyi.github.io/2022-04-07-Shell%20|%20%E9%87%8D%E5%AD%A6%20Shell%20%E7%BC%96%E7%A8%8B%E4%B9%8B%20Linux%20%E4%B8%89%E5%89%91%E5%AE%A2.html","excerpt":"","text":"正则表达式 RegExp 一个在线图形化解释正则表达式的工具网站。支持正则表达式的 linux 命令主要有：grep、sed、awk、find、expr等。正则表达式一般以一系列格式控制字符来匹配具有特定规律和意义的字符串，如电话号码、电子邮件地址等。 正则语法速查表： 符号 支持的语法 描述 归类 开始、结束匹配控制 ^ Basic RegExp 表示以它后面的表达式开头才匹配 $ Basic RegExp 表示以它前面的表达式结尾才匹配 归类 一些特殊字符的意义 . Basic RegExp 表示匹配任意一个字符（不匹配 \\n、\\r） ? Extended RegExp 表示起一个表达式匹配零次或一次 * Basic RegExp 表示前一个表达式匹配零次或多次 + Extended RegExp 表示前一个表达式匹配一次或多次 | Extended RegExp 表示在其分隔的两个表达式之间进行选择 \\ 表示将下个字符进行转义 () Extended RegExp 标记一个子表达式的开始和结束 [] Basic RegExp 标记一个中括号表达式的开始和结束 {} Extended RegExp 标记限定符表达式的开始和结束 归类 Basic RegExp 除 * + ? 的限定符，n 取非负整数 {n} Extended RegExp 表示精确匹配 n 次 {n,} Extended RegExp 表示最少匹配 n 次 {n,m} Extended RegExp n&lt;m，表示匹配 n 到 m 次 归类 [] 限定的普通字符 [anychars] Basic RegExp 表示匹配其中列举的任一字符 [^anychars] Basic RegExp 表示匹配除了其中列举的任意字符 [A-Z] Basic RegExp 表示匹配所有大写字母中的一个 归类 常见转义字符 \\s\\S Basic RegExp \\s 匹配所有空白字符、\\S 匹配所有非空白字符 \\w Basic RegExp 相当于 [A-Za-z0-9]，匹配大写字母、小写字母或 0 到 9 中的一个 \\d Basic RegExp 匹配 0 到 9 中的一个数 \\t Basic RegExp 匹配一个制表符 \\v Basic RegExp 匹配一个垂直制表符 \\r Basic RegExp 匹配一个回车符 \\f Basic RegExp 匹配一个换页符 * 和 + 限定符都是贪婪的，即会尽可能多的匹配字符（最长子串），在它们后面加上 ？限定符并指定使用 Perl 正则模式实现非贪婪或最小字串匹配。 特殊符号要匹配本身，需进行转义。 使用 grep + 正则查找文件内容 1234567891011121314151617grep, egrep, fgrep - 打印匹配给定模式的行# 用法格式grep [options] PATTERN [FILE...]grep [options] [-e PATTERN | -f FILE] [FILE...]# 常见选项-A NUM, --after-context=NUM # 打印出匹配的行之后的下文 NUM 行 -B NUM, --before-context=NUM # 打印出匹配的行之前的上文 NUM 行-C NUM, --context=NUM # 打印除匹配行之前和之后的上下文 NUM 行-c NUM, --count # 打印出匹配的数量而不是匹配的内容，配合 -v 为不匹配的数量-E, --extended-regexp # 使用拓展正则进行解释匹配-P, --perl-regexp # 使用 perl 正则进行解释匹配-o, --only-matching # 只显示匹配中的行中与模式相匹配的部分-v, --invert-match # 只选择不匹配的行（反选）-w, --word-regexp # 只选择含有能组成完整的词的匹配的行。判断方法是匹配的子字符串必须是一行的开始，# 或者是在一个不可能是词的组成的字符之后。与此相似，它必须是一行的结束，或者是# 在一个不可能是词的组成的字符之前。词的组成字符是字母，数字，还有下划线。 🟢grep 默认支持 Basic RegExp 语法，可以通过传递选项 -E 以支持扩展正则表达式语法（相当于 egrep 命令）或 -P 以支持 Perl 语言的正则表达式语法。 123456789101112131415# 测试文件内容[skinyi@fedora ~]$ cat -n lyrics.txt 1 Fly me to the moon 2 3 Fly me to the mo0n 4 And let me play @mong the stars 5 (I want you)Let me see what Spring is like 0n Jupiter and Mars 6 In other words,hold my hand 7 _In other words,darling,kiss me 8 Fill m9 heart with song 9 And 1et me sing forever more10 (Because)You are all I long for All I worship and adOre11 in other words,please be true12 in other words,I love you13 12345678910111213# 过滤空行 -v 反选 -n 输出行号[skinyi@fedora ~]$ grep -nv &#x27;^$&#x27; lyrics.txt 1:Fly me to the moon3:Fly me to the mo0n4:And let me play @mong the stars5:(I want you)Let me see what Spring is like 0n Jupiter and Mars6:In other words,hold my hand7:_In other words,darling,kiss me8:Fill m9 heart with song9:And 1et me sing forever more10:(Because)You are all I long for All I worship and adOre11:in other words,please be true12:in other words,I love you 12345678910111213# 去掉以某个字符开头的行（常用来去注释）[skinyi@fedora ~]$ grep -nv &#x27;^(&#x27; lyrics.txt 1:Fly me to the moon2:3:Fly me to the mo0n4:And let me play @mong the stars6:In other words,hold my hand7:_In other words,darling,kiss me8:Fill m9 heart with song9:And 1et me sing forever more11:in other words,please be true12:in other words,I love you13: 1234567# 匹配以 i 开头，e 结尾的最短子串，-P 指定使用 perl 语言的正则语法，支持非贪婪写法[skinyi@fedora ~]$ egrep -no &#x27;^i.+?e&#x27; lyrics.txt # 不能达到目的 11:in other words,please be true12:in other words,I love[skinyi@fedora ~]$ grep -no -P &#x27;^i.+?e&#x27; lyrics.txt # 可达到目的 11:in othe12:in othe 使用 sed 命令流式的处理文本文件 sed -r 支持扩展正则。Sed是一个流式编辑器。流式编辑器是用来在输入流（一个文件或者管道输入）中完成基本文本转换的工具。 sed 命令会根据脚本命令来处理文本文件中的数据，这些命令要么从命令行中输入，要么存储在一个文本文件中，此命令的执行过程如下： 每次读取一行内容； 根据提供的规则命令匹配并修改数据。注意，sed 默认不会直接修改源文件数据，而是会将数据复制到缓冲区中，修改也仅限于缓冲区中的数据； 将执行结果输出； 当一行数据匹配完成后，它会继续读取下一行数据，并重复 1-3 的过程，直到将文件中所有行的数据处理完毕。 123456789sed - 文本筛选和格式转换的流式编辑器# 用法格式sed [选项]... &#123;脚本（若没有其他脚本）&#125; [输入文件]...# 常见选项-e 脚本, --expression=脚本 # 添加 脚本 到程序的处理工作流列表-f 脚本文件, --file=脚本文件 # 添加 脚本文件 到程序的处理工作流列表-i [扩展名], --in-place[=扩展名] # 直接修改文件（如果指定拓展名则备份文件）-E, -r, --regexp-extended # 在脚本模式中使用拓展正则-n, --quiet, --silent # 取消自动打印模式空间 12345678910111213141516171819# 测试文本[skinyi@fedora ~]$ cat -n lyrics.txt 1 My whole world changed from the moment I met you 2 And it would never be the same 3 Felt like I knew that I always loved you 4 From the moment I heard your name 5 6 Everything was perfect, I knew this love was worth it 7 Our own miracle in the making 8 And till this world stops turning 9 I’ll still be here waiting and waiting to make that vow that I’ll... 10 11 I’ll be by your side 12 Till the day I die 13 I’ll be waiting till I hear you say I do 14 Something old, something new 15 Something borrowed, something blue 16 I’ll be waiting till I hear you say I do 17 打印内容 sed 命令实现文件内容打印采用的基本格式为：[address][/&#123;front-&#125;pattern/,/&#123;back-pattern/&#125;]p。其中 address 表示指定要操作的具体行，2 条斜线内实现指定模式内容的打印，3 条斜线分隔且包围的可指定一定范围的内容的查找（若后模式无法匹配则会一直打印到文件末尾）。 123456# 查找 met 和 name 之间的内容[skinyi@fedora ~]$ sed -nr &#x27;/\\smet\\s/,/\\sname\\s?/p&#x27; lyrics.txt My whole world changed from the moment I met youAnd it would never be the sameFelt like I knew that I always loved youFrom the moment I heard your name 1234567# 不显示空行和以 I 开头的行，常用来进行配置文件的过滤（I 替为 #）[skinyi@fedora ~]$ sed -nr &#x27;/^$|I/!p&#x27; lyrics.txt And it would never be the sameOur own miracle in the makingAnd till this world stops turningSomething old, something newSomething borrowed, something blue 🔴注意：! 代表执行反操作，比如 !p 代表匹配的内容不打印（不匹配的打印），!d 代表匹配的内容不删除（不匹配的删除）。 查找并替换 sed 命令实现文件内容查找并替换采用的基本格式为：[address]s/pattern/replacement/flags。其中： address 表示指定要操作的具体行； pattern 指的是需要替换的内容； replacement 指的是要替换的新内容； flags 用来实现一些特定功能。 flags 标记 功能 n n 为 1~512 之间的数字，表示指定要替换的字符串出现第几次时才进行替换，例如，一行中有 3 个 A，但用户只想替换第二个 A，这是就用到这个标记 g 对数据中所有匹配到的内容进行替换，如果没有 g，则只会在第一次匹配成功时做替换操作。例如，一行数据中有 3 个 A，则只会替换第一个 A p 会打印与替换命令中指定的模式匹配的行。此标记通常与 -n 选项一起使用 w file 将缓冲区中的内容写到指定的 file 文件中 &amp; 用正则表达式匹配的内容进行替换 \\n 匹配第 n 个子串，该子串之前在 pattern 中用 () 指定 \\ 转义（转义替换部分包含：&amp;、\\ 等） 12345678910# 将所有出现的 do 替换为 will（不修改源文件）并比较[skinyi@fedora ~]$ sed &#x27;s/do/will/g&#x27; lyrics.txt | colordiff lyrics.txt -13c13&lt; I’ll be waiting till I hear you say I do---&gt; I’ll be waiting till I hear you say I will16c16&lt; I’ll be waiting till I hear you say I do---&gt; I’ll be waiting till I hear you say I will 123# 将第 4 行的 heard 改为 knew 并仅输出修改的行（不修改源文件）[skinyi@fedora ~]$ sed -n &#x27;4s/heard/knew/p&#x27; lyrics.txtFrom the moment I knew your name 123# 将第 13 行的第三个 I 改为 we 并仅输出修改的行（不修改源文件）[skinyi@fedora ~]$ sed -n &#x27;13s/I/we/3p&#x27; lyrics.txtI’ll be waiting till I hear you say we do 🔵注意：匹配模式字符串包含 / 时需要进行转义。 案例：仅打印网卡 ens160 的 ip 12[skinyi@fedora gh-pages]$ ip addr show ens160 | sed -nr &#x27;4s#(^.*t )(.*)(/.*$)#\\2#gp&#x27; # \\2 表示第二组192.168.30.128 删除文件中的特定行（单行或连续行） sed 命令实现删除文件中的特定行的基本格式为：[address]d，其中 address 表示指定要操作的具体行，当不指定地址时代表删除所有行。 以下例子还是以上述 lyrics.txt 文件为范例。 123# 删除所有行（仅在缓冲区）[skinyi@fedora ~]$ sed &#x27;d&#x27; lyrics.txt[skinyi@fedora ~]$ 1234# 删除第 12 行（仅在缓冲区）[skinyi@fedora ~]$ sed &#x27;12d&#x27; lyrics.txt | cdiff lyrics.txt - # alias cdiff=&#x27;colordiff&#x27;，下同12d11&lt; Till the day I die 123456# 删除第 11 到 13 行（仅在缓冲区）[skinyi@fedora ~]$ sed &#x27;11,13d&#x27; lyrics.txt | cdiff lyrics.txt -11,13d10&lt; I’ll be by your side&lt; Till the day I die&lt; I’ll be waiting till I hear you say I do 1234567891011# 删除第 10 行到最后一行（仅在缓冲区）[skinyi@fedora ~]$ sed &#x27;10,$d&#x27; lyrics.txt | cdiff lyrics.txt - # $代表最后一行的行号10,17d9&lt; &lt; I’ll be by your side&lt; Till the day I die&lt; I’ll be waiting till I hear you say I do&lt; Something old, something new&lt; Something borrowed, something blue&lt; I’ll be waiting till I hear you say I do&lt; 增加内容（以行为单位） sed 命令实现文件中增加特定内容行的基本格式为：sed [address]&#123;a|n&#125;\\new_content，其中 a 代表向指定位置后面插入内容、i 代表向指定位置前面插入内容、address 表示指定要操作的具体行，不指定则在每行前面或后面添加内容。 123456789101112# 给每行后面添加 ----------------------------------------------------（仅在缓冲区），并查看前 10 行[skinyi@fedora ~]$ sed &#x27;a\\-------------------------------------------------&#x27; lyrics.txt | head -10My whole world changed from the moment I met you-------------------------------------------------And it would never be the same-------------------------------------------------Felt like I knew that I always loved you-------------------------------------------------From the moment I heard your name-------------------------------------------------------------------------------------------------- 1234567# 给第 1 行前增加 911 - I Do（仅在缓冲区），并查看前 5 行[skinyi@fedora ~]$ sed &#x27;1i\\911 - I Do&#x27; lyrics.txt | head -5911 - I DoMy whole world changed from the moment I met youAnd it would never be the sameFelt like I knew that I always loved youFrom the moment I heard your name 1234567# 添加多行可以使用 \\n 转义字符，效果如下：[skinyi@fedora ~]$ sed &#x27;1i\\I Do\\n911&#x27; lyrics.txt | head -5I Do911My whole world changed from the moment I met youAnd it would never be the sameFelt like I knew that I always loved you 替换整行 sed 命令实现文件中替换某行的内容的基本格式为：sed [address]c\\new_content，其中 address 表示指定要操作的具体行，不指定则会将每行的内容都替换成新行。 12345# 更改首行内容为 Your partial heart got broken from the moment you left me（仅在缓冲区）并查看前三行[skinyi@fedora ~]$ sed &#x27;1c\\Your partial heart got broken from the moment you left me&#x27; lyrics.txt | head -3Your partial heart got broken from the moment you left meAnd it would never be the sameFelt like I knew that I always loved you 使用 awk 实现文本扫描处理 AWK 是一门实现文本扫描与处理的编程语言，常用来实现文本过滤、统计、计算等。awk 将文本文件按照指定（或默认）的分隔符抽象成一个不太严格的表格（每列不一定等长），继而实现对文本的精确处理，awk 抽象和表格的对应关系如下： 表格概念 awk 中的概念 awk 默认分隔符 awk 内置变量及作用 行 Row 记录 Record 换行 \\n NR 指定记录号 列 Column 字段 Feild 空白字符 \\s NF 获取列数 12345678# 用法格式awk - 模式扫描处理工具awk [ options ] -f program-file [ - ] file ...awk [ options ] [ - ] program-text file ...## awk 程序中的 BEGIN&#123;&#125;、END&#123;&#125; 分别控制读取文件之前和读取文件结束的过程。# 常见选项-v var=new_var # 修改 awk 内置变量的取值，如：-v OFS=:（打印字段时以冒号分隔）-F fs, --field-separator fs # 指定 fs 作为每列的分隔符，相当于 -v FS=fs。 用法示例 123456789101112# 打印 1 到 3 行的内容[skinyi@fedora ~]$ awk &#x27;NR==1,NR==3 &#123;print&#125;&#x27; lyrics.txt My whole world changed from the moment I met youAnd it would never be the sameFelt like I knew that I always loved you# 打印 2 和 6 行的内容[skinyi@fedora ~]$ awk &#x27;NR==2 || NR==6 &#123;print&#125;&#x27; lyrics.txt And it would never be the sameEverything was perfect, I knew this love was worth it# 打印以 Everything 开头的行[skinyi@fedora ~]$ awk &#x27;/^Everything/&#123;print&#125;&#x27; lyrics.txt Everything was perfect, I knew this love was worth it","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"Shell","slug":"学习/Shell","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Shell/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://skinyi.github.io/tags/Shell/"},{"name":"Bash","slug":"Bash","permalink":"https://skinyi.github.io/tags/Bash/"},{"name":"脚本编程","slug":"脚本编程","permalink":"https://skinyi.github.io/tags/%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/"}]},{"title":"重学 Shell 编程之基础回顾（三）","slug":"Shell | 重学 Shell 编程之基础回顾（三）","date":"2022-04-01T06:40:56.259Z","updated":"2022-04-07T05:59:22.604Z","comments":true,"path":"2022-04-01-Shell | 重学 Shell 编程之基础回顾（三）.html","link":"","permalink":"https://skinyi.github.io/2022-04-01-Shell%20|%20%E9%87%8D%E5%AD%A6%20Shell%20%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%9F%BA%E7%A1%80%E5%9B%9E%E9%A1%BE%EF%BC%88%E4%B8%89%EF%BC%89.html","excerpt":"","text":"Shell 条件测试 条件测试只会得到真与假两种结果，常与 if 判断语句结合进行具有一定复杂逻辑的工作。以下是 shell 条件测试中一些比较常用的语法： 条件测试返回 0 时表示真，返回其他非 0 值时表示假，跟其他编程语言不一致！ 语法 描述 test &lt;测试表达式&gt; 利用 test 命令进行条件测试，注意 test 命令和参数之间存在空格 [ &lt;测试表达式&gt; ] 推荐。等价于上条语法，注意左右中括号和表达式之间存在空格 [[ &lt;测试表达式&gt; ]] 扩展语法，较新，部分解释器可能不支持，注意左右双中括号和表达式之间存在空格 ((&lt;测试表达式&gt;)) 一般用于 if 语句，左右双小括号和表达式之间可以不存在空格 test &lt;测试表达式&gt; 和 [ &lt;测试表达式&gt; ] 语法 这两种语法需要记忆一些涉及文件、逻辑判断使用的特殊选项符号，将其整理如下： 文件测试语法 文件测试语法 描述 归类 文件存在、类型判断 -e pathname 当由 pathname 指定的文件或目录存在时返回真 -s filename 当 filename 存在并且文件大小大于 0 时返回真 -f filename 当 filename 存在并且是常规文件时返回真 -d pathname 当 pathname 存在并且是一个目录时返回真 -b filename 当 filename 存在并且是块文件时返回真 -c filename 当 filename 存在并且是字符文件时返回真 -S filename 当 filename 存在并且是 socket 时返回真 -p filename 当 filename 存在并且是命名管道时返回真 -h filename 当 filename 存在并且是符号链接文件时返回真 (或 -L filename) -t fd 当 fd 是与终端设备相关联的文件描述符时返回真 归类 文件权限位判断 -r pathname 当由 pathname 指定的文件或目录存在并且可读时返回真 -w pathname 当由 pathname 指定的文件或目录存在并且可写时返回真 -x pathname 当由 pathname 指定的文件或目录存在并且可执行时返回真 -u pathname 当由 pathname 指定的文件或目录存在并且设置了 SUID 位时返回真 -g pathname 当由 pathname 指定的文件或目录存在并且设置了 SGID 位时返回真 -k pathname 当由 pathname 指定的文件或目录存在并且设置了&quot;粘滞&quot;位时返回真 -O pathname 当由 pathname 存在并且被当前进程的有效用户 id 的用户拥有时返回真(字母 O 大写) -G pathname 当由 pathname 存在并且属于当前进程的有效用户 id 的用户的用户组时返回真 归类 两个文件的比较 file1 -nt file2 file1 比 file2 新时返回真 file1 -ot file2 file1 比 file2 旧时返回真 file1 -ef file2 file1 和 file2 是同一个文件的硬链接时返回真 逻辑测试语法 逻辑测试语法 描述 -a 逻辑与，操作符两边均为真，结果为真，否则为假。 -o 逻辑非，操作符两边一边为真，结果为真，否则为假。 ! 取非，条件为假，结果为真。 常见字符串测试语法 常见字符串测试语法 描述 -z string 字符串 string 为空串(长度为0)时返回真 -n string 字符串 string 为非空串时返回真 str1 = str2 字符串 str1 和字符串 str2 相等时返回真 str1 == str2 同 = str1 != str2 字符串 str1 和字符串 str2 不相等时返回真 str1 &lt; str2 按字典顺序排序，字符串 str1 在字符串 str2 之前 str1 &gt; str2 按字典顺序排序，字符串 str1 在字符串 str2 之后 常见数值测试语法 常见数值测试语法 描述 int1 -eq int2 如果 int1 等于 int2，则返回真 int1 -ne int2 如果 int1 不等于 int2，则返回真 int1 -lt int2 如果 int1 小于 int2，则返回真 int1 -le int2 如果 int1 小于等于 int2，则返回真 int1 -gt int2 如果 int1 大于 int2，则返回真 int1 -ge int2 如果 int1 大于等于 int2，则返回真 单中括号语法引用变量除了要使用 $ 符号还需要用引号将变量括起来。 [[ &lt;测试表达式&gt; ]] 语法 大部分情形下，双中括号语法与 test 和单中括号语法通用，但是仍存在以下区别： 逻辑测试 [[ &lt;测试表达式&gt; ]] 语法中使用 &amp;&amp;、|| 表示逻辑与和逻辑非，但在 [ &lt;测试表达式&gt; ] 语法中使用 -a 和 -o 运算符。 通配符和正则 [[ &lt;测试表达式&gt; ]] 语法中支持使用通配符和正则表达式。 字符串 [[ &lt;测试表达式&gt; ]] 语法中匹配字符串或通配符不需要引号括起来。 ((&lt;测试表达式&gt;)) 语法 ((&lt;测试表达式&gt;)) 只支持算术运算比较。 案例：判断磁盘是否挂载且挂载点对当前用户是否可读可写 check_disk.sh123456789#!/bin/shdev_name=&quot;sdb1&quot;dev_path=&quot;/dev/$dev_name&quot;mnt_path=&quot;/mnt/data&quot;if [ -b &quot;$dev_path&quot; -a -r &quot;$mnt_path&quot; -a -w &quot;$mnt_path&quot; ]; then echo &quot;磁盘 $dev_path 已挂载且当前用户可读写！&quot;else echo &quot;磁盘未挂载或对当前用户不可读或不可写！&quot;fi Shell 分支语句结构 if 判断语句 if 语句支持单分支和多分支选择结构，单/双分支语句的一般格式是： 12345if 条件; then 条件为真执行的语句else 条件为假执行的语句 # 单分支时不用 else 的部分fi 对于多分支： 123456789if 条件1; then 条件1成立时执行的语句elif 条件2; then 条件2成立时执行的语句elif 条件n; then 条件n成立时执行的语句else 以上条件都不成立时执行的语句fi 与其他编程语言类似，条件判断语句中可以使用 break 关键字进行跳出。 案例：编写脚本监测可用剩余内存并发邮件报警 要求： 当内存可用大小小于 100m 时发邮件进行报警； 将脚本加入 crontab 任务，定时每 30 分钟执行一次。 check_mem.sh123456#!/bin/shmem_free=`free -m|awk &#x27;NR==2 &#123;print $NF&#125;&#x27;`if test $mem_free -lt &#x27;100&#x27;; then local msg=&quot;当前可用内存为 $&#123;mem_free&#125;m，已不足 100m！&quot; echo msg | mail -s &#x27;服务器内存告警&#x27; user@mailsrv.comfi 执行 crontab -e，写入定时任务： 1* /30 * * * * /bin/bash /path/to/scripts/check_mem.sh case in 判断语句 Case in 语句一般用于多分支且判断条件较简单的分支语句结构。Case in 语句的一般格式是： 12345678910111213case 表达式 in 匹配模式1) 匹配模式1成立时执行的语句 ;; 匹配模式2) 匹配模式2成立时执行的语句 ;; 匹配模式n) 匹配模式n成立时执行的语句 ;; *) 其他匹配模式都不成立时执行的语句esac 其中，表达式既可以是一个变量、一个数字、一个字符串，还可以是一个数学计算表达式，或者是命令的执行结果，只要能够得到表达式的值就可以；匹配模式可以是一个数字、一个字符串，甚至是一个简单的正则表达式；;; 的作用相当于其他编程语言的 case 语句中的 break；*) 的作用相当于其他编程语言的 case 语句中的 default。 案例：模拟实现服务启停、重启、查询的管理脚本 service.sh12345678910111213141516171819#!/bin/shcase $1 in start) echo &quot;服务启动成功！&quot; ;; stop) echo &quot;服务停止成功！&quot; ;; restart) echo &quot;重启服务成功！&quot; ;; status) echo &quot;呃。。。。。。&quot; ;; *) echo &quot;Usage: $0 &#123;start|stop|restart|status&#125;&quot; exit 1esacexit 0 Shell 循环语句结构 for 循环 12345# list 是一个列表，可以是数字或字符串序列，元素之间用空格隔开for $variable in &#123;list&#125; # 或 &#123;start..end..step&#125;，如 &#123;1..100..2&#125;表示从1都100，每次自增 2 do do_something...done 类似 C 语言： 1234for (( expression1;expression2;expression3 ))do do_something...done 例子： 123456789101112131415161718192021# 循环列表for i in 1 2 3 4 5 6 7 8do echo $idone# 循环序列，自定义步长for i in &#123;1..10..2&#125;do echo $idone# 类似 C 语言for (( i=1;i&lt;10;++i ))do echo $idone# 遍历数组array=(1 2 3 4 5) # 定义数组for i in $&#123;array[*]&#125;do echo $idone while 循环 1234while [表达式]do do_something...done until 循环 1234until [表达式]do do_something...done 循环结构也可以使用 break,continue 关键字进行逻辑控制。 函数 基本格式： 12345678910111213141516171819# 定义函数，function、return 关键字可省略 ## 标准写法function func_name()&#123; do_something... return ret_val&#125;## 省略花括号function func_name( do_something... return ret_val)## 一般写法func_name()&#123; do_something... retuen ret_val&#125;# 调用函数，其中 arg1 arg2 ... argN 都是参数func_name arg1 arg2 ... argN# 必须先定义再调用 在日常工作中，一把将 shell 的函数定义和函数调用分布在两个脚本文件中，此行为有点类似 C 语言编程中设置头文件的行为，其初衷是模块化编程。 def_func.sh1234function my_func()&#123; echo &quot;单独定义的函数。&quot; return 0&#125; 调用独立定义的函数： exec_func.sh123456#!/bin/shfunc_path=&quot;/path/to/def_func.sh&quot;# 判断函数文件是否存在[ -f func_path ] &amp;&amp; . func_path || &#123;echo &quot;找不到文件：$func_path&quot; 2&gt;&amp;1; exit 1&#125;# 调用函数my_func 函数内部也有一些特殊变量，可进行传递的参数等的处理，可参考调用 shell 脚本时内部的特殊变量，脚本的特殊变量不会被函数内部自动继承，需要层层传递。 调试 shell 脚本 利用 bash -x 显示脚本执行过程 12345678910111213141516171819202122232425[skinyi@fedora ~]$ bash -x check_website_status.sh baidu.com+ req_url=+ req_timeout=5+ req_fails=0+ req_alert_fails=10+ req_wait_time=1+ check_parameters baidu.com+ &#x27;[&#x27; 1 -ne 1 &#x27;]&#x27;+ req_url=baidu.com+ check_status+ true+ curl --head --connect-timeout 5 -s -f baidu.com -o /dev/null+ &#x27;[&#x27; 0 -ne 0 &#x27;]&#x27;++ date --rfc-3339=seconds+ local &#x27;date=2022-04-07 13:43:55+08:00&#x27;+ echo &#x27;2022-04-07 13:43:55 时进行了一次成功的请求&#x27;2022-04-07 13:43:55 时进行了一次成功的请求+ sleep 1+ true+ curl --head --connect-timeout 5 -s -f baidu.com -o /dev/null+ &#x27;[&#x27; 0 -ne 0 &#x27;]&#x27;++ date --rfc-3339=seconds+ local &#x27;date=2022-04-07 13:43:56+08:00&#x27;+ echo &#x27;2022-04-07 13:43:56 时进行了一次成功的请求&#x27;2022-04-07 13:43:56 时进行了一次成功的请求 使用 set -x 和 set +x 包围要调试的代码块 1234567891011[skinyi@fedora ~]$ cat more_than_3.sh #!/bin/shstr_count=0for word in $@;do set -x if [ `expr length $word` -gt 3 ]; then let str_count+=1 fi set +xdoneecho &quot;大于 3 的拼音/单词个数为：$str_count&quot; 执行脚本： 1234567891011121314151617181920212223242526272829[skinyi@fedora ~]$ ./more_than_3.sh ni bu shi zhen zheng de kuai le++ expr length ni+ &#x27;[&#x27; 2 -gt 3 &#x27;]&#x27;+ set +x++ expr length bu+ &#x27;[&#x27; 2 -gt 3 &#x27;]&#x27;+ set +x++ expr length shi+ &#x27;[&#x27; 3 -gt 3 &#x27;]&#x27;+ set +x++ expr length zhen+ &#x27;[&#x27; 4 -gt 3 &#x27;]&#x27;+ let str_count+=1+ set +x++ expr length zheng+ &#x27;[&#x27; 5 -gt 3 &#x27;]&#x27;+ let str_count+=1+ set +x++ expr length de+ &#x27;[&#x27; 2 -gt 3 &#x27;]&#x27;+ set +x++ expr length kuai+ &#x27;[&#x27; 4 -gt 3 &#x27;]&#x27;+ let str_count+=1+ set +x++ expr length le+ &#x27;[&#x27; 2 -gt 3 &#x27;]&#x27;+ set +x大于 3 的拼音/单词个数为：3","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"Shell","slug":"学习/Shell","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Shell/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://skinyi.github.io/tags/Shell/"},{"name":"Bash","slug":"Bash","permalink":"https://skinyi.github.io/tags/Bash/"},{"name":"脚本编程","slug":"脚本编程","permalink":"https://skinyi.github.io/tags/%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/"}]},{"title":"重学 Shell 编程之基础回顾（二）","slug":"Shell | 重学 Shell 编程之基础回顾（二）","date":"2022-03-30T08:03:08.891Z","updated":"2022-04-07T02:26:16.026Z","comments":true,"path":"2022-03-30-Shell | 重学 Shell 编程之基础回顾（二）.html","link":"","permalink":"https://skinyi.github.io/2022-03-30-Shell%20|%20%E9%87%8D%E5%AD%A6%20Shell%20%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%9F%BA%E7%A1%80%E5%9B%9E%E9%A1%BE%EF%BC%88%E4%BA%8C%EF%BC%89.html","excerpt":"","text":"引用命令的结果 `command` $(command) 例： 1234[skinyi@fedora ~]$ echo &quot;当前日期是：`date`&quot;当前日期是：2022年 03月 31日 星期四 11:13:50 CST[skinyi@fedora ~]$ echo &quot;当前用户的 id 是：$(id -u)&quot;当前用户的 id 是：1000 Shell 运算符 Shell 和其它编程语言不同，Shell 不能直接进行算数运算，必须使用数学计算命令。以下是 Shell 中使用的算数运算符： Shell 算数运算符 意义（带 * 代表常用） +、- 加法（或正号）、减法（或负号） * *、/、% 乘法、除法、取余（取模） * ** 幂运算 * ++、-- 自增、自减 * !、&amp;&amp;、|| 逻辑非（取反）、逻辑与（and）、逻辑或（or） * &lt;、&lt;=、&gt;、&gt;= 小于、小于等于、大于、大于等于 ==、!=、= 相等、不等、对于字符串 = 也可表示相当于 * &lt;&lt;、&gt;&gt; 左移位、右移位 ~、|、&amp;、^ 按位取反、按位异或、按位与、按位或 =、+=、-=、*=、/=、%= 赋值运算符，a+=1 相当于 a=a+1，后面类推 * 要想让数学计算发挥作用，必须使用数学计算命令，Shell 中常用的数学计算命令如下表所示。 Shell 运算操作符与运算命令 意义 (()) 用于整数运算的常用运算符，效率很高 let 用于整数运算，类似于”(())“ expr 可用于整数运算，但还有很多其他的额外功能 bc Linux 下的一个计算器程序（适合整数及小数运算） $[] 用于整数运算 awk awk 既可以用于整数运算，也可以用于小数运算 declare 定义变量值和属性，-i 参数可以用于定义整型变量，做运算 (()) 运算符 用法示例： 123456789101112131415161718# 定义变量：[skinyi@fedora ~]$ i=1# 错误示例：[skinyi@fedora ~]$ i=((i+1));echo $ibash: 未预期的符号“(”附近有语法错误[skinyi@fedora ~]$ echo ((i+1))bash: 未预期的符号“(”附近有语法错误# 正确示例：[skinyi@fedora ~]$ i=$((i+1));echo $i2[skinyi@fedora ~]$ ((i=i+1));echo $i3[skinyi@fedora ~]$ i=$((i&gt;1));echo $i1[skinyi@fedora ~]$ ((i=i&gt;1));echo $i0[skinyi@fedora ~]$ echo $((i&lt;1))1 总结： 内部赋值（不直接引用）：((var=表达式))； 外部赋值（直接引用）：var=$((表达式))、echo $((表达式))。 let 指令 用法示例： 1234567891011121314# 正确示例：[skinyi@fedora ~]$ let num=1+1; echo $num2[skinyi@fedora ~]$ let num=num+2; echo $num4[skinyi@fedora ~]$ let num+=2; echo $num6# 错误示例：[skinyi@fedora ~]$ let num=2&gt;1; echo $num2 # 无法根据比较结果赋值[skinyi@fedora ~]$ let num**2; echo $num2 # 只能是以赋值的形式进行计算[skinyi@fedora ~]$ let num=$((2&gt;1)); echo $num1 # 仅用双括号就能实现效果，用 let 冗余 案例：监测网站服务的存活状态 以下示例展示了一个简单的网站服务存活检测的脚本，其原理是对网站定时发送 head 请求以确认网站服务可用，当请求失败次数达到一定次数后给当前系统用户发送邮件告知网站服务出了问题并退出脚本的执行。要想再严格些可以考虑认为一定周期内达到最大失败次数才认为网站挂了，还有在脚本传参时可以进行 url 格式的正则检查，当然这里只是个小案例，主要还是将之前学到的没学到的东西都用了一遍，加深记忆。 check_website_status.sh12345678910111213141516171819202122232425262728293031323334353637383940414243444546#!/bin/sh## Check web service statusreq_url=&#x27;&#x27; # 请求的网址 urlreq_timeout=&#x27;5&#x27; # 请求超时时间req_fails=&#x27;0&#x27; # 最大尝试请求次数req_alert_fails=&#x27;10&#x27; # 触发报警的最大尝试次数req_wait_time=&#x27;1&#x27; # 每次请求间隔时间check_parameters()&#123; if [ $# -ne 1 ]; then printf &quot;错误：未指定或指定了多个参数！\\n用法：$0 &lt;url&gt;\\n&quot; 2&gt;&amp;1 exit 1 else req_url=$1 fi&#125;send_mail_alert()&#123; if [ $req_fails -ge $req_alert_fails ]; then local mail_message=&quot;自脚本启动以来共发生了$&#123;req_fails&#125;次失败的请求，已达最大失败上限，请及时进行人工检查处理。\\n&quot; echo -e $mail_message | mail -s &quot;警告：你的网站服务可能已经不可用&quot; $USER exit 0 # 发送邮件后就退出，防止邮件轰炸 fi&#125;check_status()&#123; while true; do local date=`date --rfc-3339=seconds` # 使用 head 请求来进行网站是否存活检测 curl --head --connect-timeout $&#123;req_timeout&#125; -s -f $&#123;req_url&#125; -o /dev/null # 若命令返回非 0 则表明请求失败 if [ $? -ne 0 ]; then let req_fails+=1 # 请求失败次数自增 echo &quot;$&#123;date%+*&#125; 时进行了一次失败的请求&quot; send_mail_alert # 调用报警判断是否报警 else echo &quot;$&#123;date%+*&#125; 时进行了一次成功的请求&quot; fi # 每次请求间隔一段时间 sleep $req_wait_time done&#125;check_parameters $@ # 函数不会继承 shell 脚本的参数，调用时需进行传参check_status expr 命令 使用 expr --help 命令查看 expr 命令帮助信息。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546[skinyi@fedora ~]$ expr --help用法：expr 表达式 或：expr 选项 --help 显示此帮助信息并退出 --version 显示版本信息并退出将表达式的值列印到标准输出，分隔符下面的空行可提升算式优先级。可用的表达式有： ARG1 | ARG2 若ARG1 的值不为 0 或者为空，则返回 ARG1，否则返回 ARG2 ARG1 &amp; ARG2 若两边的值都不为 0 或为空，则返回 ARG1，否则返回 0 ARG1 &lt; ARG2 ARG1 小于 ARG2 ARG1 &lt;= ARG2 ARG1 小于或等于 ARG2 ARG1 = ARG2 ARG1 等于 ARG2 ARG1 != ARG2 ARG1 不等于 ARG2 ARG1 &gt;= ARG2 ARG1 大于或等于 ARG2 ARG1 &gt; ARG2 ARG1 大于 ARG2 ARG1 + ARG2 计算 ARG1 与 ARG2 相加之和 ARG1 - ARG2 计算 ARG1 与 ARG2 相减之差 ARG1 * ARG2 计算 ARG1 与 ARG2 相乘之积 ARG1 / ARG2 计算 ARG1 与 ARG2 相除之商 ARG1 % ARG2 计算 ARG1 与 ARG2 相除之余数 字符串 : 表达式 定位字符串中匹配表达式的模式 match 字符串 表达式 等于&quot;字符串 : 表达式&quot; substr 字符串 偏移量 长度 替换字符串的子串，偏移的数值从 1 起计 index 字符串 字符 在字符串中发现字符的地方建立下标，或者标0 length 字符串 字符串的长度 + 记号 将给定记号解析为字符串，即使它是一个类似 “match”或运算符&quot;/&quot;那样的关键字 ( 表达式 ) 给定&lt;表达式&gt;的值请注意有许多运算操作符都可能需要由 shell 先实施转义。如果参与运算的 ARG 自变量都是数字，比较符就会被视作数学符号，否则就是多义的。模式匹配会返回&quot;\\&quot;和&quot;\\&quot;之间被匹配的子字符串或空(null)；如果未使用&quot;\\&quot;和&quot;\\&quot;，则会返回匹配字符数量或是 0。若表达式的值既不是空也不是 0，退出状态值为 0；若表达式的值为空或为 0，退出状态值为 1。如果表达式的句法无效，则会在出错时返回退出状态值 3。 用法示例： 123456789101112131415161718192021222324252627# 使用时最好都进行转义防止与 shell 特殊含义符号冲突[skinyi@fedora ~]$ expr 1 + 34[skinyi@fedora ~]$ expr 2 \\* 36[skinyi@fedora ~]$ expr 2 * 3expr: 语法错误：未预期的参数[skinyi@fedora ~]$ expr 2 \\+ 57# expr match 模式匹配，输出匹配字符个数[skinyi@fedora ~]$ expr .bashrc.d \\: &quot;.*&quot;9[skinyi@fedora ~]$ expr match .bashrc.d &quot;.*\\.d&quot;9[skinyi@fedora ~]$ expr .bashrc.d \\: &quot;.*b&quot;2[skinyi@fedora ~]$ expr .bashrc.d \\: &quot;.*p&quot;0[skinyi@fedora ~]$ expr match zhiyaoniqingqingyixiao wodexinjiumizui0[skinyi@fedora ~]$ expr match zhiyaoniqingqingyixiao zhiyaoni8[skinyi@fedora ~]$ expr match zhiyaoniqingqingyixiao zhini0# expr length 获取字符串长度[skinyi@fedora ~]$ expr length 1234567899 案例：参数传入一个文件的名字，判断其是否是 mp3 文件 check_mp3.sh123#!/bin/sh# &amp;&amp; 分隔的两条语句前面的执行成功（退出码为 0）后才执行后面的语句，||反之expr &quot;$1&quot; &quot;:&quot; &quot;.*\\.mp3\\$&quot; 2&gt;&gt;/dev/null &amp;&amp; echo &quot;这是个 mp3 文件&quot; || echo &quot;这不是 mp3 文件&quot; 案例：参数传入一句话（拼音或单词），判断其长度大于 3 的拼音、单词个数 count_more_than_3.sh12345678#!/bin/shstr_count=0for word in $@; do if [ `expr length $word` -gt 3 ]; then let str_count+=1 fidoneecho &quot;大于 3 的拼音/单词个数为：$str_count&quot; bc 命令 bc 命令默认是以交互模式运行的，即执行 bc 命令会直接进入交互模式，用户可以输入表达式进行计算并得到结果，可以使用管道来传递单个表达式进行计算。bc 同时支持整数和小数计算。 用法示例： 1234[skinyi@fedora ~]$ echo 4.0/2.0 | bc2[skinyi@fedora ~]$ echo 9/3 | bc3 案例：计算 1 到 100 的和 1234567891011#!/bin/sh# echo &#123;1..100&#125; 会打印以空格作为分隔符的 1 到 100 的数字# tr 命令：用于转换或删除文件中的字符，`tr &#x27; &#x27; &#x27;+&#x27;` 代表将输入中的空格转换为 + 再输出echo &quot;1 到 100 的和是 $(echo &#123;1..100&#125; | tr &#x27; &#x27; &#x27;+&#x27; | bc)。&quot;# 或者# seq 用于生成序列，-s 选项指定分隔符为 +echo &quot;1 到 100 的和是 seq -s &#x27;+&#x27; 100 | bc。&quot;# 使用双括号echo &quot;1 到 100 的和是 $((`seq -s &#x27;+&#x27; 100`))。&quot;# 使用 expr，注意这次的分隔符echo &quot;1 到 100 的和是 $(seq -s &#x27; + &#x27; 100 | xargs expr)。&quot; awk 命令 用法示例： 123456[skinyi@fedora ~]$ echo &quot;4.2 2.4&quot; | awk &#x27;&#123;print $1+$2&#125;&#x27;6.6[skinyi@fedora ~]$ echo &quot;4.2 2.4&quot; | awk &#x27;&#123;print $1*$2&#125;&#x27;10.08[skinyi@fedora ~]$ echo &quot;4.2 2.4&quot; | awk &#x27;&#123;print $1+4*$2&#125;&#x27;13.8 $[表达式] $[表达式] 仅能用于整数运算，用法示例： 1234567[skinyi@fedora ~]$ echo $[2**2]4[skinyi@fedora ~]$ echo $[2+2+2]6[skinyi@fedora ~]$ num=5[skinyi@fedora ~]$ echo $[num+2+2]9 read 指令 read 指令用于从标准输入设备中读取输入。 12345678910111213141516171819202122232425262728293031323334[skinyi@fedora ~]$ read --helpread: read [-ers] [-a 数组] [-d 分隔符] [-i 缓冲区文字] [-n 读取字符数] [-N 读取字符数] [-p 提示符] [-t 超时] [-u 文件描述符] [名称 ...] 从标准输入读取一行并将其分为不同的域。 从标准输入读取单独的一行，或者如果使用了 -u 选项，从文件描述符 FD 中读取。 该行被分割成域，如同词语分割一样，并且第一个词被赋值给第一个 NAME 变量，第二 个词被赋值给第二个 NAME 变量，如此继续，直到剩下所有的词被赋值给最后一个 NAME 变量。只有 $IFS 变量中的字符被认作是词语分隔符。 如果没有提供 NAME 变量，则读取的行被存放在 REPLY 变量中。 选项： -a array 将词语赋值给 ARRAY 数组变量的序列下标成员，从零开始 -d delim 持续读取直到读入 DELIM 变量中的第一个字符，而不是换行符 -e 使用 Readline 获取行 -i text 使用 TEXT 文本作为 Readline 的初始文字 -n nchars 读取 nchars 个字符之后返回，而不是等到读取换行符。 但是分隔符仍然有效，如果遇到分隔符之前读取了不足 nchars 个字符。 -N nchars 在准确读取了 nchars 个字符之后返回，除非遇到文件结束符或者读超时， 任何的分隔符都被忽略 -p prompt 在尝试读取之前输出 PROMPT 提示符并且不带 换行符 -r 不允许反斜杠转义任何字符 -s 不回显终端的任何输入 -t timeout 如果在 TIMEOUT 秒内没有读取一个完整的行则超时并且返回失败。 TMOUT 变量的值是默认的超时时间。TIMEOUT 可以是小数。 如果 TIMEOUT 是 0，那么仅当在指定的文件描述符上输入有效的时候， read 才返回成功；否则它将立刻返回而不尝试读取任何数据。 如果超过了超时时间，则返回状态码大于 128 -u fd 从文件描述符 FD 中读取，而不是标准输入 退出状态： 返回码为零，除非遇到了文件结束符、读超时（且返回码不大于128）、 出现了变量赋值错误或者无效的文件描述符作为参数传递给了 -u 选项。 用法示例： 123456789101112[skinyi@fedora ~]$ read -p &quot;给你五秒时间输入你的名字：&quot; -t 5 name给你五秒时间输入你的名字：[skinyi@fedora ~]$[skinyi@fedora ~]$ read -p &quot;给你五秒时间输入你的名字：&quot; -t 5 name给你五秒时间输入你的名字：skinyi[skinyi@fedora ~]$ echo $nameskinyi[skinyi@fedora ~]$ read -p &quot;输入你的名字和年龄：&quot; name age ;echo &quot;$name $age&quot;输入你的名字和年龄：skinyi # 未输入的变量默认为空skinyi [skinyi@fedora ~]$ read -p &quot;输入你的名字和年龄：&quot; name age ;echo &quot;$name $age&quot;输入你的名字和年龄：skinyi 18skinyi 18","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"Shell","slug":"学习/Shell","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Shell/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://skinyi.github.io/tags/Shell/"},{"name":"Bash","slug":"Bash","permalink":"https://skinyi.github.io/tags/Bash/"},{"name":"脚本编程","slug":"脚本编程","permalink":"https://skinyi.github.io/tags/%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/"}]},{"title":"重学 Shell 编程之基础回顾（一）","slug":"Shell | 重学 Shell 编程之基础回顾（一）","date":"2022-03-29T01:39:48.733Z","updated":"2022-04-22T05:51:31.666Z","comments":true,"path":"2022-03-29-Shell | 重学 Shell 编程之基础回顾（一）.html","link":"","permalink":"https://skinyi.github.io/2022-03-29-Shell%20|%20%E9%87%8D%E5%AD%A6%20Shell%20%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%9F%BA%E7%A1%80%E5%9B%9E%E9%A1%BE%EF%BC%88%E4%B8%80%EF%BC%89.html","excerpt":"","text":"Shebang Shebang 是指出现在 Shell 脚本文件第一行中的前两个字符 #!，用以指定命令解释器，例如： #!/bin/sh 会使用 /bin/sh，即 bash(sh 是 bash 的一个软连接)解释器执行脚本内容； #!/usr/bin/python 会使用 python 解释器去执行脚本内容； #!/usr/bin/env NAME，是一种在不同平台上都能找到 NAME 解释器，并用 NAME 解释器执行脚本内容的写法。 🟢 一些细节： 如果脚本没有指定 shebang，脚本执行的时候，默认用当前 shell 去解释脚本，即 $SHELL 环境变量； 如果 shebang 指定了可执行的解释器，如 /bin/bash、/usr/bin/python，那么脚本在执行时，文件名会作为参数传递给解释器； 如果 shebang 指定的解释器没有可执行权限，则会报错：&quot;bad interpreter: Permission denied&quot;； 如果 shebang 指定的解释器不是一个可执行文件，那么则会忽略此指定的解释器，继而转交给当前的 shell 去执行这个脚本； 如果 shebang 指定的解释器不存在，那么会报错 &quot;bad interpreter: No such file or directory&quot;； shebang 指定解释器需写其绝对路径（如：#!/bin/bash），找寻解释器的过程不会在 $PATH 环境变量中找； 如果使用 bash script.sh 这样的命令来执行脚本，脚本中 shebang 所指定的解释器会被忽略而使用命令显式指定的 bash。 执行脚本 执行一个脚本一般有以下几种方法，以执行 script.sh 脚本为例： bash script.sh 或 sh script.sh，被执行的脚本文件可以没有可执行权限，或者脚本没有指定 shebang 时可使用； 使用 绝对/相对 路径执行脚本，被执行的脚本文件需要有可执行权限； source script.sh 或者 . script.sh，在当前 Shell 进程中执行脚本（不产生子 Shell 进程）； 少见用法：sh &lt; script.sh。 一些常见的其他 shell 解释器： /bin/sh /bin/bash /sbin/nologin /usr/bin/sh /usr/bin/bash /usr/sbin/nologin /bin/tcsh /bin/csh /bin/dash 当前系统支持的解释器类型可以执行 cat /etc/shells 命令查看。不过最受欢迎的解释器还是 bash 解释器。bash 解释器支持以下特性： 文件路径 tab 键补全 命令补全 快捷键 ctrl + a、e、u、k、l 通配符 历史命令 命令别名 命令行展开 Shell 变量 Shell 语言是弱类型语言，如其他编程语言，其也有变量的概念。 定义变量 123\\$ NAME=&quot;VALUE&quot; # 默认所有变量类型都是字符串类型，不能指定类型\\$ echo $&#123;NAME&#125;\\$ VALUE 关于单引号、双引号、反引号用法的一个案例： 123456789\\$ date=&quot;2020-03-29 20:24:56 CST&quot; \\$ VAR=&#x27;$&#123;date&#125;&#x27;;echo $&#123;VAR&#125;\\$ $date # 单引号括起来的字符串不解析变量及命令结果\\$ VAR=&quot;$&#123;date&#125;&quot;;echo $&#123;VAR&#125;\\$ 2020-03-29 20:24:56 CST # 双引号括起来的字符串会解析变量和命令结果\\$ VAR=`date`;echo $&#123;VAR&#125;\\$ 2022年 03月 30日 星期三 08:58:33 CST # 反引号代表执行命令，并取得命令的结果\\$ VAR=&quot;`date`&quot;;echo $&#123;VAR&#125;\\$ 2022年 03月 30日 星期三 09:01:14 CST # 双引号也会解析反引号执行的结果 变量替换及引用 12345\\$ NAME=&quot;ANOTHER_VALUE&quot;\\$ echo $&#123;NAME&#125;\\$ ANOTHER_VALUE\\$ echo $NAME # 省略花括号\\$ ANOTHER_VALUE 变量名命名规范 见名知意，避免使用保留关键字 变量名组成可以是字母、数字以及下划线 不能以数字开头 不能使用标点符号 变量名严格区分大小写 变量的作用域 局部变量：只能在函数内部使用的变量 全局变量：只能在当前 Shell 进程中使用的变量 环境变量：可以在子 Shell 进程中使用的变量 🔵 注意点： 不同于其他编程语言，Shell 函数内部定义的变量的作用域是全局的，即执行这个脚本的进程内可见（不等同于脚本内部可见，因为使用 source 可以在一个 Shell 进程内执行多个脚本），要实现仅在函数内部可见需使用 local 关键字，如：local var=&quot;something&quot; 全局变量只在当前 Shell 进程可见，对其他进程、子进程都不可见，当使用 export 命令将变量进行导出后，父 Shell 进程的被导出的变量将会对子进程可见，该变量即被称作环境变量 父 Shell 进程退出后，此环境变量会消失，如要定义一些常用的环境变量并在启动每个 Shell 进程时自动定义它们，此时就需将它们写在特定的配置文件里 一些特殊变量 变量 描述 $0 当前脚本的文件名 $n(n&gt;=1) 传递给脚本或函数的参数。（n 代表是第几个传递的参数，数字） $# 传递给脚本或函数的参数个数。 $* 传递给脚本或函数的所有参数，被引号括起来时所有参数视作一个整体。 $@ 传递给脚本或函数的所有参数，被引号括起来时每个参数视作一个整体，可遍历每个参数。 $? 上个命令的退出状态，或函数的返回值。 $$ 当前 Shell 进程 ID。对于 Shell 脚本，就是脚本所在的进程 ID。 $! 上一次后台进程的 PID。 $_ 获取上次执行命令的最后一个参数。 123456789101112131415161718192021[skinyi@fedora ~]$ cat test.sh#!/bin/shecho &#x27;使用&quot;$*&quot;打印参数：&#x27;for var in &quot;$*&quot;do echo &quot;$var&quot;doneecho &#x27;使用&quot;$@&quot;打印参数：&#x27;for var in &quot;$@&quot;do echo &quot;$var&quot;done[skinyi@fedora ~]$ bash test.sh a b c d使用&quot;$*&quot;打印参数：a b c d使用&quot;$@&quot;打印参数：abcd 🟢 一般来说，程序、命令的返回值为 0 时代表命令成功执行完成，返回其他值即代表发生了错误，可以根据返回值去查询相应的文档进行排错调试。对于 Shell 来说，函数的返回值跟 C、JAVA 之类的函数返回值的意义和作用是不同的。 查看环境变量 set declare env export 案例：判断传入参数个数。 123456789[skinyi@fedora ~]$ cat test.sh#!/bin/sh[ &quot;$#&quot; -ne &quot;2&quot; ] &amp;&amp; &#123; echo &quot;Expect 2 args!&quot; exit 112&#125;[skinyi@fedora ~]$ bash test.sh 1Expect 2 args! Bash 内建命令 可以使用 compgen -b 查看所有 shell 内建命令。shell 内建命令附加在 bash 命令中，因此它们是随 bash 进程常驻内存的，内建命令执行一般不需要创建子进程。 命令 作用 echo 将指定字符串输出到 STDOUT eval 将指定的参数拼接成一个命令，然后执行该命令 exec 用指定命令替换 shell 进程 export 设置子 shell 进程可用的变量 read 从 STDIN 读取一行数据并将其赋给一个变量 shift 将位置参数依次向下降一个位置 alias 为指定命令定义一个别名 getopts 分析指定的位置参数 let 计算一个数学表达式中的每个参数 local 在函数中创建一个局部变量 readonly 从 STDIN 读取一行数据并将其赋给一个不可修改的变量 readarray 从 STDIN 读取数据行并将其放入索引数组 test 基于指定条件返回退出状态码 0 或 1 trap 如果收到了指定的系统信号，执行指定的命令 wait 等待指定的进程完成，并返回退出状态码 echo 12345678# 常用选项-n 不换行输出-e 解析字符串中的格式化字符，等同于 `printf` 命令的效果# 格式化字符\\n 换行\\r 回车\\t 制表符\\b 退格 eval 12345# 例子[skinyi@fedora ~]$ set 11 22 33 44 # 通过 set 命令设置 $1, $2, $3, $4[skinyi@fedora ~]$ echo $4 # 输出 $4 的值，即 44[skinyi@fedora ~]$ echo &#x27;$&#x27;$# # 此时会输出 $4 而非 $4 的值[skinyi@fedora ~]$ eval echo &#x27;$&#x27;$# # 此时会输出 $4 的值 44 原理：eval 会把参数进行扫描拼接再执行，即上述例子最后一条命令会先扫描得到 echo $4，然后再去执行。 exec exec 会在当前进程中直接执行后面的命令而不会创建子进程，因此当执行的命令退出后该进程也会被销毁，即效果是原本的 bash 进程“不见了”。 1234[skinyi@fedora ~]$ sudo su -[root@fedora ~]\\# exec whoamiroot[skinyi@fedora ~]$ Shell 子串 字串 描述 ${var} 返回变量 var 的值 ${@var} 返回变量 var 的值的字符串长度，注意@替换为# ${var:start} 返回变量 var 的 start 个字符之后的所有字符 ${var:start:length} 返回变量 var 的 start 个字符之后长度为 length 的子字符串 ${var#word} 返回变量 var ”掐头“（最短匹配）后的子字符串 ${var##word} 返回变量 var ”掐头“（最长匹配）后的子字符串 ${var%word} 返回变量 var ”去尾“（最短匹配）后的子字符串 ${var%%word} 返回变量 var ”去尾“（最长匹配）后的子字符串 ${var/pattern/string} 返回变量 var 经单次匹配 pattern 并使用 string 替换后的值 ${var//pattern/string} 返回变量 var 经多次匹配 pattern 并使用 string 替换后的值 ${var:-word} 未定义变量 var 或值为空时返回 word，否则直接返回 var 的值 ${var:=word} 未定义变量 var 或值为空时返回 word，同时将 word 赋值给 var ${var:+word} 当变量 var 已赋值时才返回 word 进行替换，否则不替换 ${var:?MASSAGE} 当变量 var 已赋值时才返回 var 的值，否则输出 MASSAGE 到 STDERR 子串处理示例： 12345678910111213141516171819[skinyi@fedora ~]$ var=&quot;abcdefghi&quot;[skinyi@fedora ~]$ echo $&#123;var&#125;abcdefghi[skinyi@fedora ~]$ echo $&#123;#var&#125;9[skinyi@fedora ~]$ echo $&#123;var:2&#125;cdefghi[skinyi@fedora ~]$ echo $&#123;var:0-5&#125; # 从右数第五个开始输出efghi[skinyi@fedora ~]$ echo $&#123;var:2:4&#125;cdef[skinyi@fedora ~]$ echo $&#123;var:0-4:2&#125; # 从右数第四个开始输出两个字符fg[skinyi@fedora ~]$ echo $&#123;var#a*d&#125;efghi[skinyi@fedora ~]$ echo $&#123;var%e*i&#125;abcd[skinyi@fedora ~]$ echo $&#123;var/cde/edc&#125;abedcfghi 案例——批量文件名修改 12345678910111213141516171819202122# 准备工作：产生实验数据[skinyi@fedora case]$ touch file_&#123;1..5&#125;_draft.&#123;jpg,png&#125; &amp;&amp; lsfile_1_draft.jpg file_2_draft.jpg file_3_draft.jpg file_4_draft.jpg file_5_draft.jpgfile_1_draft.png file_2_draft.png file_3_draft.png file_4_draft.png file_5_draft.png[skinyi@fedora case]$ mv file_2_draft.jpg file_2_finished.jpg[skinyi@fedora case]$ mv file_2_draft.png file_2_delete.png[skinyi@fedora case]$ lsfile_1_draft.jpg file_2_delete.png file_3_draft.jpg file_4_draft.jpg file_5_draft.jpgfile_1_draft.png file_2_finished.jpg file_3_draft.png file_4_draft.png file_5_draft.png[skinyi@fedora case]$# 任务一：将所有结尾为 draft 的 jpg 文件重新命名，去掉结尾的 _draft 后缀[skinyi@fedora case]$ for filename in `ls *draft.jpg`; do mv $filename $&#123;filename/_draft/&#125;; \\done; lsfile_1_draft.png file_2_delete.png file_3_draft.png file_4_draft.png file_5_draft.pngfile_1.jpg file_2_finished.jpg file_3.jpg file_4.jpg file_5.jpg[skinyi@fedora case]$# 任务二：将所有开头为 file 且结尾为 draft 的 png 文件重新命名，修改为 pic_&#123;n&#125;_undo.png 的形式[skinyi@fedora case]$ for filename in `ls *draft.png`; do tmp=$&#123;filename/draft/undo&#125;; \\mv $filename $&#123;tmp/file/pic&#125;; done; lsfile_1.jpg file_2_finished.jpg file_4.jpg pic_1_undo.png pic_4_undo.pngfile_2_delete.png file_3.jpg file_5.jpg pic_3_undo.png pic_5_undo.png[skinyi@fedora case]$ Shell 扩展变量示例： 12345678910111213141516171819202122232425262728293031323334353637383940# 未定义 undefined 变量，定义 defined 变量的值为 defined[skinyi@fedora case]$ echo $undefined[skinyi@fedora case]$ defined=&quot;defined&quot;[skinyi@fedora case]$# var2=$&#123;var1:-word&#125; 用法示例[skinyi@fedora case]$ res=$&#123;undefined:-&quot;not defined&quot;&#125;;printf &quot;$undefined\\n$res\\n&quot;not defined[skinyi@fedora case]$ res=$&#123;defined:-&quot;not defined&quot;&#125;;printf &quot;$defined\\n$res\\n&quot;defineddefined[skinyi@fedora case]$# var2=$&#123;var1:=word&#125; 用法示例[skinyi@fedora case]$ res=$&#123;undefined:=&quot;will defined&quot;&#125;;printf &quot;$undefined\\n$res\\n&quot;will definedwill defined[skinyi@fedora case]$ res=$&#123;defined:=&quot;will redefined?&quot;&#125;;printf &quot;$defined\\n$res\\n&quot;defineddefined[skinyi@fedora case]$ unset undefined # 销毁 undefined 变量[skinyi@fedora case]$ echo $undefined[skinyi@fedora case]$# var2=$&#123;var1:+word&#125; 用法示例[skinyi@fedora case]$ res=$&#123;undefined:+&quot;something&quot;&#125;;printf &quot;$undefined\\n$res\\n&quot;[skinyi@fedora case]$ res=$&#123;defined:+&quot;something&quot;&#125;;printf &quot;$defined\\n$res\\n&quot;definedsomething# var2=$&#123;var1:?MASSAGE&#125; 用法示例[skinyi@fedora case]$ res=$&#123;undefined:?&quot;undefined is not defined!&quot;&#125;;printf &quot;$undefined\\n$res\\n&quot;bash: undefined: undefined is not defined! # 程序立即返回，没有执行后面的语句[skinyi@fedora case]$ res=$&#123;undefined:?&#125; # 也可不指定报错信息，会有默认的 stderr 信息bash: undefined：参数为空或未设置[skinyi@fedora case]$ res=$&#123;defined:?&quot;undefined is not defined!&quot;&#125;;printf &quot;$defined\\n$res\\n&quot;defineddefined[skinyi@fedora case]$ 命令列表、进程列表、进程分组 命令列表，示例：pwd; ls; ... 直接执行，不能放到后台进程 进程列表，示例：(pwd; ls; ...) 在子 shell 中执行然后返回父 shell 进程分组，示例：{pwd; ls; ...} 不会启动子 shell，与命令列表一样，只是给命令进行了分组 🟢 可以通过环境变量 BASH_SUBSHELL 来判断自己是否是子 Shell，若该变量的值为 0，则代表自己不是 subshell，若为其他值则是。 🟢 创建子 shell 时新建子进程但子进程由 bash 维护，只能通过 $BASHPID 获取PID，与父进程共用同一个 POSIX 语义下的 PID 与 PPID。本质上实现了多进程。 12345678910111213141516[skinyi@fedora ~]$ pwd; ls; echo $BASH_SUBSHELL/home/skinyicase gh-pages package-lock.json test.sh0[skinyi@fedora ~]$ (pwd; ls; echo $BASH_SUBSHELL)/home/skinyicase gh-pages package-lock.json test.sh1[skinyi@fedora ~]$ echo $BASH_SUBSHELL;(echo $BASH_SUBSHELL;(echo $BASH_SUBSHELL;(echo $BASH_SUBSHELL;(echo $BASH_SUBSHELL;(echo $BASH_SUBSHELL;)))))012345[skinyi@fedora ~]$","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"Shell","slug":"学习/Shell","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Shell/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://skinyi.github.io/tags/Shell/"},{"name":"Bash","slug":"Bash","permalink":"https://skinyi.github.io/tags/Bash/"},{"name":"脚本编程","slug":"脚本编程","permalink":"https://skinyi.github.io/tags/%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/"}]},{"title":"Docker 容器的本质及底层技术","slug":"Docker | Docker 容器的本质及底层技术","date":"2022-03-21T05:27:20.144Z","updated":"2022-03-24T14:51:08.422Z","comments":true,"path":"2022-03-21-Docker | Docker 容器的本质及底层技术.html","link":"","permalink":"https://skinyi.github.io/2022-03-21-Docker%20|%20Docker%20%E5%AE%B9%E5%99%A8%E7%9A%84%E6%9C%AC%E8%B4%A8%E5%8F%8A%E5%BA%95%E5%B1%82%E6%8A%80%E6%9C%AF.html","excerpt":"","text":"容器的本质 容器本身是一种进程隔离技术。容器为进程提供了一个隔离的环境，容器内的进程无法访问容器外的进程。以运行一个 ubuntu 容器为例： 12[root@localhost ~]\\# docker run -it ubunturoot@d304e6f37918:\\# top # 执行 top 命令 在主机上查看系统进程： 1234567[root@localhost ~]\\# ps -ef# ......root 3630 3629 0 13:48 pts/0 00:00:00 docker run -it ubunturoot 3648 1 0 13:48 ? 00:00:00 /usr/bin/containerd-shim-runc-v2 -namespace moby -id d304e6f3791808ca34c8f8361da22root 3674 3648 0 13:48 pts/0 00:00:00 bashroot 3775 3674 0 13:49 pts/0 00:00:00 top# ...... 其中第一条记录是启动该容器时的命令，其父进程是执行该命令的 bash 进程；第二条记录是该容器的进程，其父进程是 systemd 进程，由 systemd 进程直接执行 containerd-shim-runc-v2 命令启动容器的进程；第三条记录表明该容器的进程自动启动一个 bash 进程用以接受用户的指令；第四条记录表明在该 bash 进程中执行了 top 命令。 进程隔离 以上示例印证了容器的本质是一个进程，容器中的进程是容器进程的子进程或子子进程。但如何表明该容器进程是与其他进程隔离的呢？在上述 Ubuntu 容器中执行 ps -ef 命令： 1234root@baf49ec287bb:\\# ps -efUID PID PPID C STIME TTY TIME CMDroot 1 0 0 06:15 pts/0 00:00:00 bashroot 9 1 0 06:15 pts/0 00:00:00 ps -ef 可以看到该容器的 bash 进程的 PID 竟然是 1 而不是和主机一样是 systemd 进程，而在主机上其进程号是 3674，由此可以视作该容器进程里的子进程认为自己运行在一个“与世隔绝”的操作系统世界里。 文件系统隔离 在该容器内部执行： 123456789101112131415161718root@baf49ec287bb:\\# ls -l /devtotal 0crw--w----. 1 root tty 136, 0 Mar 21 06:42 consolelrwxrwxrwx. 1 root root 11 Mar 21 06:15 core -&gt; /proc/kcorelrwxrwxrwx. 1 root root 13 Mar 21 06:15 fd -&gt; /proc/self/fdcrw-rw-rw-. 1 root root 1, 7 Mar 21 06:15 fulldrwxrwxrwt. 2 root root 40 Mar 21 06:15 mqueuecrw-rw-rw-. 1 root root 1, 3 Mar 21 06:15 nulllrwxrwxrwx. 1 root root 8 Mar 21 06:15 ptmx -&gt; pts/ptmxdrwxr-xr-x. 2 root root 0 Mar 21 06:15 ptscrw-rw-rw-. 1 root root 1, 8 Mar 21 06:15 randomdrwxrwxrwt. 2 root root 40 Mar 21 06:15 shmlrwxrwxrwx. 1 root root 15 Mar 21 06:15 stderr -&gt; /proc/self/fd/2lrwxrwxrwx. 1 root root 15 Mar 21 06:15 stdin -&gt; /proc/self/fd/0lrwxrwxrwx. 1 root root 15 Mar 21 06:15 stdout -&gt; /proc/self/fd/1crw-rw-rw-. 1 root root 5, 0 Mar 21 06:15 ttycrw-rw-rw-. 1 root root 1, 9 Mar 21 06:15 urandomcrw-rw-rw-. 1 root root 1, 5 Mar 21 06:15 zero 可以发现该容器的设备文件中没有主机中的硬盘 block 文件，这是由于该容器的文件系统也是和主机不一样的独立文件系统。那么容器的文件系统在哪儿呢？使用 docker inspect 容器名|容器ID 命令并查看输出的 GraphDriver 字段来找到容器的文件系统文件在主机中的位置。 123456789[skinyi@localhost ~]\\$ sudo docker inspect -f &#x27;&#123;&#123;json .GraphDriver&#125;&#125;&#x27; ubuntu | jq&#123; &quot;Data&quot;: &#123; &quot;MergedDir&quot;: &quot;/var/lib/docker/overlay2/7472d22959e652e97acb49e6de5dd704bd2fb46de0f35d12a7b0cfbba1655cb5/merged&quot;, &quot;UpperDir&quot;: &quot;/var/lib/docker/overlay2/7472d22959e652e97acb49e6de5dd704bd2fb46de0f35d12a7b0cfbba1655cb5/diff&quot;, &quot;WorkDir&quot;: &quot;/var/lib/docker/overlay2/7472d22959e652e97acb49e6de5dd704bd2fb46de0f35d12a7b0cfbba1655cb5/work&quot; &#125;, &quot;Name&quot;: &quot;overlay2&quot;&#125; 该容器的文件系统位置就在主机上 UpperDir 属性所指向的位置。主机另起终端在该目录下找到容器的 dev 目录，并 ls -l 会发现该目录是空的，其实这是正常的，因为容器中该目录是内存数据中的一部分而未持久化到主机硬盘中。 文件隔离的本质技术是使用 chroot 系统调用，该系统调用用于将一个进程及其子进程的根目录改变到文件系统中的一个新位置，并让这些进程只能访问到该目录，此功能的初衷是为每个进程提供独立的磁盘空间。 我们可以模拟创建容器所进行的操作： 123456[root@localhost ~]\\# cd /var/lib/docker/overlay2/7472d22959e652e97acb49e6de5dd704bd2fb46de0f35d12a7b0cfbba1655cb5/[root@localhost 7472d22959e652e97acb49e6de5dd704bd2fb46de0f35d12a7b0cfbba1655cb5]\\# chroot diffroot@localhost:\\# ls bin boot dev etc home lib lib32 lib64 libx32 media mnt opt proc root run sbin srv sys tmp usr varroot@localhost:\\# pwd/ 此时无法执行 ps -ef 命令，因为其内存文件系统还没有挂载。但我们的实验可以到此为止。 Linux 命名空间技术 后面的容器技术的实现基本上都离不开 Linux 的 Namespace 技术，该技术是 Linux 提供的内核级环境隔离的方法，它提供了以下的系统隔离能力： Mount Namespace 提供磁盘挂载点和文件系统的隔离能力 IPC Namespace 提供进程间通信隔离的能力 Network Namespace 提供网络隔离能力 UTS Namespace 提供主机名及主机域的隔离能力 PID Namespace 提供进程隔离能力 User Namespace 提供用户隔离能力 在主机上查看容器的 bash 进程、主机的 bash 进程以及主机 systemd 进程的命名空间： 123456789101112131415161718192021222324252627282930313233343536[root@localhost ~]\\# ls -l /proc/3674/ns总用量 0lrwxrwxrwx. 1 root root 0 3月 21 15:42 cgroup -&gt; &#x27;cgroup:[4026532847]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 15:42 ipc -&gt; &#x27;ipc:[4026532777]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 15:42 mnt -&gt; &#x27;mnt:[4026532775]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 15:41 net -&gt; &#x27;net:[4026532780]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 15:42 pid -&gt; &#x27;pid:[4026532778]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 15:42 pid_for_children -&gt; &#x27;pid:[4026532778]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 15:42 time -&gt; &#x27;time:[4026531834]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 15:42 time_for_children -&gt; &#x27;time:[4026531834]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 15:42 user -&gt; &#x27;user:[4026531837]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 15:42 uts -&gt; &#x27;uts:[4026532776]&#x27;[root@localhost ~]\\# ls -l /proc/self/ns总用量 0lrwxrwxrwx. 1 root root 0 3月 21 15:42 cgroup -&gt; &#x27;cgroup:[4026531835]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 15:42 ipc -&gt; &#x27;ipc:[4026531839]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 15:42 mnt -&gt; &#x27;mnt:[4026531840]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 15:42 net -&gt; &#x27;net:[4026532000]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 15:42 pid -&gt; &#x27;pid:[4026531836]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 15:42 pid_for_children -&gt; &#x27;pid:[4026531836]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 15:42 time -&gt; &#x27;time:[4026531834]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 15:42 time_for_children -&gt; &#x27;time:[4026531834]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 15:42 user -&gt; &#x27;user:[4026531837]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 15:42 uts -&gt; &#x27;uts:[4026531838]&#x27;[root@localhost ~]\\# ls -l /proc/1/ns总用量 0lrwxrwxrwx. 1 root root 0 3月 21 13:05 cgroup -&gt; &#x27;cgroup:[4026531835]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 13:42 ipc -&gt; &#x27;ipc:[4026531839]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 13:42 mnt -&gt; &#x27;mnt:[4026531840]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 13:42 net -&gt; &#x27;net:[4026532000]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 13:42 pid -&gt; &#x27;pid:[4026531836]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 15:50 pid_for_children -&gt; &#x27;pid:[4026531836]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 13:42 time -&gt; &#x27;time:[4026531834]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 15:50 time_for_children -&gt; &#x27;time:[4026531834]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 13:42 user -&gt; &#x27;user:[4026531837]&#x27;lrwxrwxrwx. 1 root root 0 3月 21 13:42 uts -&gt; &#x27;uts:[4026531838]&#x27; 可以发现主机的 bash 进程和 systemd 进程完全一致，但容器中的进程和主机进程中的存在部分差别。命名空间中还包含 cgroup 命名空间，这涉及到 Linux 管理硬件资源分配的一种技术。 CGroup 控制组 CGroup 是 Linux 内核提供的一种可以限制、记录、隔离进程组所使用的计算资源（CPU、内存、I/O 等）的机制。CGroup 提供了以下功能： 限制进程组可以使用的资源数量 进程组的优先级控制 记录进程组使用的资源数量 进程组隔离 进程组控制 容器技术使用 CGroup 技术限制容器对主机资源的使用。 Containerd 容器运行时 Containerd 是一个强大的工业级容器运行时环境，其脱胎于 docker 的 libcontainerd 后经开源独立以及不断完善从 RunC 发展到现在的 Containerd（谷歌及其他大厂的一系列操作下）。现在谷歌的 K8S 默认集成的容器运行时环境已经是 Containerd，而不是原本的 Docker，Docker 现在更多代表的其实是操纵 Containerd 的一个客户端。","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Docker","slug":"学习/Docker","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Docker/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://skinyi.github.io/tags/Docker/"},{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"容器","slug":"容器","permalink":"https://skinyi.github.io/tags/%E5%AE%B9%E5%99%A8/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://skinyi.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"}]},{"title":"云计算与阿里云 ACP 概述","slug":"云计算 | 云计算与阿里云 ACP 概述","date":"2022-03-13T02:02:31.486Z","updated":"2022-03-14T13:17:58.484Z","comments":true,"path":"2022-03-13-云计算 | 云计算与阿里云 ACP 概述.html","link":"","permalink":"https://skinyi.github.io/2022-03-13-%E4%BA%91%E8%AE%A1%E7%AE%97%20|%20%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B8%8E%E9%98%BF%E9%87%8C%E4%BA%91%20ACP%20%E6%A6%82%E8%BF%B0.html","excerpt":"","text":"云计算与虚拟化概述 云计算 云计算是一种模型，它可以实现随时随地、便捷地、随需应变地从可配置计算资源共享池中获取所需的资源（例如，网络、服务器、存储、应用及服务），资源能够快速供应并释放，使管理资源的工作量和与服务提供商的交互减小到最低限度。 云计算五大特征： On-Demand Self-Service 按需自助服务 Rapid Elasticity 快速弹性伸缩 Resource Pooling 资源化池 Measured Service 可计量服务 Broad Network Access 广泛网络接入 云计算的四大部署模式： Private Cloud: 私有云 Public Cloud: 公有云（阿里云 ECS） Community Cloud: 社区云（医药行业云、运输行业云、金融行业云） Hybrid Cloud: 混合云（采用两种或两种以上上述部署模式部署） 云计算的核心技术是虚拟化技术，虚拟化其实主要提供了 Iaas 模式的服务，云计算的其他服务模式都是在 IaaS 的基础上发展而来的。 云计算的三种服务模式： IaaS(Infrastructure as a Service) 基础设施即服务: 出租处理能力、存储空间、网络带宽等基本计算资源，如：亚马逊 EC2、弹性云服务器 PaaS(Platform as a Service) 平台即服务：为客户开发的应用程序提供可部署的云服务，如：Microsoft Azure、数据库服务 SaaS(Software as a Service) 软件即服务：在网络上提供可直接使用的应用程序，如：Office 365、各种云 APP 云计算的八个通用特点：大规模、弹性计算、标准化、地理分布、虚拟化、面向服务、低成本、高安全性。 云计算的发展历程： 云计算 1.0 计算虚拟化 云计算 2.0 软件定义与整合 云计算 3.0 云原生与重构业务 虚拟化 虚拟化是指一种将硬件转变（抽象）为软件的技术。虚拟化是资源的逻辑表示，其不受物理限制的约束。虚拟化创建了一层隔离层，把硬件和上层应用分离开来，允许在一个硬件资源上运行多个逻辑应用。 常见的虚拟化：服务器虚拟化、网络虚拟化、存储虚拟化、桌面虚拟化等。其中服务器虚拟化的结构自下而上分别是：宿主机、宿主机操作系统、Hypervisor、客户机、客户机操作系统。 Hypervisor：虚拟机技术的核心、虚拟化层的具体实现。 创造并运行虚拟机的软件、固件或者硬件； 以软件的方式，实现一套和物理主机环境完全一样的虚拟环境，物理主机有的所有资源，包括 CPU、内存、网络 IO、设备 IO 等都有； 相当于物理主机的资源进行划分和隔离，供上层使用（共享硬件）。 主流 Hypervisor 产品：VMware ESXi、Microsoft Hyper-V、Linux KVM、Red Hat Enterprise Virtualization(RHEV)、Citrix XenServer、Oracle VM、VMware Workstation、VMware Player、VMware Fusion. 根据在整个系统中的位置不同，虚拟化架构分为以下几种： 寄居虚拟化架构：寄居虚拟化架构指在宿主操作系统之上安装和运行虚拟化程序，依赖于宿主操作系统对设备的支持和物理资源的管理。（VMware） 裸金属虚拟化架构：裸金属虚拟化架构指直接在硬件上面安装虚拟化软件，再在其上安装操作系统和应用，依赖虚拟层内核和服务器控制台进行管理。（阿里云弹性裸金属服务器，ECS Bare Metal Instance） 操作系统虚拟化架构：操作系统虚拟化架构在操作系统层面增加虚拟服务器功能。操作系统虚拟化架构把单个的操作系统划分为多个容器，使用容器管理器来进行管理。宿主操作系统负责在多个虚拟服务器（即容器）之间分配硬件资源，并且让这些服务器彼此独立。（docker） 混合虚拟化架构将一个内核级驱动器插入到宿主操作系统内核。这个驱动器作为虚拟硬件管理器来协调虚拟机和宿主操作系统之间的硬件访问。（KVM） 服务器虚拟化技术的分类： 按照虚拟对象来分可分为：CPU 虚拟化、内存虚拟化、I/O 虚拟化； 按照虚拟化程度分：全虚拟化、半虚拟化、硬件辅助虚拟化。 虚拟化的特点： 分区：在单一物理服务器上同时运行多个虚拟机 隔离：在单一物理服务器上的多个虚拟机之间相互隔离 封装：整个虚拟机执行环境封装在独立文件中，可以通过移动文件的方式来迁移该虚拟机 相对于硬件隔离：虚拟机无需修改，即可在任何服务器上运行 CPU 虚拟化 CPU 虚拟化分为 CPU 全虚拟化技术、CPU 半虚拟化技术以及 CPU 硬件辅助虚拟化技术。CPU的虚拟化技术可以单CPU模拟多CPU并行，允许一个平台同时运行多个操作系统，并且应用程序都可以在相互独立的空间内运行而互不影响，从而显著提高计算机的工作效率。 CPU 全虚拟化 CPU 全虚拟化主要采用优先级压缩技术（Ring Compression）和 二进制代码翻译技术（Binary Translation）。优先级压缩技术让 VMM 和 Guest 运行在不同的特权级下。 对 X86 架构而言，即 VMM 运行在最高特权级别 Ring 0 下，Guest OS 运行在Ring 1 下，用户应用运行在 Ring 3 下。因此 Guest OS 的核心指令无法直接下达 到计算机系统硬件执行，而是需要经过 VMM 的捕获和模拟执行（部分难以虚拟化的指令需要通过 Binary Translation技术进行转换）。 CPU 半虚拟化 CPU 半虚拟化主要采用 Hypercall 技术。Guest OS 的部分代码被改变，从而使 Guest OS 会将和特权指令相关的操作都转换为发给 VMM 的 Hypercall（超级调用），由 VMM 继续进行处理。而Hypercall 支持的批处理和异步这两种优化方式，使得通过 Hypercall 能得到近似于物理机的速度。 CPU 硬件辅助虚拟化 CPU 硬件辅助虚拟化目前主要有 Intel 的 VT-x 和 AMD 的 AMD-V 这两种技术。其核心思想都是通过引入新的指令和运行模式，使 VMM 和 Guest OS 分别运行在不同模式（ROOT 模式和非 ROOT 模式）下，且 Guest OS 运行在 Ring 0 下。通常情况下，Guest OS 的核心指令可以直接下达到计算机系统硬件执行，而不需要经过 VMM。当 Guest OS 执行到特殊指令的时候，系统会切换到 VMM，让 VMM 来处理特殊指令。 内存虚拟化 内存虚拟化的产生源于 VMM 与客户系统在对物理内存的认识上存在冲突，造成物理内存真正拥有者—— VMM 必须对系统访问的内存进行一定程度上的虚拟化。 内存全虚拟化技术 通过使用影子页表（Shadow Page Table）实现虚拟化。 VMM 为每个Guest 都维护一个影子页表，影子页表维护虚拟地址（VA）到机器地址（MA）的映射关系。而 Guest 页表维护 VA 到客户机物理地址（GPA）的映射关系。 当 VMM 捕获到 Guest 页表的修改后，VMM 会查找负责 GPA 到 MA 映射的 P2M 页表或者哈希函数，找到与该 GPA 对应的 MA，再将 MA 填充到真正在硬件上起作用的影子页表，从而形成 VA 到 MA 的映射关系。而 Guest 的页表则无需变动。 内存半虚拟化技术 通过使用页表写入法实现虚拟化。 Guest OS 在创建一个新的页表时，会向 VMM 注册该页表。之后在 Guest 运行的时候，VMM 将不断的管理和维护这个表，使 Guest 上面的程序能直接访问到合适的地址。 内存硬件辅助虚拟化技术 通过扩展页表 EPT（extended page table）实现虚拟化。 EPT 通过使用硬件虚拟化技术，使其能在原有的页表的基础上，增加一个 EPT 页表，用于记录 GPA 到 MA 的映射关系。VMM 预先把 EPT 页表设置到 CPU 中。 Guest 修改 Guest 页表，无需 VMM 干预。地址转换时，CPU 自动查找两张页表完成 Guest 虚拟地址到机器地址的转换，从而降低整个内存虚拟化所需的开销。 阿里云及阿里云云计算认证 阿里云 ACP 认证是面向使用阿里云云计算产品的架构、开发、运维人员的专业技术认证，主要涉及阿里云的计算、存储、网络、安全类的核心产品。该认证在 2020 年 1 月 15 日之后在原有通过线下机考的要求之上新增了完成前置实验的要求，其线下机考题分单选（70 道）和多选（30 道）两种题型，每题 1 分，总分 100 分，考生需达到 80 分以上才算通过。 具体要求可参见官方考试大纲。 阿里云云计算相关概念 ECS 云服务器 ECS(Elastic Compute Service) 是一种简单高效、处理能力可弹性伸缩的计算服务。帮助您构建更稳定、安全的应用，提升运维效率，降低IT成本，使您更专注于核心业务创新。 SLB 负载均衡 负载均衡SLB（Server Load Balancer）是一种对流量进行按需分发的服务，通过将流量分发到不同的后端服务器来扩展应用系统的吞吐能力，并且可以消除系统中的单点故障，提升应用系统的可用性。阿里云负载均衡SLB分为两类：传统型负载均衡CLB和应用型负载均衡ALB。 Auto Scaling 弹性伸缩 弹性伸缩（Auto Scaling）是根据业务需求和策略自动调整计算能力（即实例数量）的服务。您可以指定实例的类型，即ECS实例或ECI实例。在业务需求增长时，弹性伸缩自动增加指定类型的实例，来保证计算能力；在业务需求下降时，弹性伸缩自动减少指定类型的实例，来节约成本。弹性伸缩不仅适合业务量不断波动的应用程序，同时也适合业务量稳定的应用程序。 OSS 对象存储 阿里云对象存储OSS（Object Storage Service）是一款海量、安全、低成本、高可靠的云存储服务，可提供99.9999999999%（12个9）的数据持久性，99.995%的数据可用性。多种存储类型供选择，全面优化存储成本。 OSS具有与平台无关的RESTful API接口，您可以在任何应用、任何时间、任何地点存储和访问任意类型的数据。 您可以使用阿里云提供的API、SDK接口或者OSS迁移工具轻松地将海量数据移入或移出阿里云OSS。数据存储到阿里云OSS以后，您可以选择标准存储（Standard）作为移动应用、大型网站、图片分享或热点音视频的主要存储方式，也可以选择成本更低、存储期限更长的低频访问存储（Infrequent Access）、归档存储（Archive）、冷归档存储（Cold Archive）作为不经常访问数据的存储方式。 CDN 内容分发网络 阿里云内容分发网络CDN（Content Delivery Network）是建立并覆盖在承载网之上，由遍布全球的边缘节点服务器群组成的分布式网络。阿里云CDN能分担源站压力，避免网络拥塞，确保在不同区域、不同场景下加速网站内容的分发，提高资源访问速度。 VPC 专有网络 专有网络是您专有的云上私有网络。您可以完全掌控自己的专有网络，例如选择IP地址范围、配置路由表和网关等，您可以在自己定义的专有网络中使用阿里云资源，如云服务器、云数据库RDS和负载均衡等。 云盾和云监控 云盾和云监控是指阿里推出的针对云产品的安全防御以及监测系统。","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"ACP","slug":"学习/ACP","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/ACP/"}],"tags":[{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"},{"name":"ACP","slug":"ACP","permalink":"https://skinyi.github.io/tags/ACP/"},{"name":"云计算","slug":"云计算","permalink":"https://skinyi.github.io/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"阿里云","slug":"阿里云","permalink":"https://skinyi.github.io/tags/%E9%98%BF%E9%87%8C%E4%BA%91/"}]},{"title":"宇宙的尽头是考公之话说 vlookup 函数","slug":"Excel | 宇宙的尽头是考公之话说 vlookup 函数","date":"2022-03-05T12:51:48.680Z","updated":"2022-03-13T02:17:58.370Z","comments":true,"path":"2022-03-05-Excel | 宇宙的尽头是考公之话说 vlookup 函数.html","link":"","permalink":"https://skinyi.github.io/2022-03-05-Excel%20|%20%E5%AE%87%E5%AE%99%E7%9A%84%E5%B0%BD%E5%A4%B4%E6%98%AF%E8%80%83%E5%85%AC%E4%B9%8B%E8%AF%9D%E8%AF%B4%20vlookup%20%E5%87%BD%E6%95%B0.html","excerpt":"","text":"废话 这篇文章构思了很久了，奈何去外地出差加班今天才抽出晚上的时间来写，做私企的社畜确实没有公务员安逸。宁夏公务员招考公告刚发布，今日头条便推送过来了新闻，我也就关注了下。截至 3 月 2 日 10 点，宁夏报名人数达到了 73095 人，社会发展贫富差距拉大以及近年疫情影响下人们追求安稳饭碗的观念愈发深入人心了。生活安稳、工作体面的体制内人员在婚恋市场都有一定的优势，每当我妈手机里的快手直播间操着方言的媒婆说“这家女子想找个体制内的呢”，身在活多钱少的私企的我的寂寞的内心顿时哇凉哇凉的。于是我决定看看今年的报考人数打算打算，不行就争取个以后做我现在公司甲方爸爸的机会，想着我以后刁难我现在同事时的威风，嘴角不禁上扬了起来。 问题的提出 暗中观察到了 3 月 2 日，报名截止的最后一天，10 点出了最后一次的报考人数公示。统计了下最高缴费招考比的职位是 437:1 的民革银川市委员会一级科员，也不知道这个职位有什么吸引人的地方。我也根据我自身的想法，将职位过滤了一遍，最终筛出来的大致自身条件不受限可报的职位有 25 个，接下来就是要决定报哪个了，我想着根据缴费招考比选最低的那个竞争会小一些。要从 25 个职位中一一比对算缴费招考比并进行比较确实有点费劲，如果能计算机辅助的完成这个任务会更好些。 问题分析 我比对了这两张表，发现他们有两个共同的列：职位名称和职位代码。看到职位代码，作为技术人员的我想到了主键和 SQL。如果能在 Excel 中执行 SQL 查询，我上面的问题不难解决而且强大的 Excel 也确实内置了对 SQL 的支持，但其实像我现在的问题根本用不着这么复杂的方法，最好的方法是用 Excel 数据处理的函数大法。 以上问题的解决思路可以被分解为：1. 从表二根据表一筛选出来的职位代码（职位名称也行，但我还是习惯用可以标识唯一性的代码串）查出缴费人数和招考人数并记录在表一；2. 在表一计算缴费和招考人数的比例；3. 表一根据此比例进行排序；4. 从表一根据排序结果综合自身其他意愿选择报考职位。 以上解决方法中最难的其实是第一步，其他方法中涉及的计算和排序都十分简单。很多人都不太会用到 Excel 提供的一个强大的查找函数 vlookup 可以满足步骤一的需要。以下是这个函数的介绍： VLOOKUP(lookup_value,table_array,col_index_num,[range_lookup]) 按行查找表格或区域内容 其中各参数的意义是： lookup_value：要查找的值，也被称为查阅值（该参数既可以是单元格也可以是定值）。 table_array：查阅值所在的区域。 需注意：查阅值应该始终位于所在区域的第一列，这样 VLOOKUP 才能正常工作。 例如，如果查阅值位于单元格 C2 内，那么你的区域应该以 C 开头。 col_index_num：区域中包含返回值的列号。 例如，如果指定 B2：D11 作为区域，则应该将 B 计为第一列，将 C 作为第二列，以此类比。 range_lookup：（可选）如果需要返回值的近似匹配，可以指定 TRUE；如果需要返回值的精确匹配，则指定 FALSE。 如果没有指定任何内容，默认值将始终为 TRUE 或近似匹配。 解决步骤 了解这个函数之后就很简单了，为了方便，在表一所在的工作簿新建工作表，将表二的内容复制过去，如图： 在职位表新建列：缴费人数、缴费招考比。职位表的结构就变成了： ◢ A B C D E F G H I J K L M N O P 1 序号 招考单位 部门及职位 职位简介 职位代码 招考人数 专业要求 学历要求 学位要求 政治面貌 其他条件 备注 申论试卷类型 联系电话 缴费人数 缴费招考比 308 304 石嘴山市 石嘴山市市直部门一级科员（一） 负责综合管理服务、信息化建设、工程建设项目规划、项目审批等工作 017001 2 计算机类、电子信息类、建筑类、水利类 本科及以上 学士及以上 不限 限男性 合并职位：市人力资源和社会保障局1人、民政局1人、团市委（参照公务员法管理群团机关）1人、就业创业服务局（参照公务员法管理事业单位）1人 A卷 0952-2012332 0952-2218747 140 70 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 然后就可以用 vlookup 函数自动从统计表根据职位代码查找到对应职位的缴费人数。简单起见，可以用 Excel 的函数向导手动可视化的选择或确定出函数的参数，从菜单栏选中：公式-插入函数，在搜索函数对话框里输入 vlookup 并点击转到，然后确保从选择函数中选中 vlookup 后点击确定。 点击每项参数后面红圈里的按钮就可以在工作表中选择参数或参数范围： 最终完整函数形式是：=VLOOKUP(E308,统计表!D2:I765,6,0)，意思是从统计表的 D2 到 I765 的单元格范围内对比 D 列的值是否为 E308 里的值，若精确匹配则返回该单元格所选范围的第六行的值为该函数的结果。 观察之后发现对应正确，然后就可以用 Excel 强大的填充工具将其他职位的缴费人数也根据第一个筛选出来的岗位填充进去。在我的操作中，填充后的函数虽然有问题但工作良好，因为职位表和统计表的职位表的排序是对应的，此时若在未对应的情况下就会出现问题，有的单元格可能会出现 #N/A 值。 问题思考 造成上述问题的原因是我们未锁定 table_array 参数的所选范围的行值，每次往下下拉填充统计范围的行值都会自增，如我在下面随便选中的一个填充后的单元格的公式变成了：=VLOOKUP(E615,统计表!D486:I1249,6,0)，这在无序情况下会出错。 为了使该参数固定，可以借助 $ 符号进行限定，这样每次填充时该函数的第二个参数就是不变的了。 于是，筛选后的职位表的第一行的公式可以写成：=VLOOKUP(E308,统计表!D$2:I$765,6,0)，然后再往下填充。再选中刚才填充的公式，其变成了：=VLOOKUP(E615,统计表!D$2:I$765,6,0)，这样就比较精准了。 计算缴费招考比，以筛选后的职位表的第一行为例：=O308/F308。然后用排序工具排序就完成任务了。 还是废话 看了最后的结果，不仅感叹现在的公务员考试越来越卷，我估计我也将只会是陪考员中的一员。由此看来还是再钻研钻研 Excel 的 SQL 查询功能比较现实。","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Office","slug":"学习/Office","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Office/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"Excel","slug":"Excel","permalink":"https://skinyi.github.io/tags/Excel/"},{"name":"Office","slug":"Office","permalink":"https://skinyi.github.io/tags/Office/"},{"name":"避免加班","slug":"避免加班","permalink":"https://skinyi.github.io/tags/%E9%81%BF%E5%85%8D%E5%8A%A0%E7%8F%AD/"},{"name":"少加班","slug":"少加班","permalink":"https://skinyi.github.io/tags/%E5%B0%91%E5%8A%A0%E7%8F%AD/"}]},{"title":"Docker Run 命令详解","slug":"Docker | Docker Run 命令详解","date":"2022-03-01T12:31:09.667Z","updated":"2022-03-28T06:09:02.646Z","comments":true,"path":"2022-03-01-Docker | Docker Run 命令详解.html","link":"","permalink":"https://skinyi.github.io/2022-03-01-Docker%20|%20Docker%20Run%20%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3.html","excerpt":"","text":"Docker 在隔离的容器中运行进程。容器是在主机上运行的进程。主机可以是本地或远程的。当执行 docker run 时，运行的容器进程是独立的，因为它有自己的文件系统、自己的网络和自己的独立于主机的进程树。 以下介绍了如何在运行时使用 docker run 命令定义容器的资源。 docker run 命令的一般形式 基本的 docker run 命令采用以下形式： 1\\$ docker run [选项] IMAGE[:标签|@摘要] [命令] [参数...] docker run 命令必须指定从中生成容器的镜像。镜像开发人员可以定义与以下内容相关的镜像默认值： 分离或前台运行； 容器标识； 网络设置； 对CPU和内存的运行时约束。 通过 docker run [选项] 用户可以添加或覆盖开发人员设置的镜像默认值。此外，用户可以覆盖几乎所有由 Docker 运行时本身设置的默认值。也正因为如此，docker run 比任何其他 Docker 命令都有更多选项。 🟢 根据你的 Docker 系统配置，你可能需要在 docker run 命令前面加上 sudo 以确保命令正常执行生效。为了避免在 docker 命令中使用 sudo，你的系统管理员可以创建一个名为 docker 的 Unix 组并向其中添加 docker 操作用户。 仅用户可指定的选项 仅执行 docker run 命令的用户可指定以下命令执行时的选项： 独立进程或前台执行 独立进程（-d 选项） 前台执行 容器标识 名称（--name 选项） PID 值 IPC 设置（--ipc） 网络设置 重启策略（--restart） 清理（--rm） 运行时资源约束 运行时特权及 Linux capabilities 独立进程或前台执行 当启动了一个 Docker 容器，你必须先决定你是否想在后台以“分离”的模式或者默认在前台运行容器，可以使用 -d[=&lt;true|false&gt;] 选项来指定分离式模式，容器会在后台运行并打印出该容器的 id。 根据设计，当用于运行容器的根进程退出时，以分离模式启动的容器也会退出，除非你还指定了 -rm 选项。如果将 -d 与 -rm 一起使用，当容器退出或守护程序退出时(无论哪个先退出)，容器将被删除。 不要向分离模式运行的容器传递 service xxx start 的命令。如以下命令尝试创建容器后启动 nginx 服务。 1\\$ docker run -d -p 80:80 my_image service nginx start 即使这也会成功的启动容器内部的 nginx 服务，但是它不符合分离的容器范例，因为随着根进程（service nginx start）的退出，分离式容器也会跟着停止，从而导致 nginx 服务启动了却不能用。要启动一个进程如 nginx web 服务器应该按照下述方法： 1\\$ docker run -d -p 80:80 my_image nginx -g &#x27;daemon off;&#x27; 要使用分离的容器进行输入/输出则必须使用网络连接或共享卷，因为该容器不会监听运行 docker run 的命令行。 为了将分离出去的容器转至前台运行，可以使用 docker attach 命令。将运行于前台的容器切至后台运行可以使用 Ctrl + p + q 快捷键。 前台运行 在前台模式下（默认模式当未指定 -d 选项），docker run 可以启动容器中的进程并且将当前终端附加到该进程的标准输入、输出以及标准错误流中。它甚至可以“假装”成为一个 TTY 会话（如大多数命令行可执行文件期望的那样）并且传递信号。以下这些选项都是可配置的： -a=[] ：附加到标准输入、标准输出和 / 或标准错误流 -t ：分配一个伪 TTY --sig-proxy=true：将所有收到的信号代理到进程(仅限非TTY模式) -i ：即使没有连接，也保持标准输入流打开 如果你没有指定 -a 选项，Docker 就会将进程的标准输入、错误流附加到当前终端中，你也可以通过 -a 选项指定哪个流进行附加，比如： 1\\$ docker run -a stdin -a stdout -i -t ubuntu /bin/bash 对于交互式进程（如命令行 shell），必须一起指定 -i 和 -t 选项来为容器进程分配一个 TTY，这两个选项常被简写为 -it。当客户端从管道中接收标准输入流时指定 -t 选项通常是被禁止的，比如： 1\\$ echo test | docker run -i busybox cat 🔴 注意：在容器中运行的 PID 为 1 的进程会被 Linux 特殊看待：它会忽略任何信号的默认行为。最终就会导致收到 SIGINT 和 SIGTERM 信号的进程不会终止除非它被编码进行指定。 容器标识 容器名称（--name） 用户可以通过三种方式来标识容器： 标识符类型 例子 UUID 长标识符 “f78375b1c487e03c9438c729345e54db9d20cfa2ac1fc3494b6eb60872e74778” UUID 短标识符 “f78375b1c487” 名称 “evil_ptolemy” 其中，UUID 标识符由 Docker 守护程序生成。如果未通过 --name 选项来给容器赋予名称，则守护程序会生成一串随机字符来自动命名该容器。给容器进行有意义的命名是一个比较好的习惯。如果你制定了容器的名称，就可以在 Docker 网络中引用容器时使用它，不论是前台还是后台运行的容器。 默认网桥网络上的容器必须被链接以通过名称进行通信。 最后，为了便于自动化，你可以让 Docker 将容器的 ID 写入到你选择的文件中。这类似于一些程序会将自身进程 ID 写入到文件中去，正如你见过的 PID 文件。 1--cidfile=&quot;&quot;：将容器 ID 写入文件 镜像[:标签] 虽然严格来说这不是一种标识容器的方法，但是你可以通过将 image[:tag] 添加到命令中来指定您想要运行容器的镜像版本。比如：docker run ubuntu:14.04。 镜像[@摘要] 使用 v2 或更高版本镜像格式的镜像有一个称为摘要的内容可寻址标识符。只要用于生成镜像的输入不变，摘要值就是可预测和可参考的。 以下示例使用在运行 alpine 镜像时使用了 sha256:9cacb71397b640ECA97488cf08582AE4068513101088e9f96c9814bfda95e0 摘要： 1\\$ docker run alpine@sha256:9cacb71397b640eca97488cf08582ae4e4068513101088e9f96c9814bfda95e0 date PID 设置（--pid） --pid=&quot;&quot; ：为容器设置 PID（进程） 命名空间模式。可选值：container:&lt;name|id&gt;：加入其他容器的 PID 命名空间；host：使用容器中的主机的 PID 命名空间。 默认情况下，所有容器都启用了 PID 命名空间。 PID 命名空间提供了进程的分离。PID 命名空间删除了系统进程的视图，并允许重用进程 ID，包括 pid 1。 在某些情况下，你希望你的容器共享主机的进程名称空间，基本上允许容器内的进程看到系统上的所有进程。例如，您可以使用像 strace 或 gdb 这样的调试工具构建一个容器，但是在调试容器中的进程时，你希望使用这些工具。 例子：在容器中执行 `htop` 创建 Dockerfile: 123FROM alpine:latestRUN apk add --update htop &amp;&amp; rm -rf /var/cache/apk/*CMD [&quot;htop&quot;] 构建此 Dockerfile 并将镜像标记为 myhtop： 1\\$ docker build -t myhtop . 使用以下命令在容器中运行 htop 命令： 1\\$ docker run -it --rm --pid=host myhtop 加入其他可以被用来调试该容器的 pid 命名空间。 例子 开启一个运行 redis 服务的容器： 1\\$ docker run --name myredis -d redis 通过运行含有 strace 的其他容器来调试 redis 容器： 12\\$ docker run -it --pid=container:my-redis my_strace_docker_image bash\\$ strace -p 1 UTS 设置（--uts） --uts=&quot;&quot; : 设置容器的 UTS 命名空间。可选值：host 值代表使用主机的 uts 值。 UTS 命名空间参数设置旨在使容器进程对于运行于目标 uts 设置中的目标进程的主机名和域可见。默认情况下所有的容器，包括指定了 --network=host 命名空间的容器，都有自己的 uts 命名空间。--uts=host 将会使容器使用和主机一样的 uts 命名空间。在指定了 --uts=host 设置后将不能再单独指定 --hostname 和 --domainname 设置。 如果希望容器的主机名随着主机的主机名的更改而更改，即容器与主机共享主机名，更好的做法是从容器中更改主机的主机名。 IPC 设置（--ipc） --ipc=&quot;MODE&quot; : 设置容器的 IPC 模式 可以接受以下值： 值 描述 不指定 使用守护程序默认设置 none 使用自己私有的 IPC 命名空间，且不挂载 /dev/shm private 使用自己私有的 IPC 命名空间 shareable 使用自己私有的 IPC 命名空间，但允许与其他容器共享此命名空间 container: &lt;_name-or-ID_&gt; 加入其他设置了 --ipc=shareable 的容器的命名空间（需指定容器名或 ID） host 使用主机的 IPC 命名空间 dockerd 守护程序默认会使用 --ipc=private 或 --ipc=shareable 设置，具体取决于 dockerd 守护程序的版本及配置。 IPC(POSIX/SysV IPC) 命名空间提供了不同命名空间下的共享内存段、信号量以及消息队列的隔离机制。 共享内存段是用于以内存的速度加速进程间通信的一种方法，除此之外还有通过管道或网络堆栈的方法。共享内存通常用于涉及科学计算或金融服务等的数据库和构建的对高性能有要求的应用程序。如果你的这类应用程序被拆分成多个容器就要考虑可能需要共享这些容器之间的 IPC 机制，做法是对主容器使用 --ipc=shareable 的设置、其他容器使用 --ipc=container:&lt;主容器名或其 ID&gt; 的设置。 网络设置 --dns=[] : 为容器指定域名服务器 --network=&quot;bridge&quot; : 指定容器接入网络的方式，可选值：bridge 在默认的 Docker 网桥上创建网络栈（默认）；none 不联网；container:&lt;name|id&gt; 复用现有容器的网络栈；host 使用 Dockr 主机的网络栈；&lt;network-name&gt;|&lt;network-id&gt; 连接至用户自定义的网络。 --network-alias=[] : 为容器添加网络范围的别名 --add-host=&quot;&quot; : 在 /etc/hosts 上自动添加一行记录 (host:IP) --mac-address=&quot;&quot; : 指定容器物理设备的 MAC 地址 --ip=&quot;&quot; : 指定容器物理设备的 IPv4 地址 --ip6=&quot;&quot; : 指定容器物理设备的 IPv6 地址 --link-local-ip=[] : 指定一个或多个容器的物理设备的链路的本地 IPv4 或 IPv6 地址 默认情况下，所有容器都会启用网络且对网络出口不做任何限制。可以通过指定 --network none 选项来禁用容器的网络，在这种情况下，可以仅通过文件、标准输入输出流来进行 I/O。 要实现不同容器之间的互通只能通过默认的网桥模式设置，链接特性是一种经典的特性，更推荐使用基于链接特性的 Docker 网络驱动。 你的容器会默认使用主机设置的 DNS 服务器，但是你可以通过指定 --dns=&lt;DNS&gt; 选项来指定容器网络的 DNS 设置。 默认情况下，容器会根据自身分配的 ip 地址来生成自己的 MAC 地址，可以通过指定 --mac-address=&lt;MAC&gt; 选项（MAC 地址的分隔符使用英文冒号，如 12:34:56:78:9a:bc）来显式指定容器的 MAC 地址。需注意 Docker 不会进行手动分配的 MAC 地址的唯一性检查。 Network:none 容器不会有到外部网络的虚拟设备及路由，但内部仍会有一个回环接口。 Network:bridge 将网络设置为桥接模式后，容器将使用 docker 的默认网络设置。在主机上设置一个桥，通常命名为 docker0，将为容器创建一对 veth 接口。veth对的一端将保留在连接到网桥的主机上，而 veth 对的另一端除了放在环回接口之外，还将放在容器的命名空间内以为网桥网络上的容器分配一个IP 地址，流量将通过该网桥路由到该容器。 默认情况下，容器可以通过它们的 IP 地址进行通信。要通过名字交流，它们必须连接在一起。 Network:host 将网络设置为主机模式后，容器将共享主机的网络堆栈，并且来自主机的所有接口将对容器可用。容器的主机名将与主机系统上的主机名相匹配。请注意 --mac-address 选项在主机网络模式下无效。即使在主机网络模式下，默认情况下容器也有自己的 UTS 命名空间。因此，在主机网络模式下允许使用 --hostname 和 --domainname 选项，它们只会更改容器内的主机名和域名。与 --hostname 类似，可以在主机网络模式下使用 --add-host、--dns、--dns-search 和 --dns-option 选项。这些选项将会更新容器中的 /etc/hosts 或 /etc/resolv.conf。不会对主机上的 /etc/hosts 和 /etc/resolv.conf 进行任何更改。 与默认网桥模式相比，主机模式提供了明显更好的网络性能，因为它使用主机的本机网络堆栈，而网桥必须通过 dockerd 守护程序经历一级虚拟化。当容器的网络性能至关重要时，例如生产负载平衡器或高性能 Web 服务器，建议以此模式运行容器。 🔵 注意：--network=&quot;host&quot; 给予容器对本地系统服务（如 D-bus）的完全访问权，因此被认为是不安全的。 Network:container 将网络设置为容器模式后，一个容器将共享另一个容器的网络堆栈。另一个容器的名称必须以 --network container:&lt;名称|id&gt; 的格式提供。注意 --add-host、--hostname、--dns、--dns-search、--dns-option 和 --mac-address 在容器网络模式中无效，而 --publish、--publish-all、--expose 在容器网络模式中也无效。 以下示例运行 redis 容器，将 redis 绑定到本地主机，然后运行 redis-cli 命令并通过本地主机接口连接到Redis服务器。 12\\$ docker run -d --name redis example/redis --bind 127.0.0.1\\$ docker run --rm -it --network container:redis example/redis-cli -h 127.0.0.1 用户定义的网络 你可以使用 Docker 网络驱动程序或外部网络驱动程序插件来创建网络。你可以将多个容器连接到同一网络。一旦连接到用户定义的网络，这些容器就可以仅使用另一个容器的 IP 地址或域名轻松地进行通信。 对于支持多主机连接的覆盖网络或自定义插件，连接到同一多主机网络但从不同引擎启动的容器也可以通过这种方式进行通信。 以下示例使用内置网桥网络驱动程序创建网络，并在创建的网络中运行容器： 12\\$ docker network create -d bridge my-net\\$ docker run --network=my-net -itd --name=container3 busybox 管理 /etc/hosts 文件 你的容器将在 /etc/hosts 中包含一些行，这些行定义了容器本身的主机名以及 localhost 和其他一些常见内容。--add-host 标志可用于向 /etc/hosts 添加额外的行。 123456789\\$ docker run -it --add-host db-static:86.75.30.9 ubuntu cat /etc/hosts127.0.0.1 localhost::1 localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetff00::0 ip6-mcastprefixff02::1 ip6-allnodesff02::2 ip6-allrouters86.75.30.9 db-static172.17.0.2 af78fbac55c9 如果一个容器连接到默认桥接网络并与其他容器链接，则该容器的 /etc/hosts 文件将使用链接容器的名称进行更新。 🔵 注意：由于 Docker 可能会实时更新容器的 /etc/hosts 文件，因此可能会出现容器内的进程最终读取空的或不完整的 /etc/hosts 文件的情况。在大多数情况下，再次重试读取应该可以解决问题。 重启策略（--restart） 使用 docker run 上的 --restart 标志可以指定容器的重启策略，决定容器在退出时应不应该以及如何重启。 当重启策略在容器上被激活时，它将在 docker ps 中显示为 Up 或 Restarting。使用 docker events 查看重启策略的效果也很有用。 策略 效果 no （默认）容器退出后不会自动重启。 on-failure[:max-retries] 当容器退出并返回一个非零状态值时尝试重启，可以指定最大重试次数。 always 无论退出状态如何，都要重启容器。当指定 always 时，Docker 守护进程将尝试无限期地重新启动容器。无论容器的当前状态如何，容器也总是在守护进程启动时启动。 unless-stopped 无论退出状态如何，都要重启容器，包括在守护进程启动时，除非容器在 Docker 守护进程停止之前处于停止状态。 在每次重新启动之前，增加延迟(从 100 毫秒开始，是之前延迟的两倍),以防止服务器洪流。这意味着守护进程将等待 100 毫秒，然后 200 毫秒，400，800，1600，等等，直到达到失败极限，最大延迟1分钟，或者当您执行 docker stop 或 docker rm -f 容器。 如果容器成功重启(容器启动并运行至少 10 秒)，延迟将重置为默认值100毫秒。 使用失败时策略时，您可以指定 Docker 尝试重新启动容器的最大次数。默认情况下，Docker 将永远尝试重新启动容器。可以通过 docker inspect 获得容器的(尝试)重启次数。例如，获取容器“my-container”的重启次数: 1\\$ docker inspect -f &quot;&#123;&#123; .RestartCount &#125;&#125;&quot; my-container 或者获得上次容器(重新)启动的时间: 1\\$ docker inspect -f &quot;&#123;&#123; .State.StartedAt &#125;&#125;&quot; my-container 将 --restart (重新启动策略)与 --rm (清理)标志结合使用会导致错误。容器重启时，连接的客户端会断开连接。 自动清理（--rm） 默认情况下，容器的文件系统即使在容器退出后仍然存在。这使得调试容易得多(因为您可以检查最终状态),并且在默认情况下保留所有数据。但是如果你运行的是短期前台进程，这些容器文件系统会不断堆积起来。相反，如果您希望 Docker 在容器退出时自动清理容器并删除文件系统，您可以添加 --rm 标志: --rm=false: 容器退出时自动清理","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Docker","slug":"学习/Docker","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Docker/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://skinyi.github.io/tags/Docker/"},{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"容器","slug":"容器","permalink":"https://skinyi.github.io/tags/%E5%AE%B9%E5%99%A8/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://skinyi.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"}]},{"title":"RHCE 考试及红帽企业 Linux 了解","slug":"Linux | RHCE 考试及红帽企业 Linux 了解","date":"2022-03-01T10:35:41.028Z","updated":"2022-03-05T12:58:15.221Z","comments":true,"path":"2022-03-01-Linux | RHCE 考试及红帽企业 Linux 了解.html","link":"","permalink":"https://skinyi.github.io/2022-03-01-Linux%20|%20RHCE%20%E8%80%83%E8%AF%95%E5%8F%8A%E7%BA%A2%E5%B8%BD%E4%BC%81%E4%B8%9A%20Linux%20%E4%BA%86%E8%A7%A3.html","excerpt":"","text":"🔴 此文章由之前的 Typora 笔记迁移过来，内容可能已经过时。 RHCE8.0 课程及考试代码 相较于 RHCE7 ，在 EX200 考试中，RHCE8 增加了 SHELL 脚本（RH254）、系统调优（RH442）以及 RHEL8 新特性的一些考察；在 EX294 考试中，RHCE7 考察一些常见的 Service 的搭建部署使用，如：NFS、SAMBA、DNS等，而在 RHCE8 考试中则主要考察 Ansible 自动化工具的操作，不再包含常见服务。 课程代码 考试代码 考试内容 考试形式 考试时长 RH124 EX200 以系统管理操作为主，如：文件系统、用户操作、权限操作、磁盘操作等 机考实验 2.5h RH134 RH294 EX294 全是关于 Ansible 自动化工具的技能操作 4h 搭建日常练习环境 🟢 所需前期准备工作： 已安装 VMWare Workstation 虚拟机，并在 bios 中开启了虚拟化相关的开关； 已下载好 RHEL8 Linux 操作系统 iso 镜像； 练习环境虚拟机以 NAT 模式和宿主机进行网络连接，使用的虚拟网卡是 VMNet8 。 虚拟机安装 RHEL8.3 操作系统 ​如图，虚拟机的配置如下，可根据自己个人硬件设备情况按需调整。 虚拟机软件选择如下： 设置 root 用户和普通用户后开始安装，等待进度条跑完重启虚拟机，重启后同意 Redhat 的 EULA，选择 FINISH CONFIGURATION 进入图形界面。图形界面默认为刚才创建的普通用户，新安装的 RHEL 还需要进行一些系统级的配置才行。 在此之前我们需要登陆 root 账户来配置我们新安装的操作系统。下图为使用 root 用户登陆后的界面。 安装完操作系统后的配置 配置网络设置 ​使用 ip addr show 命令来查看操作系统的网络配置结果如图所示： 🟢 其它网卡设备介绍： lo 虚拟网卡设备， lo 是主机用于向自身发送通信的一个特殊地址（也就是一个特殊的目的地址），其 ip 为 127.0.0.1 ； virbr0 是 KVM 默认创建的一个网桥，其作用是为连接其上的虚拟机网卡提供 NAT 访问外网的功能，可提供 DHCP 服务，其默认 ip 为 192.168.122.1。此虚拟设备被强制删除后重启系统还会再次创建，如需卸载须使用 KVM 虚拟化管理工具； birbr0-nic, 同上由 KVM 服务创建，可以使用 brctl 命令进行管理。 其中 ens160 才是连接外网所需要的网卡设备。可以看到此网卡没有绑定 ip 地址，但虚拟机软件是设置的 NAT 且已开启了 DHCP 服务，因此导致此问题的原因可能是我们的网卡设备没有启动或启用。需要检查此网卡设备的配置文件，其路径为：/etc/sysconfig/network-scripts/ifcfg-ens160（可以推断 RHEL 的网卡配置文件名称都是由 &quot;ifcfg-&quot; 和网卡名组成的），使用 vim 编辑器来编辑此文件，此文件内容如下： 123456789101112131415TYPE=Ethernet # 网络类型：以太网PROXY_METHOD=none # 网络代理方法BROWSER_ONLY=no BOOTPROTO=dhcp # 激活设备使用的地址配置协议：dhcp,static,none,bootpDEFROUTE=yes # ipv4 默认路由设备：yes,noIPV4_FAILURE_FATAL=noIPV6INIT=yes # 初始化 ipv6 协议栈：yes,noIPV6_AUTOCONF=yes # 自动配置 ipv6：yes,noIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyNAME=ens160 # 网卡名UUID=74e066fb-4f82-4422-ae3f-570dd2fca5a5 DEVICE=ens160 # 应用到的设备（和 HWADDR 必须留一个，后者指网卡物理地址）ONBOOT=no # 开机后自动激活此设备 🟢 Linux 网络配置说明： 网卡的相关配置文件：/etc/sysconfig/network-scripts/ifcfg-网卡名 路由相关的配置文件：/etc/sysconfig/network-scripts/route-网卡名 网络相关说明参考/usr/share/doc/initscripts-version/sysconfig.txt 需要将 ONBOOT=no 更改为 ONBOOT=yes 以使此网卡开机就激活启用，重启虚拟机，验证网卡是否已经自动激活（自动获得了 ip 地址则配置成功）。 使用 Xshell 远程登陆 ​在 Xshell 里新建连接，进行配置即可远程登陆到此虚拟机。 RHEL 和 CentOS 的区别 简称 中文全称 存在付费 付费回报 特点 RHEL 红帽企业 Linux 操作系统 是 获得技术支持 稳定，最先获得 Bug 修复 CentOS 社区企业操作系统 否 - 含有一些新特性，比较稳定，延迟获得 Bug 修复","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"}]},{"title":"Docker 命令手册及常用帮助命令","slug":"Docker | Docker 命令手册及常用帮助命令","date":"2022-02-27T14:03:20.637Z","updated":"2022-03-01T13:16:25.044Z","comments":true,"path":"2022-02-27-Docker | Docker 命令手册及常用帮助命令.html","link":"","permalink":"https://skinyi.github.io/2022-02-27-Docker%20|%20Docker%20%E5%91%BD%E4%BB%A4%E6%89%8B%E5%86%8C%E5%8F%8A%E5%B8%B8%E7%94%A8%E5%B8%AE%E5%8A%A9%E5%91%BD%E4%BB%A4.html","excerpt":"","text":"常用命令速查表格 命令 用途 docker version 查看 docker 客户端及服务端（docker 引擎）的版本及环境信息 docker info 查看 docker 的系统信息，包括客户端、服务端配置、镜像与容器数量以及一些其他常见配置 docker [命令] --help 查看 docker [命令] 使用的帮助信息，比如 docker image --help Docker 命令速查手册地址：https://docs.docker.com/engine/reference/run/ 。 常用帮助命令介绍 docker version 查看 docker 版本信息 12345678910111213141516171819202122232425262728293031[skinyi@fedora ~]\\$ sudo docker version[sudo] skinyi 的密码：Client: Docker Engine - Community Version: 20.10.12 API version: 1.41 Go version: go1.16.12 Git commit: e91ed57 Built: Mon Dec 13 11:46:03 2021 OS/Arch: linux/amd64 Context: default Experimental: trueServer: Docker Engine - Community Engine: Version: 20.10.12 API version: 1.41 (minimum version 1.12) Go version: go1.16.12 Git commit: 459d0df Built: Mon Dec 13 11:43:48 2021 OS/Arch: linux/amd64 Experimental: false containerd: Version: 1.4.12 GitCommit: 7b11cfaabd73bb80907dd23182b9347b4245eb5d runc: Version: 1.0.2 GitCommit: v1.0.2-0-g52b36a2 docker-init: Version: 0.19.0 GitCommit: de40ad0 docker info 查看 docker 的系统信息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657[skinyi@fedora ~]\\$ sudo docker info[sudo] skinyi 的密码：Client: Context: default Debug Mode: false Plugins: app: Docker App (Docker Inc., v0.9.1-beta3) buildx: Docker Buildx (Docker Inc., v0.7.1-docker) scan: Docker Scan (Docker Inc., v0.12.0)Server: Containers: 2 Running: 0 Paused: 0 Stopped: 2 Images: 1 Server Version: 20.10.12 Storage Driver: overlay2 Backing Filesystem: xfs Supports d_type: true Native Overlay Diff: true userxattr: false Logging Driver: json-file Cgroup Driver: systemd Cgroup Version: 2 Plugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc io.containerd.runc.v2 io.containerd.runtime.v1.linux Default Runtime: runc Init Binary: docker-init containerd version: 7b11cfaabd73bb80907dd23182b9347b4245eb5d runc version: v1.0.2-0-g52b36a2 init version: de40ad0 Security Options: seccomp Profile: default cgroupns Kernel Version: 5.16.8-200.fc35.x86_64 Operating System: Fedora Linux 35 (Server Edition) OSType: linux Architecture: x86_64 CPUs: 2 Total Memory: 3.788GiB Name: fedora ID: I5R6:5NIE:OTIL:XBI4:R6WP:5XSO:BZTG:QGV6:6RHG:OU7U:P3EP:JTEC Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries: 127.0.0.0/8 Live Restore Enabled: false docker [命令] --help 查看 docker [命令] 的帮助信息 123456789101112131415161718192021[skinyi@fedora ~]\\$ docker image --helpUsage: docker image COMMANDManage imagesCommands: build Build an image from a Dockerfile history Show the history of an image import Import the contents from a tarball to create a filesystem image inspect Display detailed information on one or more images load Load an image from a tar archive or STDIN ls List images prune Remove unused images pull Pull an image or a repository from a registry push Push an image or a repository to a registry rm Remove one or more images save Save one or more images to a tar archive (streamed to STDOUT by default) tag Create a tag TARGET_IMAGE that refers to SOURCE_IMAGERun &#x27;docker image COMMAND --help&#x27; for more information on a command. 123456789101112131415161718[skinyi@fedora ~]$ sudo docker container list --helpUsage: docker container ls [OPTIONS]List containersAliases: ls, ps, listOptions: -a, --all Show all containers (default shows just running) -f, --filter filter Filter output based on conditions provided --format string Pretty-print containers using a Go template -n, --last int Show n last created containers (includes all states) (default -1) -l, --latest Show the latest created container (includes all states) --no-trunc Don&#x27;t truncate output -q, --quiet Only display container IDs -s, --size Display total file sizes docker 子命令功能简介 子命令 描述 docker attach 将本地标准输入输出和错误流附加到正在运行的容器 docker build 从 Dockerfile 构建一个镜像 docker builder 管理镜像构建器 docker checkpoint 管理检查点 docker commit 从一个容器的所有更改创建一个新的镜像 docker config 管理 Docker 的配置 docker container 管理容器 docker context 管理 docker 上下文 docker cp 在容器和本地存储之间拷贝文件或目录 docker create 创建一个新的容器 docker diff 监视容器上的文件或目录的变化 docker events 从 docker 守护服务上获取实时事件 docker exec 在一个运行的容器上运行命令 docker export 将一个容器的文件系统以 tar 包的形式导出 docker history 展示一个镜像的提交历史 docker image 管理 docker 镜像 docker images 列出镜像 docker import 从 tar 包中导入内容来创建一个文件系统镜像 docker info 显示系统范围的信息 docker inspect 返回 docker 对象的底层信息 docker kill 杀掉一个或多个运行中的容器 docker load 从一个 tar 包或标准输入来加载镜像 docker login 登录 Docker registry docker logout 登出 Docker registry docker logs 获取一个容器的日志 docker manifest 管理 Docker 镜像清单和清单列表","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Docker","slug":"学习/Docker","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Docker/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://skinyi.github.io/tags/Docker/"},{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"容器","slug":"容器","permalink":"https://skinyi.github.io/tags/%E5%AE%B9%E5%99%A8/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://skinyi.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"}]},{"title":"Docker 介绍以及安装与卸载","slug":"Docker | Docker 介绍以及安装与卸载","date":"2022-02-27T13:03:47.405Z","updated":"2022-03-21T06:22:59.708Z","comments":true,"path":"2022-02-27-Docker | Docker 介绍以及安装与卸载.html","link":"","permalink":"https://skinyi.github.io/2022-02-27-Docker%20|%20Docker%20%E4%BB%8B%E7%BB%8D%E4%BB%A5%E5%8F%8A%E5%AE%89%E8%A3%85%E4%B8%8E%E5%8D%B8%E8%BD%BD.html","excerpt":"","text":"Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中,然后发布到任何流行的 Linux 或 Windows 操作系统的机器上,也可以实现虚拟化,容器是完全使用沙箱机制,相互之间不会有任何接口。 Docker 官方文档地址：https://docs.docker.com/。在其官网上关于 docker 的整体架构介绍可以找到这张图： 可以看出 docker 整体是模块化、低耦合且遵循 C/S 架构的，构成它的是功能不同的组件，以下是对这些组件的功能的梳理。 Docker 组件介绍 Docker Daemon：Docker 守护进程（dockerd）监听 Docker API 请求并管理 Docker 对象，例如镜像、容器、网络和存储卷。守护进程还可以与其他守护进程通信以管理 Docker 服务。 Docker Client：Docker 客户端（docker）是许多 Docker 用户与 Docker 交互的主要方式。当你使用 docker run 等命令时，客户端会将这些命令发送给 dockerd，dockerd 会执行这些命令。 docker 命令使用 Docker API。Docker 客户端可以与多个守护进程通信。 Docker Desktop：是一个易于安装的应用程序，适用于 Mac 或 Windows 环境，能够构建和共享容器化应用程序和微服务。Docker Desktop 包括 Docker 守护程序 (dockerd)、Docker 客户端 (docker)、Docker Compose、Docker Content Trust、Kubernetes 和 Credential Helper。有关更多信息，请参阅 Docker 桌面。 Docker Registries：Docker 仓库存储 Docker 映像（Docker Image）。DockerHub 是一个任何人都可以使用的公共仓库，并且 Docker 默认配置为在 DockerHub 上查找镜像。甚至可以定制运行自己的私有仓库。 当使用 docker pull 或 docker run 命令时，将从系统所配置的镜像仓库中提取所需的镜像。当使用 docker push 命令时，你定制的镜像会被推送到你配置的镜像仓库中。 Docker Objects：当使用 Docker 时，会涉及到创建和使用图像、容器、网络、卷、插件和其他对象。以下简要概述其中一些对象。 Docker Image Docker 镜像是一个只读模板，其中包含创建 Docker 容器时的说明。通常，一个镜像基于另一个镜像，并附带有一些额外的自定义。例如，可以构建一个基于 ubuntu 镜像的镜像，但会安装 Apache Web 服务器和一些你的应用程序，该镜像还包含使你的应用程序运行所需的配置的详细信息。 你可以创建自己的镜像，也可以只使用其他人创建并在仓库中发布的镜像。要构建你自己的镜像，你需要使用简单的语法创建一个 Dockerfile，用于定义创建和运行镜像所需的步骤。Dockerfile 中的每条指令都会在镜像中创建一个层。当你更改 Dockerfile 并重建映像时，仅重建那些已更改的层。与其他虚拟化技术相比，这是使镜像如此轻量、小巧和快速的部分原因。 Docker Container Docker 容器是镜像的可运行实例。你可以使用 Docker API 或 CLI 创建、启动、停止、移动或删除容器。你可以将容器连接到一个或多个网络，将存储附加到它，甚至可以根据其当前状态创建新的镜像。 默认情况下，一个容器与其他容器以及其宿主机的隔离相对较好。你可以控制容器的网络、存储和其他底层子系统与其他容器或宿主机的隔离程度。 一个容器由其镜像以及你在创建或启动它时提供给它的任何配置选项进行定义。当容器被移除时，任何未存储在持久存储中的状态更改都会消失。 ​Docker 三大核心组件指的是：Docker Image、Docker Container 以及 Docker Registry。 Docker 运行示例 以下命令运行 ubuntu 容器，以交互方式附加到本地命令行会话，并运行 /bin/bash。 1[skinyi@fedora ~]\\$ sudo docker run -i -t ubuntu /bin/bash ^ 安装 Docker 后如不做其他配置则 docker run 命令只能使用 root 权限来执行。 当你运行此命令时，会发生以下情况（假设你使用的是默认镜像仓库配置）： 如果你在本地没有 ubuntu 映像，Docker 会从你配置的镜像仓库（默认 DockerHub）中提取它，就像你手动运行 docker pull ubuntu 一样； Docker 使用该镜像创建一个新容器，就像你手动运行了 docker container create 命令一样； Docker 为该容器分配一个读写文件系统，作为该容器的底层，这允许正在运行的容器在其本地文件系统中创建或修改文件和目录； 由于没有指定任何其他的网络选项，Docker 会创建一个网络接口来将该容器连接到默认网络，包括为容器分配 IP 地址。默认情况下，容器可以使用主机的网络连接连接到外部网络。 Docker 启动容器并执行 /bin/bash。由于容器以交互方式运行并附加到您的终端（-i 和 -t 选项），所以你可以在将输出记录到终端时使用键盘提供输入。 当你键入 exit 命令以终止 /bin/bash 命令时，容器会停止但不会被删除，你可以重新启动或删除它。 Docker 的安装与卸载 个人学习使用操作系统为：Fedora 35，Fedora 版本目前仅支持 Fedora 34 和 Fedora 35。 12345678910111213141516171819202122[skinyi@fedora ~]\\$ cat /etc/os-releaseNAME=&quot;Fedora Linux&quot;VERSION=&quot;35 (Server Edition)&quot;ID=fedoraVERSION_ID=35VERSION_CODENAME=&quot;&quot;PLATFORM_ID=&quot;platform:f35&quot;PRETTY_NAME=&quot;Fedora Linux 35 (Server Edition)&quot;ANSI_COLOR=&quot;0;38;2;60;110;180&quot;LOGO=fedora-logo-iconCPE_NAME=&quot;cpe:/o:fedoraproject:fedora:35&quot;HOME_URL=&quot;https://fedoraproject.org/&quot;DOCUMENTATION_URL=&quot;https://docs.fedoraproject.org/en-US/fedora/f35/system-administrators-guide/&quot;SUPPORT_URL=&quot;https://ask.fedoraproject.org/&quot;BUG_REPORT_URL=&quot;https://bugzilla.redhat.com/&quot;REDHAT_BUGZILLA_PRODUCT=&quot;Fedora&quot;REDHAT_BUGZILLA_PRODUCT_VERSION=35REDHAT_SUPPORT_PRODUCT=&quot;Fedora&quot;REDHAT_SUPPORT_PRODUCT_VERSION=35PRIVACY_POLICY_URL=&quot;https://fedoraproject.org/wiki/Legal:PrivacyPolicy&quot;VARIANT=&quot;Server Edition&quot;VARIANT_ID=server Fedora 操作系统 Docker 安装文档：https://docs.docker.com/engine/install/fedora/。 卸载旧版本 12345678[skinyi@fedora ~]\\$ sudo dnf remove docker \\ docker-client \\ docker-client-lastest \\ docker-common \\ docker-lastest-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine 使用软件仓库进行 Doker 的安装 ​安装 dnf-plugins-core 插件。 1[skinyi@fedora ~]$ sudo dnf -y install dnf-plugins-core ​添加 docker 的官方软件仓库。 12[skinyi@fedora ~]$ sudo dnf config-manager --add-repo \\ https://download.docker.com/linux/fedora/docker-ce.repo 安装 Docker 引擎 1[skinyi@fedora ~]$ sudo dnf install docker-ce docker-ce-cli containerd.io 启动并验证 Docker 是否成功安装 1234567891011121314151617181920212223[skinyi@fedora ~]$ sudo systemctl start docker[skinyi@fedora ~]$ sudo docker run hello-worldHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://hub.docker.com/For more examples and ideas, visit: https://docs.docker.com/get-started/ 实现非 root 权限执行 docker 命令或者实现一些其他安装后的优化可以参阅：https://docs.docker.com/engine/install/linux-postinstall/。 卸载 Docker 引擎 12[skinyi@fedora ~]$ sudo dnf remove docker-ce docker-ce-cli containerd.io[skinyi@fedora ~]$ sudo rm -rf /var/lib/docker /var/lib/containerd 启动 Docker 时的执行过程 启动过程中的注意点： Docker 优先使用的存储驱动为 Overlay2； 加载容器时会设置容器的网络，并创建虚拟网络接口 docker0，该接口使用桥接模式接入网络，并在宿主机防火墙中配置一个 docker zone； Docker 的守护程序 dockerd 初始化成功后会启动 docker 应用容器引擎，然后 docker 引擎通过监听 /run/docker.sock 套接字实现客户端与守护程序之间的通信。","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Docker","slug":"学习/Docker","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Docker/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://skinyi.github.io/tags/Docker/"},{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"容器","slug":"容器","permalink":"https://skinyi.github.io/tags/%E5%AE%B9%E5%99%A8/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://skinyi.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"}]},{"title":"使用 Hexo 搭建个人博客","slug":"Hexo | 使用 Hexo 搭建个人博客","date":"2022-02-21T14:23:11.437Z","updated":"2022-03-30T07:56:22.109Z","comments":true,"path":"2022-02-21-Hexo | 使用 Hexo 搭建个人博客.html","link":"","permalink":"https://skinyi.github.io/2022-02-21-Hexo%20|%20%E4%BD%BF%E7%94%A8%20Hexo%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2.html","excerpt":"","text":"一直以来都有搭建个人网站或者说博客的想法，今天终于把这件事做成了，感谢 Github 各大代码托管平台的 GitHub XXX Pages 服务，使我们即使没有公网服务器也能搭个人人可访问的静态个人网站，而且无需任何费用。当然国内码云也有这项服务，由于一些理由我没有在那上面弄， Github Pages 由于国内访问速度太慢了，我就在码云上面也创建了仓库，然而启用 Pages 功能需要实名认证。言归正传，按照 Hexo 社区的惯例以及正好作为自己对搭建个人网站过程的记录，我的个人网站上的第一篇文章就打算写写这个搭建博客的过程。 准备工作 搭建博客所需的环境和官网地址如下： 名称 作用 官网 Nodejs Hexo 博客框架依赖的开发环境 https://nodejs.org/en/ Git 推送博客至 github 或其他一些代码托管 https://git-scm.com/ Hexo 快速、简洁且高效的博客框架 https://hexo.io/zh-cn/ Purer theme 一款简洁高效的响应式个人博客主题 https://github.com/fengkx/hexo-theme-purer 博客系统平台环境搭建在我的 Fedora 35 虚拟机上。 12[skinyi@localhost ~]$ uname -aLinux localhost.localdomain 5.16.9-200.fc35.x86_64 #1 SMP PREEMPT Fri Feb 11 16:29:17 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux 安装步骤 我非常建议你按照我上面所给的表格来访问官方文档来分步进行部署。官方文档永远不会过时而且详尽，会最大程度上解决你的疑虑。以下是我对此次部署过程的一次记录，其中会着重记录我的部署过程中踩过的一些坑。 安装 Nodejs 使用 Linux 系统我个人比较倾向于从软件仓库获得软件，但是软件仓库里的软件不一定会是最新版的，但是这种方式可以使我们省去自己编译、配置的时间。Nodejs 官网上的下载页面里的 Linux 二进制版本是压缩包，要从软件仓库获得它的话需要点击下面的 Installing Node.js via package manager 链接来查阅官方文档。 根据文档的描述，Fedora 35 可以通过安装 dnf 软件模块的方式来进行安装，可以先看看仓库里已有的软件流版本： 1234567891011121314151617[skinyi@localhost ~]$ dnf module list nodejs上次元数据过期检查：0:08:01 前，执行于 2022年02月23日 星期三 18时50分04秒。Fedora Modular 35 - x86_64Name Stream Profiles Summary nodejs 12 default, development, minimal Javascript runtime nodejs 14 default, development, minimal Javascript runtime nodejs 15 default, development, minimal Javascript runtime nodejs 16 default, development, minimal Javascript runtime Fedora Modular 35 - x86_64 - UpdatesName Stream Profiles Summary nodejs 12 default, development, minimal Javascript runtime nodejs 14 common, development, minimal Javascript runtime nodejs 15 default, development, minimal Javascript runtime nodejs 16 [e] common, development, minimal Javascript runtime 提示：[d]默认，[e]已启用，[x]已禁用，[i]已安装 Hexo 官方文档中建议 Nodejs 版本使用 Nodejs 12.0 及以上版本的，在这里我选择安装 Nodejs 16 版本的。 1[skinyi@localhost ~]$ sudo dnf module install nodejs:16 安装完成后查看 Nodejs 版本号： 12[skinyi@localhost ~]$ node -vv16.14.0 从仓库安装完成后，需要升级 npm 版本以及为了不用以 root 权限执行 npm 命令，需要更改 npm 的配置： 1234# 在当前用户主目录创建 npm 全局安装目录[skinyi@localhost ~]$ mkdir ~/.npm-global# 配置 npm 使用刚才建的目录路径[skinyi@localhost ~]$ npm config set prefix &#x27;~/.npm-global&#x27; 添加 ~/.npm-global/bin 路径到用户环境变量： 12[skinyi@localhost ~]$ echo &#x27;export PATH=~/.npm-global/bin:$PATH&#x27; &gt;&gt; ~/.bash_rc[skinyi@localhost ~]$ source ~/.bash_rc 安装Git 使用 dnf 包管理器安装 Git： 1[skinyi@localhost ~]$ sudo dnf install git-core git 全局配置，如果需要通过 git 将博客部署到 Github Pages 上，需要配置 git 的一些全局设置： 12[skinyi@localhost ~]$ git config --global user.name &quot;github 上的用户名&quot;[skinyi@localhost ~]$ git config --global user.email &quot;注册 github 账号使用的邮箱&quot; 安装 Hexo 以上依赖软件安装成功后，就可以进行 Hexo 的安装了： 1[skinyi@localhost ~]$ npm install -g hexo-cli 在工作目录里初始化自己的博客项目： 1234[skinyi@localhost ~]$ hexo init blog[skinyi@localhost ~]$ cd blog[skinyi@localhost ~]$ npm install[skinyi@localhost ~]$ hexo server 可以通过浏览器访问本地地址：http://127.0.0.1:4000 来预览生成的博客网站，若要在外部访问的话需要通过防火墙开放 4000 端口，在此不再赘述。 更换博客主题 从 Hexo 主题列表里筛选了一圈后我终于选中了此时用的这款主题，它的 Github 链接是：https://github.com/fengkx/hexo-theme-purer ，如果你也喜欢这款主题，可以通过项目主页的的说明文档来了解它的安装、配置及使用，不过建议你在看作者的文档前先大致看下 Hexo 的使用文档来了解了解 Hexo 的一些基本概念，这样看作者的文档再上手就比较容易了。 这款主题是基于 EJS 和 Tailwind CSS 构建的，以后若有兴趣构建自己的主题可以参考使用这两种技术。 下载主题文件 我没有按照官方使用 git clone 同步的方法来下载主题，直接通过下载仓库源码的方式下载下来。gh-pages 是我的整个博客项目的主目录。 123[skinyi@localhost gh-pages]$ wget -c https://github.com/fengkx/hexo-theme-purer/archive/refs/heads/master.zip -O themes/[skinyi@localhost gh-pages]$ unzip themes/master.zip[skinyi@localhost gh-pages]$ mv themes/hexo-theme-purer-master themes/purer 文档中为了避免由于主题更新而导致原有的主题目录下的 _config.yml 文件失效故而选择把主题的 _config.yml 放在主题外面并取名为 _config.theme.yml，在进行编译时将此文件的内容写进主题底下的 _config.yml。虽然我之后不会更新这个主题但是我还是按照文档里的做了，只不过我起的名字为 _config.purer.yml。 将 purer 主题下的 _config.example.yml 复制到项目主目录下。然后编辑 package.json 的内容如下： 12[skinyi@localhost gh-pages]$ cp themes/purer/_config.example.yml _config.purer.yml[skinyi@localhost gh-pages]$ code package.json package.json123456789&#123; &quot;scripts&quot;: &#123; &quot;theme&quot;: &quot;cat ./_config.purer.yml &gt; ./themes/purer/_config.yml &quot;, &quot;build&quot;: &quot;npm run theme &amp;&amp; hexo generate&quot;, &quot;clean&quot;: &quot;hexo clean&quot;, &quot;deploy&quot;: &quot;npm run theme &amp;&amp; hexo deploy&quot;, &quot;server&quot;: &quot;npm run theme &amp;&amp; hexo server&quot; &#125;,&#125; 配置主题 安装及配置插件 首先可选的工作是卸载不需要或不推荐的渲染器： 12[skinyi@localhost gh-pages]$ npm uninstall hexo-renderer-stylus[skinyi@localhost gh-pages]$ npm uninstall hexo-renderer-marked 安装 markdown-it 渲染器以及其他常用插件： 12345678# markdown-it 渲染器[skinyi@localhost gh-pages]$ npm i -S hexo-renderer-markdown-it# 支持从post_assert_folder 用 markdown 引入图片[skinyi@localhost gh-pages]$ npm i -S hexo-asset-image# 支持 emoji[skinyi@localhost gh-pages]$ npm i -S markdown-it-emoji# 支持数学公式[skinyi@localhost gh-pages]$ npm i -S @iktakahiro/markdown-it-katex 由于 hexo-renderer-markdown-it 默认不生成 h1 的锚点，所以我们需要在站点配置文件添加如下设置，在插件对象里将刚才添加的两个插件加进去: _config.yml123456789101112131415markdown: html: true xhtmlOut: true breaks: true langPrefix: linkify: true typographer: quotes: “”‘’ anchors: level: 1 permalink: false separator: &#x27;-&#x27; plugins: - &#x27;@iktakahiro/markdown-it-katex&#x27; - markdown-it-emoji 创建常见页面 在 项目主目录/source 下按需添加 categories、tags、repositories、links、about 目录，这些分别对应博客框架中的分类页、标签页、仓库页（主题独有）、友链页、关于页。然后在其中创建对应的 index.md 文件。 我的项目没有要友链页，故最终目录结构如下： 12345678910111213141516171819[skinyi@localhost gh-pages]$ tree -L 2 sourcesource├── about│ └── index.md├── categories│ └── index.md├── images│ ├── avatar.jpg│ └── favicon.png├── _posts│ ├── 使用 Hexo 搭建个人博客.md│ └── images├── README.md├── repository│ └── index.md└── tags └── index.md7 directories, 8 files 如果你事先看过 Hexo 的文档，你就会知道 _post 目录存放的是写好的文章以及我们刚刚创建的 index.md 需要添加 front-matter。以内容稍微多的 about 目录的 front-matter 为例： 1234567---title: 关于description: 个人简介layout: aboutsidebar: customdate: 2022-02-22 20:55:00--- 其他目录的 front-matter 可以参考主题作者文档中的 Demo 链接。 定制主题配置 接下来需要修改项目主目录下的 _config_purer.yml 文件来定制自己的主题，这个参照主题文档按照自己的心意定制就成，我没有要友链和书单页面。 写作 所有已经发表的文章都在项目目录的 source/_posts 子目录下，Hexo 同样支持添加草稿，草稿目录里的文章默认不会渲染出来。对我来说懒得使用草稿了，因为吹牛根本不需要打草稿。我比较喜欢 VSCode 里边写边想，写完后再部署就可以了，根本不需要草稿。 博文是以 markdown 格式编写的，好在这门语言的学习成本并不高，多写多用多记就可以满足大部分使用需要，比较冷门的格式需要用的时候再查也花费不了太长时间。 部署文章 博客网站搭建起来了需要部署到公网上才能被他人看到，但是公网 IP 以及服务器需要花费不小的经济成本，好在一些代码托管网站都提供了 XXX Pages 服务。需要注意的是：在国内的平台上启用 Pages 服务一般都需要进行实名认证，而在 Github Pages 上部署不需要进行实名。 使用 git 的方式进行博客部署可以安装 hexo 插件 hexo-deployer-git： 1[skinyi@localhost gh-pages]$ npm install hexo-deployer-git --save 在 _config.yml 中修改配置： 1234567deploy: type: git repo: github: &lt;github 仓库地址&gt; # 如 https://github.com/xxx/xxx.github.io gitee: &lt;gitee 仓库地址&gt; # 如 https://gitee.com/xxx/xxx branch: [代码分支] # 如 master message: [提交信息] 生成站点文件并推送至远程仓库： 1[skinyi@localhost gh-pages]$ hexo clean &amp;&amp; hexo deploy 通过 Git 方式提交时建议在本地生成公私钥对并将生成的公钥文件添加到远程仓库的公钥列表里，然后每次提交时就可以通过验证公私密钥对的方式而不用每次都输用户名及密码。 到这里基本算是介绍完了所有的搭建步骤，之后我会把我在 Typora 里写的所有学习笔记都搬运到这个博客中，当然这个网站的内容并不局限于一些跟技术相关的东西，我并不确定我写的这些东西会不会有人看，我也打算写一些技术博客以外的东西，不管以后怎么样、写些什么，就活在当下、享受并记录生活吧。","categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"杂项","slug":"学习/杂项","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/%E6%9D%82%E9%A1%B9/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://skinyi.github.io/tags/Javascript/"},{"name":"Nodejs","slug":"Nodejs","permalink":"https://skinyi.github.io/tags/Nodejs/"},{"name":"Hexo","slug":"Hexo","permalink":"https://skinyi.github.io/tags/Hexo/"},{"name":"Markdown","slug":"Markdown","permalink":"https://skinyi.github.io/tags/Markdown/"}]}],"categories":[{"name":"学习","slug":"学习","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"Linux","slug":"学习/Linux","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"日常记录","slug":"日常记录","permalink":"https://skinyi.github.io/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/"},{"name":"迁移文章","slug":"迁移文章","permalink":"https://skinyi.github.io/categories/%E8%BF%81%E7%A7%BB%E6%96%87%E7%AB%A0/"},{"name":"生活","slug":"生活","permalink":"https://skinyi.github.io/categories/%E7%94%9F%E6%B4%BB/"},{"name":"驾驶","slug":"生活/驾驶","permalink":"https://skinyi.github.io/categories/%E7%94%9F%E6%B4%BB/%E9%A9%BE%E9%A9%B6/"},{"name":"Shell","slug":"学习/Shell","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Shell/"},{"name":"Docker","slug":"学习/Docker","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Docker/"},{"name":"ACP","slug":"学习/ACP","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/ACP/"},{"name":"Office","slug":"学习/Office","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/Office/"},{"name":"杂项","slug":"学习/杂项","permalink":"https://skinyi.github.io/categories/%E5%AD%A6%E4%B9%A0/%E6%9D%82%E9%A1%B9/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skinyi.github.io/tags/Linux/"},{"name":"RHEL","slug":"RHEL","permalink":"https://skinyi.github.io/tags/RHEL/"},{"name":"RHCE","slug":"RHCE","permalink":"https://skinyi.github.io/tags/RHCE/"},{"name":"认证考试","slug":"认证考试","permalink":"https://skinyi.github.io/tags/%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"},{"name":"记分","slug":"记分","permalink":"https://skinyi.github.io/tags/%E8%AE%B0%E5%88%86/"},{"name":"驾照","slug":"驾照","permalink":"https://skinyi.github.io/tags/%E9%A9%BE%E7%85%A7/"},{"name":"开车","slug":"开车","permalink":"https://skinyi.github.io/tags/%E5%BC%80%E8%BD%A6/"},{"name":"法律法规","slug":"法律法规","permalink":"https://skinyi.github.io/tags/%E6%B3%95%E5%BE%8B%E6%B3%95%E8%A7%84/"},{"name":"Shell","slug":"Shell","permalink":"https://skinyi.github.io/tags/Shell/"},{"name":"Bash","slug":"Bash","permalink":"https://skinyi.github.io/tags/Bash/"},{"name":"脚本编程","slug":"脚本编程","permalink":"https://skinyi.github.io/tags/%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/"},{"name":"Docker","slug":"Docker","permalink":"https://skinyi.github.io/tags/Docker/"},{"name":"容器","slug":"容器","permalink":"https://skinyi.github.io/tags/%E5%AE%B9%E5%99%A8/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://skinyi.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"},{"name":"ACP","slug":"ACP","permalink":"https://skinyi.github.io/tags/ACP/"},{"name":"云计算","slug":"云计算","permalink":"https://skinyi.github.io/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"阿里云","slug":"阿里云","permalink":"https://skinyi.github.io/tags/%E9%98%BF%E9%87%8C%E4%BA%91/"},{"name":"Excel","slug":"Excel","permalink":"https://skinyi.github.io/tags/Excel/"},{"name":"Office","slug":"Office","permalink":"https://skinyi.github.io/tags/Office/"},{"name":"避免加班","slug":"避免加班","permalink":"https://skinyi.github.io/tags/%E9%81%BF%E5%85%8D%E5%8A%A0%E7%8F%AD/"},{"name":"少加班","slug":"少加班","permalink":"https://skinyi.github.io/tags/%E5%B0%91%E5%8A%A0%E7%8F%AD/"},{"name":"Javascript","slug":"Javascript","permalink":"https://skinyi.github.io/tags/Javascript/"},{"name":"Nodejs","slug":"Nodejs","permalink":"https://skinyi.github.io/tags/Nodejs/"},{"name":"Hexo","slug":"Hexo","permalink":"https://skinyi.github.io/tags/Hexo/"},{"name":"Markdown","slug":"Markdown","permalink":"https://skinyi.github.io/tags/Markdown/"}]}